- Hay otro curso que cubre ML y base de datos Oracle.
- Saber de Bibliotecas de ciencia de datos y aprendizaje autom√°tico de c√≥digo abierto, y saber c√≥mo aplicarlas.

- Me gustar√≠a verificar si incluye las siguientes terminolog√≠a de los productos de ciencia de datos, en su defecto sumarla con el mismo criterios al cuadro:

OU Community 

ciclo de vida ML
modelo ML: Definen una representaci√≥n matem√°tica de tus datos y negocio. Se crean en sesiones de notebook dentro de proyectos.

entrenar Modelos
evaluar Modelos
desplegar Modelos Model Deployments: Permite desplegar modelos desde el cat√°logo como endpoints HTTP sobre infraestructura gestionada. Este tipo de despliegue como aplicaciones web que sirven predicciones en tiempo real es la forma m√°s com√∫n de operacionalizar modelos. Los endpoints HTTP son flexibles y pueden procesar solicitudes de predicci√≥n.

escalar Modelos
supervisi√≥n Modelos

automatizar pipelines ML

datos estructurados
datos √∫nicos y a menudo no estructurados

OCI Data Labeling (etiquetado de datos)
ADS 

reproducibilidad modelos
auditabilidad modelos

Enterprise-grade

JupyterLab interfaz familiar donde escriben c√≥digo Python.
Model Catalog
(tenancy) tenencia 
Projects (Proyectos): Son contenedores
Notebook Sessions (Sesiones de Notebook):  Es donde trabajan los cient√≠ficos de datos para codificar, construir y entrenar modelos, puede seleccionar CPU o GPU, el tipo de c√≥mputo (compute shape) y la cantidad de almacenamiento sin necesidad de aprovisionar manualmente.. Proveen un entorno de JupyterLab con bibliotecas de c√≥digo abierto preinstaladas y la posibilidad de agregar m√°s.

compute shape

Conda: Sistema de gesti√≥n de entornos y paquetes de c√≥digo abierto, creado para programas en Python. Se utiliza en el servicio de ciencia de datos para instalar, ejecutar y actualizar paquetes con sus dependencias r√°pidamente. Conda permite crear, guardar, cargar y alternar entre entornos de forma sencilla dentro del notebook.

ADS SDK (Accelerated Data Science Software Development Kit): Es una biblioteca en Python incluida en OCI Data Science. Tiene muchas funciones y objetos que automatizan o simplifican pasos del flujo de trabajo en ciencia de datos: conexi√≥n a datos, exploraci√≥n, visualizaci√≥n, entrenamiento con AutoML, evaluaci√≥n y explicaci√≥n de modelos. Adem√°s, ofrece una interfaz sencilla para acceder al cat√°logo de modelos y otros servicios de OCI, incluyendo almacenamiento de objetos (Object Storage).
an√°lisis exploratorio
Feature Types (tipos de caracter√≠sticas)
optimizaci√≥n de hiperpar√°metros
ADSTuner
 AutoML 
explainability (explicabilidad de modelos).



Data Science Jobs (Tareas de Ciencia de Datos): Permiten definir y ejecutar tareas repetibles de aprendizaje autom√°tico en infraestructura gestionada.

OCI Console: M√©todo m√°s com√∫n de acceso. Proporciona una interfaz basada en navegador, f√°cil de usar, que da acceso a las sesiones de notebook y todas las caracter√≠sticas del servicio. Esta ser√° la interfaz usada durante el curso.

SDKs (Kits de desarrollo): Estos permiten escribir c√≥digo para gestionar recursos del servicio. Se mostrar√°n ejemplos del uso del SDK de Python para desplegar modelos y crear tareas.

CLI (Command Line Interface): Ofrece acceso r√°pido y funcionalidad completa sin necesidad de scripting.

Regions (Regiones): OCI Data Science como servicio en la nube est√° disponible a trav√©s de regiones, que son centros de datos distribuidos globalmente, ofreciendo entornos seguros y de alto rendimiento local.

SDK de Accelerated Data Science

AutoML 
MLOps
servicios OCI
ML Services
AI Services
OCI Data Labeling 
escalabilidad empresarial
Projects, 
Notebook Sessions, 
Conda
Data Science Jobs
object storage
 Feature Types
 heatmaps
Feature Engineering
AutoML, 
ADSTuner
Pol√≠ticas IAM, 
Tenencia IAM 
Configuraci√≥n IAM
Compartments, 
grupos de usuarios, 
grupos din√°micos
Politicas, 
Sintaxis de pol√≠ticas: verbs, 
resource types pol√≠ticas,
OCI Resource Manager
Terraform Script
Networking para Data Science
VCN, 
Subnets, 
VNICs, 
DRG, 
NAT, 
Service Gateway
Patrones,
red por defecto
red personalizada
VCN Wizard
workloads
ctivos externos
Autenticaci√≥n
Interfaces
Interfaz ADS SDK,
Interfaz Python SDK,
Interfaz CLI
Autorizaci√≥n
Resource Principals
Resource seguridad, 
rotaci√≥n de certificados
Archivos de configuraci√≥n .pem
credenciales
Virtual cloud network (VCN)
Public subnet
Private subnet
Internet gateway (IG)
NAT gateway (NAT)
Service gateway (SG)
entorno OCI Data Science
pr√°cticas de MLOps
escalado MLOps, 
monitoreo MLOps


pipelines 


Servicios OCI
incorporar buenas pr√°cticas de aprendizaje autom√°tico
OCI Data Science para construir, entrenar, desplegar y gestionar modelos de ML
uso de otros servicios de datos e inteligencia artificial de OCI


Como cient√≠fico de datos o ingeniero de aprendizaje autom√°tico, nuestro trabajo diario consiste en obtener datos, preparar datos, construir y entrenar modelos, evaluar modelos, desplegar y escalar modelos, y tambi√©n automatizar pipelines (flujos de trabajo) de aprendizaje autom√°tico.

caso de uso para conectar nuestras actividades de aprendizaje autom√°tico con un problema empresarial del mundo real.

Quieren mejorar sus operaciones creando mejores experiencias para clientes, anticipando demanda de servicios y evitando fallas de equipos que se podr√≠an haber prevenido

Oracle AI es el portafolio de servicios en la nube para ayudar a las organizaciones a aprovechar todos los datos en esta nueva generaci√≥n de escenarios, la capa escencial que inicia este proceso.

Luego vienen los servicios de ML son utilizados principalmente por los cient√≠ficos de datos para construir, entrenar, desplegar y administrar modelos de ML.

Le sigue los servicios de IA contienen modelos de ML preconstruidos para usos espec√≠ficos. Algunos est√°n preentrenados y otros son entrenados por el cliente con sus propios datos. 

La capa superior de este diagrama son las aplicaciones, y esto se refiere de forma amplia a todas las maneras en que se consume la IA. Puede ser una aplicaci√≥n, un proceso de negocio o un sistema anal√≠tico.

Todos se utilizan simplemente llamando a la API del servicio, enviando los datos a procesar, y el servicio devuelve un resultado.

Ahora bien, esos servicios de IA y ML que acabo de mostrarte no funcionan de manera aislada. Est√°n respaldados por muchos otros servicios disponibles en nuestra infraestructura en la nube, incluyendo an√°lisis de negocios, an√°lisis de grafos y muchas formas de integraci√≥n y gesti√≥n de datos, todo funcionando sobre la infraestructura b√°sica de la nube. Estos servicios pueden combinarse en varias arquitecturas para respaldar diferentes escenarios.


OCI Data Science proporciona bibliotecas de c√≥digo abierto junto con acceso f√°cil a diferentes niveles de potencia de c√≥mputo sin necesidad de gestionar ninguna infraestructura.

Calidad empresarial (Enterprise-grade).El tercer principio trata sobre ser de calidad empresarial. Eso significa que est√° integrado con todos los protocolos de seguridad y acceso de OCI. La infraestructura subyacente est√° completamente gestionada. El cliente no tiene que pensar en aprovisionar c√≥mputo ni almacenamiento, ya que el servicio se encarga de todo el mantenimiento, actualizaciones y parches, para que los usuarios puedan enfocarse en resolver problemas empresariales con ciencia de datos.


Model Catalog (Cat√°logo de Modelos): Lugar donde se almacenan, rastrean, comparten y gestionan los modelos. Es un repositorio centralizado y gestionado de artefactos de modelos. Incluye metadatos sobre el origen del modelo, informaci√≥n relacionada con Git, y el script o notebook usado para subirlo al cat√°logo

Por ejemplo, se integra con Autonomous Database y el servicio de Big Data mediante clases como SecretKeeper, que facilitan el almacenamiento seguro de credenciales y el acceso a esos servicios.





| M√≥dulo / √Årea         | T√©rmino clave            | Descripci√≥n breve                                                  | Ejemplo aplicado a hotel real                                     |
|-----------------------|--------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|
| Entorno de desarrollo | Conda                    | Gestor de entornos y dependencias para Python                      | Crear entorno ‚Äúreservas‚Äù con pandas y matplotlib                   |
| Entorno de desarrollo | ADS SDK                  | Librer√≠a de Python que simplifica tareas en el ciclo ML            | Entrenar modelo para predecir cancelaciones                       |
| Entorno de desarrollo | Notebook Session         | Ambiente interactivo en OCI para ejecutar c√≥digo y analizar datos  | Editar notebook para detecci√≥n de anomal√≠as en reservas            |
| IAM                   | Tenancy                  | Entorno ra√≠z que agrupa todos los recursos en OCI                  | Tenencia ‚ÄúHotelCorp‚Äù con compartimientos separados                |
| IAM                   | Compartment              | Contenedor l√≥gico para organizar recursos y pol√≠ticas              | Compartimiento ‚ÄúMarketing‚Äù con notebooks y objetos                |
| IAM                   | Group / Dynamic Group    | Grupo de usuarios o recursos con pol√≠ticas asociadas               | Grupo ‚ÄúAnalistas‚Äù con acceso a m√©tricas y logs                    |
| IAM                   | User / Principal         | Identidad que puede autenticarse y operar sobre recursos           | Usuario ‚ÄúAnaRecepcion‚Äù con acceso a modelos y buckets              |
| IAM                   | Policy / IAM Settings    | Reglas que autorizan acciones sobre recursos                       | Pol√≠tica que permite acceso al Object Storage                     |
| IAM                   | OCI CLI / Token          | Herramientas para operar OCI desde la terminal                     | Usar CLI para lanzar notebook desde cron semanal                  |
| Automatizaci√≥n        | Job / Pipeline / Workload| Ejecuciones automatizadas en infraestructura OCI                   | Job nocturno que actualiza predicci√≥n de ocupaci√≥n                |
| Automatizaci√≥n        | Scheduler / Cron         | Programador de tareas para ejecuci√≥n peri√≥dica                     | Ejecutar script todos los d√≠as a las 6 AM                         |
| Automatizaci√≥n        | Logging / Audit          | Registro de actividad y monitoreo del sistema                      | Ver qui√©n modific√≥ modelo de predicci√≥n ayer                      |
| Ciencia de datos      | ML Lifecycle             | Ciclo completo: ingesti√≥n, entrenamiento, despliegue, monitoreo    | Desde historial de reservas hasta API en producci√≥n               |
| Ciencia de datos      | AutoML / ADSTuner        | Entrenamiento autom√°tico y ajuste de hiperpar√°metros               | Entrenar 20 modelos y elegir el m√°s preciso                       |
| Ciencia de datos      | Model Catalog / Deployment| Repositorio y endpoints HTTP para modelos ML                       | Compartir modelo con el equipo de recepci√≥n                       |
| Ciencia de datos      | Feature Engineering      | Transformar variables para mejorar modelos                         | Crear ‚Äútemporada alta‚Äù desde campo fecha                          |
| Ciencia de datos      | Train-Test Split         | Divisi√≥n de datos para entrenamiento y evaluaci√≥n                  | Usar datos de 2021 para entrenar y 2022 para testear              |
| Ciencia de datos      | Metrics / Evaluation     | Indicadores para medir la calidad de un modelo                     | Ver precisi√≥n y F1 Score del modelo de ocupaci√≥n                  |
| Visualizaci√≥n         | Feature Types / Heatmap    | Clasificaci√≥n de variables y visualizaci√≥n de relaciones            | Ver correlaci√≥n entre ocupaci√≥n y d√≠a de la semana                  |
| Visualizaci√≥n         | Histogram / Distribution   | Gr√°fico que muestra frecuencia de valores                           | Distribuci√≥n de estad√≠as por cantidad de noches                    |
| Visualizaci√≥n         | Boxplot / Outliers         | Visualizaci√≥n de rango y valores extremos                           | Detectar precios fuera de lo com√∫n en reservas                     |
| Visualizaci√≥n         | Pairplot / Correlation     | Comparaci√≥n cruzada entre variables num√©ricas                       | Relaci√≥n entre tarifa, ocupaci√≥n y tipo de habitaci√≥n              |
| Almacenamiento        | Object Storage / Bucket    | Almacenamiento escalable en OCI para datasets y resultados          | Guardar CSV con reservas hist√≥ricas                                |
| Almacenamiento        | Dataset / CSV / JSON       | Formatos de datos para an√°lisis y entrenamiento de modelos          | Subir archivo ‚Äúcancelaciones_2023.csv‚Äù al bucket                   |
| Almacenamiento        | Data Flow / Data Catalog   | Servicios para procesar y documentar grandes vol√∫menes de datos     | Catalogar datasets sobre temporada alta y baja                     |
| Seguridad             | Vault / Secret Keeper      | Gesti√≥n segura de credenciales y claves                             | Conectar notebook con base Oracle sin exponer claves               |
| Seguridad             | Encryption / Access Policy | Protecci√≥n de datos y reglas de acceso                              | Definir pol√≠tica que proh√≠ba modificar modelos desde marketing     |
| Redes                 | VCN / Subnet / NAT / SG    | Red virtual y componentes para tr√°fico interno y externo            | Acceder a Object Storage sin exponer IP p√∫blica                    |
| Redes                 | Public / Private Endpoint  | Configuraci√≥n de acceso a servicios desde dentro o fuera de OCI     | API de predicci√≥n solo accesible desde subnet del hotel            |
| Redes                 | Internet Gateway / Route   | Permisos para que una red tenga salida a internet                   | Notebook con acceso a repositorios externos                        |
| Pr√°cticas MLOps       | Escalado / Load Balancer   | Optimizaci√≥n de recursos para alta demanda                          | Aumentar recursos si el uso del modelo crece durante temporada alta|
| Pr√°cticas MLOps       | Monitoring / Logging       | Seguimiento de m√©tricas y eventos en producci√≥n                     | Ver cu√°ntas veces se consult√≥ el modelo desde recepci√≥n            |
| Pr√°cticas MLOps       | Explainability / Feature Importance| Herramientas para interpretar el modelo                     | Mostrar que ‚Äútipo de cliente‚Äù impacta m√°s en cancelaciones         |
| Pr√°cticas MLOps       | Retraining / Drift         | Reentrenamiento y detecci√≥n de cambios en los datos                 | Actualizar modelo si cambian patrones de reserva                   |
| SDK / Herramientas    | Python SDK / OCI SDK       | Librer√≠as para interactuar con servicios OCI desde c√≥digo           | Crear bucket y notebook usando Python desde script                    |
| SDK / Herramientas    | ADS SDK / ADSInterpreter   | Herramientas espec√≠ficas para ciencia de datos en OCI               | Generar explicaci√≥n de modelo con gr√°ficos autom√°ticos                |
| SDK / Herramientas    | OCI CLI                    | Interfaz de l√≠nea de comandos para operar servicios OCI             | Lanzar notebook o subir archivos directamente desde consola           |
| Infraestructura       | Terraform / Resource Manager| Infraestructura como c√≥digo para automatizar configuraci√≥n          | Crear compartimientos y pol√≠ticas de acceso de forma repetible        |
| Infraestructura       | Stack / Plan / Apply       | Proceso de despliegue con Terraform: definir, previsualizar, ejecutar| Desplegar recursos para nuevo hotel sin errores manuales              |
| Organizaci√≥n           | Tags / Cost Tracking        | Etiquetado de recursos y seguimiento de costos                      | Ver cu√°nto cuesta entrenar modelos en entorno ‚ÄúTemporadaAlta‚Äù         |
| Buenas pr√°cticas      | Modularizaci√≥n / Reusabilidad| Separar funciones para claridad y mantenimiento                     | Validaciones de reserva en m√≥dulo ‚Äúutils‚Äù                             |
| Buenas pr√°cticas      | Confirmaci√≥n / Validaci√≥n  | Evitar errores cr√≠ticos con chequeos y confirmaciones expl√≠citas    | Confirmar borrado de modelo con ‚Äú¬øEst√°s seguro? [y/n]‚Äù                |
| Buenas pr√°cticas      | Documentaci√≥n / Naming     | Uso de nombres claros y descripciones en c√≥digo y estructura        | Bucket ‚Äúdatos_cancelaciones_hotelA_2023‚Äù                              |
| Bonus Ctrl+BA         | Ficha t√©cnica / Glosario Ctrl| Recurso con t√©rminos clave y ejemplos integrados                    | Usar en mentor√≠as dentro del servidor Ctrl+BA                         |
| Bonus Ctrl+BA         | Cuestionarios / Flashcards | Material para repasar y autoevaluarse en 3 niveles                  | Fichas para revisar IAM, ML y MLOps antes del examen                  |
| Bonus Ctrl+BA         | Presentaci√≥n / Teaching Pack| Recurso did√°ctico para exponer temas en clase o comunidad           | Explicar el ciclo ML con ejemplos hoteleros y slides visuales         |


































*************************************************************

Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de este cap√≠tulo completo titulado *Data Exploration and Preparation*, con estructura clara, numeraci√≥n continua y mejoras para integrarlo a tu m√≥dulo sobre el ciclo de vida del aprendizaje autom√°tico.

---

# üîç Lecci√≥n: Data Exploration and Preparation  
## üìò Exploraci√≥n y preparaci√≥n de datos en OCI Data Science

### 1. Introducci√≥n

Hola y bienvenido a esta nueva lecci√≥n del curso de Oracle Cloud Infrastructure Data Science.  
Soy Himanshu Raj, cient√≠fico de datos y l√≠der de entrenamiento en AI/ML en Oracle.

En esta lecci√≥n abordaremos el **segundo paso del ciclo de vida del aprendizaje autom√°tico**:  
üëâ **Exploraci√≥n y preparaci√≥n de datos**.

Veremos:

- Por qu√© es necesario el preprocesamiento.
- Qu√© pasos incluye.
- Herramientas de transformaci√≥n de ADS.
- C√≥mo dividir los datos en conjuntos de entrenamiento, prueba y validaci√≥n.

---

### 2. ¬øPor qu√© preprocesar los datos?

Los datos reales suelen tener:

- Valores faltantes.
- Errores.
- Outliers.
- Formatos inconsistentes.

üîß Por eso, antes de buscar patrones, debemos **limpiar y transformar** los datos.

El preprocesamiento puede incluir varios pasos, seg√∫n el problema y el tipo de datos.  
üí° Es com√∫n que esta etapa sea la m√°s extensa del ciclo de vida de ML.

---

### 3. Operaciones b√°sicas sobre datos

Cuando los datos provienen de m√∫ltiples fuentes, debemos **combinarlos**.  
ADS permite realizar operaciones como:

- Agregar o eliminar filas/columnas.
- Filtrar.
- Concatenar vertical u horizontalmente.
- Unir por columnas o √≠ndices.

üìå Las operaciones de `pandas` tambi√©n se aplican a objetos `ADSData`.

---

### 4. Limpieza y validaci√≥n

Es importante verificar:

- Formatos y unidades.
- Convenciones de nombres.
- Tipos de datos.
- Valores nulos.
- Duplicados.
- Estad√≠sticas descriptivas.

---

### 5. Imputaci√≥n de valores faltantes

Los valores faltantes pueden deberse a errores humanos o t√©cnicos.  
Ejemplo: coordenadas GPS incorrectas por mal clima.

Opciones:

- ‚ùå Eliminar filas incompletas (no recomendado).
- ‚úÖ Imputar con:
  - Media o mediana (para datos num√©ricos).
  - Moda (para datos categ√≥ricos).

---

### 6. Codificaci√≥n de variables categ√≥ricas

- **Label Encoding** (`label_encoder`): convierte categor√≠as en n√∫meros.  
  ‚ö†Ô∏è No recomendable para datos ordinales.

- **One Hot Encoding**:
  - Convierte una columna categ√≥rica en varias columnas binarias.
  - Se puede hacer con `pandas.get_dummies()` o `fit_transform()`.

---

### 7. Detecci√≥n de outliers

Los outliers pueden ser errores o datos v√°lidos pero at√≠picos.

- Se detectan con:
  - Visualizaciones: scatterplot, boxplot.
  - Estad√≠sticas: desviaci√≥n est√°ndar, distribuci√≥n gaussiana.
  - Algoritmos de ML (supervisado o no supervisado).

üìå En aprendizaje no supervisado, se asume que los outliers son pocos y no siguen la misma tendencia.

---

### 8. Escalado de caracter√≠sticas

El escalado ajusta las variables a una misma escala.  
Es √∫til en algoritmos sensibles a distancias (ej. regresi√≥n).

- **Normalizaci√≥n (Min-Max)**: valores entre 0 y 1.
- **Estandarizaci√≥n**: media 0, desviaci√≥n est√°ndar 1 ‚Üí distribuci√≥n normal.

---

### 9. Reducci√≥n de dimensionalidad

La **dimensionalidad** es el n√∫mero de variables de entrada.

- Alta dimensionalidad = mayor costo computacional.
- Dos enfoques:
  - **Selecci√≥n de caracter√≠sticas**: elegir un subconjunto.
  - **Extracci√≥n de caracter√≠sticas**: crear nuevas variables a partir de las existentes.

---

### 10. Preprocesamiento de texto

Para datos textuales, se aplican t√©cnicas como:

- Vectorizaci√≥n.
- Eliminaci√≥n de stop words.
- Tokenizaci√≥n.
- POS tagging.
- Stemming y lematizaci√≥n.

---

### 11. Herramientas de transformaci√≥n en ADS

#### a. `suggest_recommendations`

- Detecta problemas en el dataset.
- Sugiere transformaciones.
- Pod√©s aceptar los cambios desde el men√∫.
- Luego se obtiene el dataset transformado con `get_transformed_dataset()`.

#### b. `auto_transform`

- Aplica todas las recomendaciones autom√°ticamente.
- Imputa valores faltantes.
- Elimina columnas altamente correlacionadas.
- Maneja clases desbalanceadas (upsampling/downsampling).
- Elimina claves primarias y columnas sin valor predictivo.

#### c. `visualize_transforms`

- Muestra visualmente las transformaciones aplicadas.
- Solo funciona con transformaciones autom√°ticas.

---

### 12. Ejemplo pr√°ctico

En un dataset de rotaci√≥n de empleados:

- ADS detecta tipos de datos.
- Sugiere transformaciones.
- Muestra correlaciones fuertes y desbalance de clases.
- Visualiza el flujo de transformaci√≥n.

üìå Los resultados var√≠an seg√∫n el dataset.

---

### 13. Divisi√≥n de datos

Dividir el dataset en:

- **Entrenamiento**
- **Prueba**
- **Validaci√≥n**

Permite evaluar la **generalizaci√≥n** del modelo.

Por defecto, ADS usa:

- 80% entrenamiento
- 10% prueba
- 10% validaci√≥n

üí° En datasets peque√±os, puede ser mejor usar 70% o 60% para entrenamiento.

---

### 14. Conclusi√≥n

Esta lecci√≥n cubri√≥:

- Preprocesamiento de datos reales.
- Herramientas de transformaci√≥n en ADS.
- Codificaci√≥n, imputaci√≥n, escalado y detecci√≥n de outliers.
- Divisi√≥n en conjuntos de entrenamiento, prueba y validaci√≥n.

---