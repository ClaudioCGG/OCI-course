- Hay otro curso que cubre ML y base de datos Oracle.
- Saber de Bibliotecas de ciencia de datos y aprendizaje autom√°tico de c√≥digo abierto, y saber c√≥mo aplicarlas.

- Me gustar√≠a verificar si incluye las siguientes terminolog√≠a de los productos de ciencia de datos, en su defecto sumarla con el mismo criterios al cuadro:

OU Community 

ciclo de vida ML
modelo ML: Definen una representaci√≥n matem√°tica de tus datos y negocio. Se crean en sesiones de notebook dentro de proyectos.

entrenar Modelos
evaluar Modelos
desplegar Modelos Model Deployments: Permite desplegar modelos desde el cat√°logo como endpoints HTTP sobre infraestructura gestionada. Este tipo de despliegue como aplicaciones web que sirven predicciones en tiempo real es la forma m√°s com√∫n de operacionalizar modelos. Los endpoints HTTP son flexibles y pueden procesar solicitudes de predicci√≥n.

escalar Modelos
supervisi√≥n Modelos

automatizar pipelines ML

datos estructurados
datos √∫nicos y a menudo no estructurados

OCI Data Labeling (etiquetado de datos)
ADS 

reproducibilidad modelos
auditabilidad modelos

Enterprise-grade

JupyterLab interfaz familiar donde escriben c√≥digo Python.
Model Catalog
(tenancy) tenencia 
Projects (Proyectos): Son contenedores
Notebook Sessions (Sesiones de Notebook):  Es donde trabajan los cient√≠ficos de datos para codificar, construir y entrenar modelos, puede seleccionar CPU o GPU, el tipo de c√≥mputo (compute shape) y la cantidad de almacenamiento sin necesidad de aprovisionar manualmente.. Proveen un entorno de JupyterLab con bibliotecas de c√≥digo abierto preinstaladas y la posibilidad de agregar m√°s.

compute shape

Conda: Sistema de gesti√≥n de entornos y paquetes de c√≥digo abierto, creado para programas en Python. Se utiliza en el servicio de ciencia de datos para instalar, ejecutar y actualizar paquetes con sus dependencias r√°pidamente. Conda permite crear, guardar, cargar y alternar entre entornos de forma sencilla dentro del notebook.

ADS SDK (Accelerated Data Science Software Development Kit): Es una biblioteca en Python incluida en OCI Data Science. Tiene muchas funciones y objetos que automatizan o simplifican pasos del flujo de trabajo en ciencia de datos: conexi√≥n a datos, exploraci√≥n, visualizaci√≥n, entrenamiento con AutoML, evaluaci√≥n y explicaci√≥n de modelos. Adem√°s, ofrece una interfaz sencilla para acceder al cat√°logo de modelos y otros servicios de OCI, incluyendo almacenamiento de objetos (Object Storage).
an√°lisis exploratorio
Feature Types (tipos de caracter√≠sticas)
optimizaci√≥n de hiperpar√°metros
ADSTuner
 AutoML 
explainability (explicabilidad de modelos).



Data Science Jobs (Tareas de Ciencia de Datos): Permiten definir y ejecutar tareas repetibles de aprendizaje autom√°tico en infraestructura gestionada.

OCI Console: M√©todo m√°s com√∫n de acceso. Proporciona una interfaz basada en navegador, f√°cil de usar, que da acceso a las sesiones de notebook y todas las caracter√≠sticas del servicio. Esta ser√° la interfaz usada durante el curso.

SDKs (Kits de desarrollo): Estos permiten escribir c√≥digo para gestionar recursos del servicio. Se mostrar√°n ejemplos del uso del SDK de Python para desplegar modelos y crear tareas.

CLI (Command Line Interface): Ofrece acceso r√°pido y funcionalidad completa sin necesidad de scripting.

Regions (Regiones): OCI Data Science como servicio en la nube est√° disponible a trav√©s de regiones, que son centros de datos distribuidos globalmente, ofreciendo entornos seguros y de alto rendimiento local.

SDK de Accelerated Data Science

AutoML 
MLOps
servicios OCI
ML Services
AI Services
OCI Data Labeling 
escalabilidad empresarial
Projects, 
Notebook Sessions, 
Conda
Data Science Jobs
object storage
 Feature Types
 heatmaps
Feature Engineering
AutoML, 
ADSTuner
Pol√≠ticas IAM, 
Tenencia IAM 
Configuraci√≥n IAM
Compartments, 
grupos de usuarios, 
grupos din√°micos
Politicas, 
Sintaxis de pol√≠ticas: verbs, 
resource types pol√≠ticas,
OCI Resource Manager
Terraform Script
Networking para Data Science
VCN, 
Subnets, 
VNICs, 
DRG, 
NAT, 
Service Gateway
Patrones,
red por defecto
red personalizada
VCN Wizard
workloads
ctivos externos
Autenticaci√≥n
Interfaces
Interfaz ADS SDK,
Interfaz Python SDK,
Interfaz CLI
Autorizaci√≥n
Resource Principals
Resource seguridad, 
rotaci√≥n de certificados
Archivos de configuraci√≥n .pem
credenciales
Virtual cloud network (VCN)
Public subnet
Private subnet
Internet gateway (IG)
NAT gateway (NAT)
Service gateway (SG)
entorno OCI Data Science
pr√°cticas de MLOps
escalado MLOps, 
monitoreo MLOps


pipelines 


Servicios OCI
incorporar buenas pr√°cticas de aprendizaje autom√°tico
OCI Data Science para construir, entrenar, desplegar y gestionar modelos de ML
uso de otros servicios de datos e inteligencia artificial de OCI


Como cient√≠fico de datos o ingeniero de aprendizaje autom√°tico, nuestro trabajo diario consiste en obtener datos, preparar datos, construir y entrenar modelos, evaluar modelos, desplegar y escalar modelos, y tambi√©n automatizar pipelines (flujos de trabajo) de aprendizaje autom√°tico.

caso de uso para conectar nuestras actividades de aprendizaje autom√°tico con un problema empresarial del mundo real.

Quieren mejorar sus operaciones creando mejores experiencias para clientes, anticipando demanda de servicios y evitando fallas de equipos que se podr√≠an haber prevenido

Oracle AI es el portafolio de servicios en la nube para ayudar a las organizaciones a aprovechar todos los datos en esta nueva generaci√≥n de escenarios, la capa escencial que inicia este proceso.

Luego vienen los servicios de ML son utilizados principalmente por los cient√≠ficos de datos para construir, entrenar, desplegar y administrar modelos de ML.

Le sigue los servicios de IA contienen modelos de ML preconstruidos para usos espec√≠ficos. Algunos est√°n preentrenados y otros son entrenados por el cliente con sus propios datos. 

La capa superior de este diagrama son las aplicaciones, y esto se refiere de forma amplia a todas las maneras en que se consume la IA. Puede ser una aplicaci√≥n, un proceso de negocio o un sistema anal√≠tico.

Todos se utilizan simplemente llamando a la API del servicio, enviando los datos a procesar, y el servicio devuelve un resultado.

Ahora bien, esos servicios de IA y ML que acabo de mostrarte no funcionan de manera aislada. Est√°n respaldados por muchos otros servicios disponibles en nuestra infraestructura en la nube, incluyendo an√°lisis de negocios, an√°lisis de grafos y muchas formas de integraci√≥n y gesti√≥n de datos, todo funcionando sobre la infraestructura b√°sica de la nube. Estos servicios pueden combinarse en varias arquitecturas para respaldar diferentes escenarios.


OCI Data Science proporciona bibliotecas de c√≥digo abierto junto con acceso f√°cil a diferentes niveles de potencia de c√≥mputo sin necesidad de gestionar ninguna infraestructura.

Calidad empresarial (Enterprise-grade).El tercer principio trata sobre ser de calidad empresarial. Eso significa que est√° integrado con todos los protocolos de seguridad y acceso de OCI. La infraestructura subyacente est√° completamente gestionada. El cliente no tiene que pensar en aprovisionar c√≥mputo ni almacenamiento, ya que el servicio se encarga de todo el mantenimiento, actualizaciones y parches, para que los usuarios puedan enfocarse en resolver problemas empresariales con ciencia de datos.


Model Catalog (Cat√°logo de Modelos): Lugar donde se almacenan, rastrean, comparten y gestionan los modelos. Es un repositorio centralizado y gestionado de artefactos de modelos. Incluye metadatos sobre el origen del modelo, informaci√≥n relacionada con Git, y el script o notebook usado para subirlo al cat√°logo

Por ejemplo, se integra con Autonomous Database y el servicio de Big Data mediante clases como SecretKeeper, que facilitan el almacenamiento seguro de credenciales y el acceso a esos servicios.





| M√≥dulo / √Årea         | T√©rmino clave            | Descripci√≥n breve                                                  | Ejemplo aplicado a hotel real                                     |
|-----------------------|--------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|
| Entorno de desarrollo | Conda                    | Gestor de entornos y dependencias para Python                      | Crear entorno ‚Äúreservas‚Äù con pandas y matplotlib                   |
| Entorno de desarrollo | ADS SDK                  | Librer√≠a de Python que simplifica tareas en el ciclo ML            | Entrenar modelo para predecir cancelaciones                       |
| Entorno de desarrollo | Notebook Session         | Ambiente interactivo en OCI para ejecutar c√≥digo y analizar datos  | Editar notebook para detecci√≥n de anomal√≠as en reservas            |
| IAM                   | Tenancy                  | Entorno ra√≠z que agrupa todos los recursos en OCI                  | Tenencia ‚ÄúHotelCorp‚Äù con compartimientos separados                |
| IAM                   | Compartment              | Contenedor l√≥gico para organizar recursos y pol√≠ticas              | Compartimiento ‚ÄúMarketing‚Äù con notebooks y objetos                |
| IAM                   | Group / Dynamic Group    | Grupo de usuarios o recursos con pol√≠ticas asociadas               | Grupo ‚ÄúAnalistas‚Äù con acceso a m√©tricas y logs                    |
| IAM                   | User / Principal         | Identidad que puede autenticarse y operar sobre recursos           | Usuario ‚ÄúAnaRecepcion‚Äù con acceso a modelos y buckets              |
| IAM                   | Policy / IAM Settings    | Reglas que autorizan acciones sobre recursos                       | Pol√≠tica que permite acceso al Object Storage                     |
| IAM                   | OCI CLI / Token          | Herramientas para operar OCI desde la terminal                     | Usar CLI para lanzar notebook desde cron semanal                  |
| Automatizaci√≥n        | Job / Pipeline / Workload| Ejecuciones automatizadas en infraestructura OCI                   | Job nocturno que actualiza predicci√≥n de ocupaci√≥n                |
| Automatizaci√≥n        | Scheduler / Cron         | Programador de tareas para ejecuci√≥n peri√≥dica                     | Ejecutar script todos los d√≠as a las 6 AM                         |
| Automatizaci√≥n        | Logging / Audit          | Registro de actividad y monitoreo del sistema                      | Ver qui√©n modific√≥ modelo de predicci√≥n ayer                      |
| Ciencia de datos      | ML Lifecycle             | Ciclo completo: ingesti√≥n, entrenamiento, despliegue, monitoreo    | Desde historial de reservas hasta API en producci√≥n               |
| Ciencia de datos      | AutoML / ADSTuner        | Entrenamiento autom√°tico y ajuste de hiperpar√°metros               | Entrenar 20 modelos y elegir el m√°s preciso                       |
| Ciencia de datos      | Model Catalog / Deployment| Repositorio y endpoints HTTP para modelos ML                       | Compartir modelo con el equipo de recepci√≥n                       |
| Ciencia de datos      | Feature Engineering      | Transformar variables para mejorar modelos                         | Crear ‚Äútemporada alta‚Äù desde campo fecha                          |
| Ciencia de datos      | Train-Test Split         | Divisi√≥n de datos para entrenamiento y evaluaci√≥n                  | Usar datos de 2021 para entrenar y 2022 para testear              |
| Ciencia de datos      | Metrics / Evaluation     | Indicadores para medir la calidad de un modelo                     | Ver precisi√≥n y F1 Score del modelo de ocupaci√≥n                  |
| Visualizaci√≥n         | Feature Types / Heatmap    | Clasificaci√≥n de variables y visualizaci√≥n de relaciones            | Ver correlaci√≥n entre ocupaci√≥n y d√≠a de la semana                  |
| Visualizaci√≥n         | Histogram / Distribution   | Gr√°fico que muestra frecuencia de valores                           | Distribuci√≥n de estad√≠as por cantidad de noches                    |
| Visualizaci√≥n         | Boxplot / Outliers         | Visualizaci√≥n de rango y valores extremos                           | Detectar precios fuera de lo com√∫n en reservas                     |
| Visualizaci√≥n         | Pairplot / Correlation     | Comparaci√≥n cruzada entre variables num√©ricas                       | Relaci√≥n entre tarifa, ocupaci√≥n y tipo de habitaci√≥n              |
| Almacenamiento        | Object Storage / Bucket    | Almacenamiento escalable en OCI para datasets y resultados          | Guardar CSV con reservas hist√≥ricas                                |
| Almacenamiento        | Dataset / CSV / JSON       | Formatos de datos para an√°lisis y entrenamiento de modelos          | Subir archivo ‚Äúcancelaciones_2023.csv‚Äù al bucket                   |
| Almacenamiento        | Data Flow / Data Catalog   | Servicios para procesar y documentar grandes vol√∫menes de datos     | Catalogar datasets sobre temporada alta y baja                     |
| Seguridad             | Vault / Secret Keeper      | Gesti√≥n segura de credenciales y claves                             | Conectar notebook con base Oracle sin exponer claves               |
| Seguridad             | Encryption / Access Policy | Protecci√≥n de datos y reglas de acceso                              | Definir pol√≠tica que proh√≠ba modificar modelos desde marketing     |
| Redes                 | VCN / Subnet / NAT / SG    | Red virtual y componentes para tr√°fico interno y externo            | Acceder a Object Storage sin exponer IP p√∫blica                    |
| Redes                 | Public / Private Endpoint  | Configuraci√≥n de acceso a servicios desde dentro o fuera de OCI     | API de predicci√≥n solo accesible desde subnet del hotel            |
| Redes                 | Internet Gateway / Route   | Permisos para que una red tenga salida a internet                   | Notebook con acceso a repositorios externos                        |
| Pr√°cticas MLOps       | Escalado / Load Balancer   | Optimizaci√≥n de recursos para alta demanda                          | Aumentar recursos si el uso del modelo crece durante temporada alta|
| Pr√°cticas MLOps       | Monitoring / Logging       | Seguimiento de m√©tricas y eventos en producci√≥n                     | Ver cu√°ntas veces se consult√≥ el modelo desde recepci√≥n            |
| Pr√°cticas MLOps       | Explainability / Feature Importance| Herramientas para interpretar el modelo                     | Mostrar que ‚Äútipo de cliente‚Äù impacta m√°s en cancelaciones         |
| Pr√°cticas MLOps       | Retraining / Drift         | Reentrenamiento y detecci√≥n de cambios en los datos                 | Actualizar modelo si cambian patrones de reserva                   |
| SDK / Herramientas    | Python SDK / OCI SDK       | Librer√≠as para interactuar con servicios OCI desde c√≥digo           | Crear bucket y notebook usando Python desde script                    |
| SDK / Herramientas    | ADS SDK / ADSInterpreter   | Herramientas espec√≠ficas para ciencia de datos en OCI               | Generar explicaci√≥n de modelo con gr√°ficos autom√°ticos                |
| SDK / Herramientas    | OCI CLI                    | Interfaz de l√≠nea de comandos para operar servicios OCI             | Lanzar notebook o subir archivos directamente desde consola           |
| Infraestructura       | Terraform / Resource Manager| Infraestructura como c√≥digo para automatizar configuraci√≥n          | Crear compartimientos y pol√≠ticas de acceso de forma repetible        |
| Infraestructura       | Stack / Plan / Apply       | Proceso de despliegue con Terraform: definir, previsualizar, ejecutar| Desplegar recursos para nuevo hotel sin errores manuales              |
| Organizaci√≥n           | Tags / Cost Tracking        | Etiquetado de recursos y seguimiento de costos                      | Ver cu√°nto cuesta entrenar modelos en entorno ‚ÄúTemporadaAlta‚Äù         |
| Buenas pr√°cticas      | Modularizaci√≥n / Reusabilidad| Separar funciones para claridad y mantenimiento                     | Validaciones de reserva en m√≥dulo ‚Äúutils‚Äù                             |
| Buenas pr√°cticas      | Confirmaci√≥n / Validaci√≥n  | Evitar errores cr√≠ticos con chequeos y confirmaciones expl√≠citas    | Confirmar borrado de modelo con ‚Äú¬øEst√°s seguro? [y/n]‚Äù                |
| Buenas pr√°cticas      | Documentaci√≥n / Naming     | Uso de nombres claros y descripciones en c√≥digo y estructura        | Bucket ‚Äúdatos_cancelaciones_hotelA_2023‚Äù                              |
| Bonus Ctrl+BA         | Ficha t√©cnica / Glosario Ctrl| Recurso con t√©rminos clave y ejemplos integrados                    | Usar en mentor√≠as dentro del servidor Ctrl+BA                         |
| Bonus Ctrl+BA         | Cuestionarios / Flashcards | Material para repasar y autoevaluarse en 3 niveles                  | Fichas para revisar IAM, ML y MLOps antes del examen                  |
| Bonus Ctrl+BA         | Presentaci√≥n / Teaching Pack| Recurso did√°ctico para exponer temas en clase o comunidad           | Explicar el ciclo ML con ejemplos hoteleros y slides visuales         |


































*************************************************************

# üîÑ M√≥dulo: Machine Learning Lifecycle  
## üìò Cap√≠tulo: ML Lifecycle Overview ‚Äì Parte 1

### 1. Introducci√≥n

Bienvenido al m√≥dulo sobre el ciclo de vida del aprendizaje autom√°tico (*Machine Learning Lifecycle*).  
Esta primera lecci√≥n ofrece una **visi√≥n general** del ciclo de vida de ML.  
Soy Wes Prichard, gerente principal de producto para Data Science y Servicios de IA en Oracle.

---

### 2. ¬øPor qu√© es importante el ciclo de vida de ML?

Las organizaciones buscan herramientas **vers√°tiles y productivas** para sus cient√≠ficos de datos, y desean que esas herramientas cubran **todo el ciclo de vida del aprendizaje autom√°tico**.  
Cuanto m√°s f√°cil y eficiente sea este ciclo, m√°s r√°pido y frecuentemente se podr√°n obtener resultados valiosos para la organizaci√≥n.

---

### 3. Las 6 etapas del ciclo de vida

Usaremos una versi√≥n simplificada del ciclo de vida, compuesta por **6 pasos**:

1. **Acceso a los datos**  
2. **Exploraci√≥n y preparaci√≥n de los datos**  
3. **Modelado** (construcci√≥n y entrenamiento del modelo)  
4. **Validaci√≥n del modelo**  
5. **Despliegue del modelo**  
6. **Monitoreo del modelo** (que puede llevar a su actualizaci√≥n o retiro)

üîπ Todo comienza con un **problema de negocio**, que define el objetivo del modelo.

---

### 4. Un proceso iterativo

Construir un modelo de ML es un proceso **iterativo**.  
Los pasos se repiten y ajustan hasta que el rendimiento del modelo sea satisfactorio.

üí° Existen representaciones m√°s complejas del ciclo de vida, como **CRISP-DM** (*Cross Industry Standard Process for Data Mining*), que pod√©s explorar por tu cuenta.  
Para este curso, usaremos el ciclo simplificado como marco para abordar las tareas clave del cient√≠fico de datos.

---

### 5. Acceso y adquisici√≥n de datos

Todo modelo de ML comienza con **datos**.  
En OCI Data Science, es √∫til almacenar los datos en la sesi√≥n de notebook para acceder r√°pidamente.

- El primer paso es **acceder y recopilar los datos** en el notebook.
- Conocer el **ecosistema de datos** de la organizaci√≥n ayuda a identificar fuentes potenciales.

#### Fuentes de datos comunes:
- **Sistemas de gesti√≥n de datos empresariales** (bases de datos, data lakes).
- **Pipelines de ingesti√≥n** desarrollados por ingenieros de datos y ML.
- **Datos no estructurados**: logs, texto, im√°genes, videos.
- **Cat√°logo de datos**: √∫til para localizar conjuntos existentes.
- **Fuentes externas**:
  - Datos p√∫blicos (gobiernos, open data).
  - Scraping web.
  - Proveedores de datos.
  - Encuestas, sensores, c√°maras, clickstream.

---

### 6. Exploraci√≥n y preparaci√≥n de datos

Una vez obtenidos los datos, el cient√≠fico de datos debe:

- **Explorar** y **visualizar** los datos.
- **Transformarlos** y repetir el proceso si es necesario.
- **Prepararlos**: limpieza y procesamiento antes del an√°lisis.

#### Tareas t√≠picas:
- Identificar y corregir datos corruptos, duplicados o incompletos.
- Determinar si los datos est√°n **etiquetados** (ej. im√°genes con bounding boxes).
- Si no lo est√°n, usar servicios como **OCI Data Labeling Cloud Service**.

---

### 7. An√°lisis exploratorio y estad√≠stico

Despu√©s de la limpieza, se analizan las **features** (variables):

- Identificar relaciones entre variables.
- Decidir transformaciones adicionales.
- Usar herramientas de an√°lisis estad√≠stico y visualizaci√≥n.

#### Preguntas clave:
- ¬øQu√© tipo de features hay?
- ¬øCu√°l es la distribuci√≥n de valores?
- ¬øHay valores nulos o inv√°lidos?
- ¬øExisten outliers?
- ¬øHay sesgos o correlaciones?
- ¬øEs necesario normalizar o transformar (ej. log)?
- ¬øC√≥mo manejar categor√≠as con cola larga?

---

### 8. Ingenier√≠a de features

Durante la exploraci√≥n, se pueden crear nuevas features que representen mejor los datos.

Ejemplo:  
En un dataset de tr√°fico con conteo por hora, pod√©s crear una feature que agrupe las horas en franjas como:

- Madrugada  
- Ma√±ana  
- Tarde  
- Noche  

Para features categ√≥ricas, suele ser necesario convertirlas en binarias (una por categor√≠a).

---

### 9. Modelado (inicio)

La etapa de modelado consiste en:

- Elegir el algoritmo de ML adecuado.
- Seleccionar las features que alimentar√°n el modelo.

üîπ En el primer paso, el cient√≠fico de datos debe decidir **qu√© tipo de modelo** es apropiado para resolver el problema planteado.

---

### 10. Tipos de aprendizaje autom√°tico

Existen dos tipos principales:

- **Aprendizaje supervisado**:  
  - El modelo aprende a partir de datos de entrada asociados a una **salida o etiqueta**.  
  - Ejemplos: clasificaci√≥n, regresi√≥n.

- **Aprendizaje no supervisado**:  
  - El modelo trabaja con datos **sin etiquetas**.  
  - Ejemplo: segmentaci√≥n de clientes ‚Üí el modelo asigna los segmentos autom√°ticamente.

---

### 11. Selecci√≥n de algoritmos y entrenamiento

- Se utilizan diferentes clases de modelos para problemas supervisados y no supervisados.
- Los cient√≠ficos de datos suelen probar **m√∫ltiples algoritmos** y generar **varios candidatos de modelos**.
- No se sabe de antemano cu√°l funcionar√° mejor ‚Üí se experimenta.

Durante el entrenamiento:

- Se prueban distintos **subconjuntos de features** como entrada.
- Reducir el n√∫mero de variables:
  - Disminuye el costo computacional.
  - Mejora la generalizaci√≥n.
  - Puede mejorar el rendimiento.

---

### 12. Divisi√≥n del conjunto de datos

- **Training set** ‚Üí para entrenar el modelo.  
- **Testing set** ‚Üí para evaluar el rendimiento en datos no vistos.

---

### 13. Evaluaci√≥n del modelo

Una vez entrenado, se debe evaluar su **idoneidad**.

- Hay herramientas open-source para calcular y visualizar m√©tricas.
- Elegir las m√©tricas adecuadas depende del **problema de negocio**.

#### Ejemplos:

- **Clasificaci√≥n**:
  - M√©trica com√∫n: **accuracy**.
  - Pero en casos como detecci√≥n de enfermedades raras, es mejor usar:
    - **Precisi√≥n** y **recall**.
    - **Matriz de confusi√≥n**: TP, TN, FP, FN.

- **Regresi√≥n**:
  - **RMSE** (error cuadr√°tico medio).
  - **MAE** (error absoluto medio).
  - **R¬≤** (coeficiente de determinaci√≥n).

- **No supervisado**:
  - Se busca que los **clusters** tengan alta cohesi√≥n interna.

---

### 14. Guardado de modelos

- Los modelos se guardan en formatos como:
  - **Pickle**
  - **ONNX**
  - **PMML**
- OCI Data Science ofrece un **cat√°logo de modelos** para preservarlos.

Seg√∫n el objetivo, el trabajo puede ser:

- Prueba de concepto.
- Experimentaci√≥n.
- Despliegue en producci√≥n.

---

### 15. Despliegue del modelo

Proceso de poner el modelo en uso.  
Tambi√©n se debe desplegar el **pipeline de transformaci√≥n de datos**.

- Los cient√≠ficos de datos colaboran con **ingenieros MLOps**.
- El despliegue puede ser:
  - **Batch**: inferencias programadas (ej. cada hora/d√≠a).
  - **Tiempo real**: activadas por eventos (ej. detecci√≥n de fraude en pagos).

#### Consideraciones:
- ¬øQu√© tan r√°pido se necesita la respuesta? ¬øMilisegundos o segundos?
- ¬øCu√°ntas solicitudes se esperan?
- ¬øQu√© tama√±o tienen los datos?

---

### 16. Monitoreo del modelo

Paso desafiante pero esencial para mantener la **eficacia** del modelo.

Dos componentes:

1. **Monitoreo estad√≠stico (drift)**:
   - Las m√©tricas pueden degradarse con el tiempo.
   - Ejemplo: valores fuera del rango del entrenamiento, cambios en la distribuci√≥n.

2. **Monitoreo operacional (ops)**:
   - Latencia de respuesta.
   - Uso de memoria y CPU.
   - Rendimiento y confiabilidad del sistema.
   - Logs y m√©tricas para diagn√≥stico.

---

### 17. Iteraci√≥n continua

El aprendizaje autom√°tico es un proceso **altamente iterativo**.  
Los pasos se repiten m√∫ltiples veces hasta alcanzar el objetivo de negocio.

---

### 18. Pr√≥ximas lecciones

En las siguientes lecciones, veremos c√≥mo **OCI Data Science** ayuda a los cient√≠ficos de datos a ejecutar cada etapa del ciclo de vida de ML.

---
