- Hay otro curso que cubre ML y base de datos Oracle.
- Saber de Bibliotecas de ciencia de datos y aprendizaje automático de código abierto, y saber cómo aplicarlas.

- Me gustaría verificar si incluye las siguientes terminología de los productos de ciencia de datos, en su defecto sumarla con el mismo criterios al cuadro:

OU Community 

ciclo de vida ML
modelo ML: Definen una representación matemática de tus datos y negocio. Se crean en sesiones de notebook dentro de proyectos.

entrenar Modelos
evaluar Modelos
desplegar Modelos Model Deployments: Permite desplegar modelos desde el catálogo como endpoints HTTP sobre infraestructura gestionada. Este tipo de despliegue como aplicaciones web que sirven predicciones en tiempo real es la forma más común de operacionalizar modelos. Los endpoints HTTP son flexibles y pueden procesar solicitudes de predicción.

escalar Modelos
supervisión Modelos

automatizar pipelines ML

datos estructurados
datos únicos y a menudo no estructurados

OCI Data Labeling (etiquetado de datos)
ADS 

reproducibilidad modelos
auditabilidad modelos

Enterprise-grade

JupyterLab interfaz familiar donde escriben código Python.
Model Catalog
(tenancy) tenencia 
Projects (Proyectos): Son contenedores
Notebook Sessions (Sesiones de Notebook):  Es donde trabajan los científicos de datos para codificar, construir y entrenar modelos, puede seleccionar CPU o GPU, el tipo de cómputo (compute shape) y la cantidad de almacenamiento sin necesidad de aprovisionar manualmente.. Proveen un entorno de JupyterLab con bibliotecas de código abierto preinstaladas y la posibilidad de agregar más.

compute shape

Conda: Sistema de gestión de entornos y paquetes de código abierto, creado para programas en Python. Se utiliza en el servicio de ciencia de datos para instalar, ejecutar y actualizar paquetes con sus dependencias rápidamente. Conda permite crear, guardar, cargar y alternar entre entornos de forma sencilla dentro del notebook.

ADS SDK (Accelerated Data Science Software Development Kit): Es una biblioteca en Python incluida en OCI Data Science. Tiene muchas funciones y objetos que automatizan o simplifican pasos del flujo de trabajo en ciencia de datos: conexión a datos, exploración, visualización, entrenamiento con AutoML, evaluación y explicación de modelos. Además, ofrece una interfaz sencilla para acceder al catálogo de modelos y otros servicios de OCI, incluyendo almacenamiento de objetos (Object Storage).
análisis exploratorio
Feature Types (tipos de características)
optimización de hiperparámetros
ADSTuner
 AutoML 
explainability (explicabilidad de modelos).



Data Science Jobs (Tareas de Ciencia de Datos): Permiten definir y ejecutar tareas repetibles de aprendizaje automático en infraestructura gestionada.

OCI Console: Método más común de acceso. Proporciona una interfaz basada en navegador, fácil de usar, que da acceso a las sesiones de notebook y todas las características del servicio. Esta será la interfaz usada durante el curso.

SDKs (Kits de desarrollo): Estos permiten escribir código para gestionar recursos del servicio. Se mostrarán ejemplos del uso del SDK de Python para desplegar modelos y crear tareas.

CLI (Command Line Interface): Ofrece acceso rápido y funcionalidad completa sin necesidad de scripting.

Regions (Regiones): OCI Data Science como servicio en la nube está disponible a través de regiones, que son centros de datos distribuidos globalmente, ofreciendo entornos seguros y de alto rendimiento local.

SDK de Accelerated Data Science

AutoML 
MLOps
servicios OCI
ML Services
AI Services
OCI Data Labeling 
escalabilidad empresarial
Projects, 
Notebook Sessions, 
Conda
Data Science Jobs
object storage
 Feature Types
 heatmaps
Feature Engineering
AutoML, 
ADSTuner
Políticas IAM, 
Tenencia IAM 
Configuración IAM
Compartments, 
grupos de usuarios, 
grupos dinámicos
Politicas, 
Sintaxis de políticas: verbs, 
resource types políticas,
OCI Resource Manager
Terraform Script
Networking para Data Science
VCN, 
Subnets, 
VNICs, 
DRG, 
NAT, 
Service Gateway
Patrones,
red por defecto
red personalizada
VCN Wizard
workloads
ctivos externos
Autenticación
Interfaces
Interfaz ADS SDK,
Interfaz Python SDK,
Interfaz CLI
Autorización
Resource Principals
Resource seguridad, 
rotación de certificados
Archivos de configuración .pem
credenciales
Virtual cloud network (VCN)
Public subnet
Private subnet
Internet gateway (IG)
NAT gateway (NAT)
Service gateway (SG)
entorno OCI Data Science
prácticas de MLOps
escalado MLOps, 
monitoreo MLOps


pipelines 


Servicios OCI
incorporar buenas prácticas de aprendizaje automático
OCI Data Science para construir, entrenar, desplegar y gestionar modelos de ML
uso de otros servicios de datos e inteligencia artificial de OCI


Como científico de datos o ingeniero de aprendizaje automático, nuestro trabajo diario consiste en obtener datos, preparar datos, construir y entrenar modelos, evaluar modelos, desplegar y escalar modelos, y también automatizar pipelines (flujos de trabajo) de aprendizaje automático.

caso de uso para conectar nuestras actividades de aprendizaje automático con un problema empresarial del mundo real.

Quieren mejorar sus operaciones creando mejores experiencias para clientes, anticipando demanda de servicios y evitando fallas de equipos que se podrían haber prevenido

Oracle AI es el portafolio de servicios en la nube para ayudar a las organizaciones a aprovechar todos los datos en esta nueva generación de escenarios, la capa escencial que inicia este proceso.

Luego vienen los servicios de ML son utilizados principalmente por los científicos de datos para construir, entrenar, desplegar y administrar modelos de ML.

Le sigue los servicios de IA contienen modelos de ML preconstruidos para usos específicos. Algunos están preentrenados y otros son entrenados por el cliente con sus propios datos. 

La capa superior de este diagrama son las aplicaciones, y esto se refiere de forma amplia a todas las maneras en que se consume la IA. Puede ser una aplicación, un proceso de negocio o un sistema analítico.

Todos se utilizan simplemente llamando a la API del servicio, enviando los datos a procesar, y el servicio devuelve un resultado.

Ahora bien, esos servicios de IA y ML que acabo de mostrarte no funcionan de manera aislada. Están respaldados por muchos otros servicios disponibles en nuestra infraestructura en la nube, incluyendo análisis de negocios, análisis de grafos y muchas formas de integración y gestión de datos, todo funcionando sobre la infraestructura básica de la nube. Estos servicios pueden combinarse en varias arquitecturas para respaldar diferentes escenarios.


OCI Data Science proporciona bibliotecas de código abierto junto con acceso fácil a diferentes niveles de potencia de cómputo sin necesidad de gestionar ninguna infraestructura.

Calidad empresarial (Enterprise-grade).El tercer principio trata sobre ser de calidad empresarial. Eso significa que está integrado con todos los protocolos de seguridad y acceso de OCI. La infraestructura subyacente está completamente gestionada. El cliente no tiene que pensar en aprovisionar cómputo ni almacenamiento, ya que el servicio se encarga de todo el mantenimiento, actualizaciones y parches, para que los usuarios puedan enfocarse en resolver problemas empresariales con ciencia de datos.


Model Catalog (Catálogo de Modelos): Lugar donde se almacenan, rastrean, comparten y gestionan los modelos. Es un repositorio centralizado y gestionado de artefactos de modelos. Incluye metadatos sobre el origen del modelo, información relacionada con Git, y el script o notebook usado para subirlo al catálogo

Por ejemplo, se integra con Autonomous Database y el servicio de Big Data mediante clases como SecretKeeper, que facilitan el almacenamiento seguro de credenciales y el acceso a esos servicios.





| Módulo / Área         | Término clave            | Descripción breve                                                  | Ejemplo aplicado a hotel real                                     |
|-----------------------|--------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|
| Entorno de desarrollo | Conda                    | Gestor de entornos y dependencias para Python                      | Crear entorno “reservas” con pandas y matplotlib                   |
| Entorno de desarrollo | ADS SDK                  | Librería de Python que simplifica tareas en el ciclo ML            | Entrenar modelo para predecir cancelaciones                       |
| Entorno de desarrollo | Notebook Session         | Ambiente interactivo en OCI para ejecutar código y analizar datos  | Editar notebook para detección de anomalías en reservas            |
| IAM                   | Tenancy                  | Entorno raíz que agrupa todos los recursos en OCI                  | Tenencia “HotelCorp” con compartimientos separados                |
| IAM                   | Compartment              | Contenedor lógico para organizar recursos y políticas              | Compartimiento “Marketing” con notebooks y objetos                |
| IAM                   | Group / Dynamic Group    | Grupo de usuarios o recursos con políticas asociadas               | Grupo “Analistas” con acceso a métricas y logs                    |
| IAM                   | User / Principal         | Identidad que puede autenticarse y operar sobre recursos           | Usuario “AnaRecepcion” con acceso a modelos y buckets              |
| IAM                   | Policy / IAM Settings    | Reglas que autorizan acciones sobre recursos                       | Política que permite acceso al Object Storage                     |
| IAM                   | OCI CLI / Token          | Herramientas para operar OCI desde la terminal                     | Usar CLI para lanzar notebook desde cron semanal                  |
| Automatización        | Job / Pipeline / Workload| Ejecuciones automatizadas en infraestructura OCI                   | Job nocturno que actualiza predicción de ocupación                |
| Automatización        | Scheduler / Cron         | Programador de tareas para ejecución periódica                     | Ejecutar script todos los días a las 6 AM                         |
| Automatización        | Logging / Audit          | Registro de actividad y monitoreo del sistema                      | Ver quién modificó modelo de predicción ayer                      |
| Ciencia de datos      | ML Lifecycle             | Ciclo completo: ingestión, entrenamiento, despliegue, monitoreo    | Desde historial de reservas hasta API en producción               |
| Ciencia de datos      | AutoML / ADSTuner        | Entrenamiento automático y ajuste de hiperparámetros               | Entrenar 20 modelos y elegir el más preciso                       |
| Ciencia de datos      | Model Catalog / Deployment| Repositorio y endpoints HTTP para modelos ML                       | Compartir modelo con el equipo de recepción                       |
| Ciencia de datos      | Feature Engineering      | Transformar variables para mejorar modelos                         | Crear “temporada alta” desde campo fecha                          |
| Ciencia de datos      | Train-Test Split         | División de datos para entrenamiento y evaluación                  | Usar datos de 2021 para entrenar y 2022 para testear              |
| Ciencia de datos      | Metrics / Evaluation     | Indicadores para medir la calidad de un modelo                     | Ver precisión y F1 Score del modelo de ocupación                  |
| Visualización         | Feature Types / Heatmap    | Clasificación de variables y visualización de relaciones            | Ver correlación entre ocupación y día de la semana                  |
| Visualización         | Histogram / Distribution   | Gráfico que muestra frecuencia de valores                           | Distribución de estadías por cantidad de noches                    |
| Visualización         | Boxplot / Outliers         | Visualización de rango y valores extremos                           | Detectar precios fuera de lo común en reservas                     |
| Visualización         | Pairplot / Correlation     | Comparación cruzada entre variables numéricas                       | Relación entre tarifa, ocupación y tipo de habitación              |
| Almacenamiento        | Object Storage / Bucket    | Almacenamiento escalable en OCI para datasets y resultados          | Guardar CSV con reservas históricas                                |
| Almacenamiento        | Dataset / CSV / JSON       | Formatos de datos para análisis y entrenamiento de modelos          | Subir archivo “cancelaciones_2023.csv” al bucket                   |
| Almacenamiento        | Data Flow / Data Catalog   | Servicios para procesar y documentar grandes volúmenes de datos     | Catalogar datasets sobre temporada alta y baja                     |
| Seguridad             | Vault / Secret Keeper      | Gestión segura de credenciales y claves                             | Conectar notebook con base Oracle sin exponer claves               |
| Seguridad             | Encryption / Access Policy | Protección de datos y reglas de acceso                              | Definir política que prohíba modificar modelos desde marketing     |
| Redes                 | VCN / Subnet / NAT / SG    | Red virtual y componentes para tráfico interno y externo            | Acceder a Object Storage sin exponer IP pública                    |
| Redes                 | Public / Private Endpoint  | Configuración de acceso a servicios desde dentro o fuera de OCI     | API de predicción solo accesible desde subnet del hotel            |
| Redes                 | Internet Gateway / Route   | Permisos para que una red tenga salida a internet                   | Notebook con acceso a repositorios externos                        |
| Prácticas MLOps       | Escalado / Load Balancer   | Optimización de recursos para alta demanda                          | Aumentar recursos si el uso del modelo crece durante temporada alta|
| Prácticas MLOps       | Monitoring / Logging       | Seguimiento de métricas y eventos en producción                     | Ver cuántas veces se consultó el modelo desde recepción            |
| Prácticas MLOps       | Explainability / Feature Importance| Herramientas para interpretar el modelo                     | Mostrar que “tipo de cliente” impacta más en cancelaciones         |
| Prácticas MLOps       | Retraining / Drift         | Reentrenamiento y detección de cambios en los datos                 | Actualizar modelo si cambian patrones de reserva                   |
| SDK / Herramientas    | Python SDK / OCI SDK       | Librerías para interactuar con servicios OCI desde código           | Crear bucket y notebook usando Python desde script                    |
| SDK / Herramientas    | ADS SDK / ADSInterpreter   | Herramientas específicas para ciencia de datos en OCI               | Generar explicación de modelo con gráficos automáticos                |
| SDK / Herramientas    | OCI CLI                    | Interfaz de línea de comandos para operar servicios OCI             | Lanzar notebook o subir archivos directamente desde consola           |
| Infraestructura       | Terraform / Resource Manager| Infraestructura como código para automatizar configuración          | Crear compartimientos y políticas de acceso de forma repetible        |
| Infraestructura       | Stack / Plan / Apply       | Proceso de despliegue con Terraform: definir, previsualizar, ejecutar| Desplegar recursos para nuevo hotel sin errores manuales              |
| Organización           | Tags / Cost Tracking        | Etiquetado de recursos y seguimiento de costos                      | Ver cuánto cuesta entrenar modelos en entorno “TemporadaAlta”         |
| Buenas prácticas      | Modularización / Reusabilidad| Separar funciones para claridad y mantenimiento                     | Validaciones de reserva en módulo “utils”                             |
| Buenas prácticas      | Confirmación / Validación  | Evitar errores críticos con chequeos y confirmaciones explícitas    | Confirmar borrado de modelo con “¿Estás seguro? [y/n]”                |
| Buenas prácticas      | Documentación / Naming     | Uso de nombres claros y descripciones en código y estructura        | Bucket “datos_cancelaciones_hotelA_2023”                              |
| Bonus Ctrl+BA         | Ficha técnica / Glosario Ctrl| Recurso con términos clave y ejemplos integrados                    | Usar en mentorías dentro del servidor Ctrl+BA                         |
| Bonus Ctrl+BA         | Cuestionarios / Flashcards | Material para repasar y autoevaluarse en 3 niveles                  | Fichas para revisar IAM, ML y MLOps antes del examen                  |
| Bonus Ctrl+BA         | Presentación / Teaching Pack| Recurso didáctico para exponer temas en clase o comunidad           | Explicar el ciclo ML con ejemplos hoteleros y slides visuales         |


































*************************************************************
---
# 📥 Lección: Access Data – Parte 1  
## 🔍 Acceso a datos en OCI Data Science

### 1. Introducción

Hola y bienvenido a la siguiente lección del curso de Oracle Cloud Infrastructure Data Science.  
Soy Himanshu Raj, científico de datos y líder senior de entrenamiento en AI/ML en Oracle.

En esta lección aprenderemos sobre el **primer paso del ciclo de vida del aprendizaje automático**:  
👉 **Acceder a los datos**.

También veremos:

- Por qué necesitamos datos.
- Cómo se recopilan.
- Cuáles son las fuentes clave para acceder a datos en OCI Data Science.

---

### 2. ¿Por qué necesitamos datos?

Toda aplicación o servicio, digital o no, **genera información**.  
Esta información puede clasificarse según su tamaño o fuente:

- **Datos por lotes (batch)**: generados con el tiempo por cargas diarias (ej. backups, migraciones).
- **Datos de servicios de streaming**: mensajes o logs de eventos de usuario e IoT.
- **Datos de aplicaciones**: generados por llamadas a APIs, eventos de aplicaciones, archivos de log, etc.

🔁 Estos datos deben ser **traídos a OCI** para su preprocesamiento y entrenamiento de modelos.  
Podés acceder a ellos desde la **interfaz gráfica** o desde la **línea de comandos** usando librerías específicas.

---

### 3. ¿Qué rol cumple el dato en ciencia de datos?

La ciencia de datos es una disciplina multidisciplinaria que necesita datos para:

- Formular hipótesis y extraer conclusiones.
- Realizar investigaciones basadas en datos.
- Resolver problemas concretos.

💡 Preguntas clave:
- ¿Qué tipo de datos necesito para resolver este problema?
- ¿Con los datos que ya tengo, puedo resolver problemas existentes?

---

### 4. Fuentes clave de datos en OCI Data Science

Estas son algunas de las fuentes más comunes (aunque no las únicas):

- **OCI Object Storage**
- **Almacenamiento local**
- **Oracle Autonomous Databases**
- **MySQL**
- **Amazon S3**
- **Endpoints HTTPS**
- **DatasetBrowser**
- **PyArrow**

---

### 5. Acceso a Oracle Object Storage

Para cargar un `DataFrame` desde Object Storage:

- Usá el ejemplo proporcionado, reemplazando el nombre del bucket y archivo.
- Podés autenticarte usando:
  - **API Key**
  - **Resource Principal** (usualmente en funciones serverless)

🔐 El módulo `set_auth` permite habilitar o deshabilitar la identidad del principal o del par de claves en una sesión abierta.

📚 Para más detalles, consultá la documentación de la clase ADS.

---

### 6. Acceso a almacenamiento local

Podés acceder a archivos locales usando funciones como:

```python
pandas.read_csv("ruta/al/archivo.csv")
```

---

### 7. Acceso a Oracle Autonomous Databases

OCI Data Science soporta ambos servicios de Autonomous Database.

- Usá `ads.read_sql`, que es **15 veces más rápido** que `pandas.read_sql`.
- Esto se debe a que **evita el ORM** y está optimizado para bases de datos Oracle.

#### Si usás un wallet file:
- Definí los parámetros de conexión y la ubicación del wallet.
- Luego ejecutá la consulta con `ads.read_sql`.

#### Si no usás wallet:
- Definí `hostname` y `port` en el diccionario `connection_parameters`.
- ⚠️ Esta opción está disponible solo en **ADS versión 2.5.6 o superior**.

🔐 Se recomienda usar **bind variables** para evitar ataques de inyección SQL.

📉 El rendimiento puede verse afectado por factores como la red, latencia, etc.

---
# 📥 Lección: Access Data – Parte 2  
## 🔍 Acceso a datos en OCI Data Science (continuación)

### 8. Optimización del acceso a bases de datos

El **tiempo de respuesta** de una base de datos puede mejorar significativamente mediante:

- Uso de **índices**.
- Escritura de **consultas SQL eficientes**.

🔹 Aunque la red de OCI es muy rápida, factores como VPNs o topologías complejas pueden afectar el rendimiento.  
Es importante considerar el **tiempo necesario para acceder a los datos**.

---

### 9. Acceso a MySQL

Podés seguir los mismos pasos que con Oracle Autonomous Database, pero:

- Debés definir el motor como `"MySQL"`.
- Esta funcionalidad está disponible a partir de **ADS versión 2.5.6**.

Para guardar un `DataFrame` en MySQL:

```python
ads.to_sql(df, engine="MySQL", ...)
```

---

### 10. Acceso a Amazon S3

- Archivos públicos o privados de **Amazon S3** pueden ser accedidos vía `pandas`.
- Para archivos privados, debés pasar las **credenciales correctas** usando el diccionario `storage_options` de ADS.

---

### 11. Acceso vía HTTP/HTTPS

También podés acceder a datos desde **URLs** usando `pandas`:

```python
pd.read_csv("https://ejemplo.com/datos.csv")
```

---

### 12. Uso de DatasetBrowser

ADS incluye el método `DatasetBrowser` para acceder fácilmente a conjuntos de datos bien definidos desde bibliotecas de referencia como:

- **Seaborn**
- **Scikit-learn**
- **GitHub**

Podés listar los datasets disponibles con:

```python
DatasetBrowser.list()
```

Y abrir uno específico con:

```python
DatasetBrowser.open("nombre_dataset")
```

---

### 13. Acceso a datos con PyArrow y OCI FS

ADS también permite editar y procesar datos grandes usando **PyArrow** a través de **OCI File Systems (OCI FS)**.

- OCI FS es un sistema de archivos Pythonic que:
  - Contiene información de conexión.
  - Permite operaciones típicas de sistema de archivos.

---

### 14. Detección de tipos semánticos de datos

ADS detecta automáticamente los **tipos semánticos** al abrir un dataset:

- **Categóricos**: ej. color de ojos, talla de camisa.
- **Ordinales**: ej. nivel educativo (primaria, secundaria, universidad).
- **Continuos**: ej. altura, versiones de software.
- **Fechas y horas**: formato datetime.

Podés inspeccionar los tipos con:

```python
df.feature_types
df.show_in_notebook()
```

---

### 15. Fuentes y formatos soportados por ADS

ADS soporta múltiples fuentes y formatos de datos en OCI Data Science.  
📚 Están listados en la [documentación oficial](https://docs.oracle.com/es-ww/iaas/Content/data-science/using/overview.htm)¹.

🔹 No se soportan directamente:
- Archivos `.txt`, `.doc`, `.pdf`
- Imágenes sin procesar
- Estructuras como `list`, `tuple`, `range`

Pero ADS incluye un **módulo de extracción de texto** para convertir `.PDF` o `.DOC` en texto plano.

---

### 16. Cierre de la lección

Esperamos que esta lección te haya sido útil para aprender cómo acceder a datos desde fuentes comunes en Oracle Data Science.  
Este paso es esencial para iniciar cualquier flujo de trabajo de machine learning.

---
