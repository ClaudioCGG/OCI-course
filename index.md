# <center>üåê Bienvenido a Ciencia de Datos</center>
---
---
## üìö √çndice tem√°tico del curso OCI Data Science 

### 1. **Bienvenida e Introducci√≥n General**
- Qu√© es Data Science y por qu√© es relevante hoy
- Objetivo del curso y habilidades requeridas
- Casos de uso: Employee Attrition
- Estructura del curso por m√≥dulos
- Consejos de estudio y comunidad de aprendizaje

### 2. **Historia y Evoluci√≥n de Data Science**
- Filosof√≠a: Navaja de Ockham
- Primeros enfoques cient√≠ficos (Mayer, Tukey, Samuel)
- Hitos tecnol√≥gicos (Deep Blue, AutoML)
- Nacimiento del t√©rmino ‚ÄúData Science‚Äù
- Aplicaciones modernas: Great Resignation y predicci√≥n de abandono

### 3. **Servicios de Oracle para Data Science y AI**
- Diferencias entre ML Services y AI Services
- OCI Data Labeling y Cat√°logo de Modelos
- Arquitectura: datos, aplicaciones, servicios
- Principios gu√≠a: aceleraci√≥n individual, colaboraci√≥n y escalabilidad empresarial

### 4. **Terminolog√≠a y Componentes Clave de OCI Data Science**
- Projects, Notebook Sessions, Conda
- ADS SDK: funcionalidades y flujo completo
- Model Catalog, Model Deployment, Data Science Jobs
- Interfaces disponibles: consola, SDK, CLI, API REST

### 5. **Visualizaci√≥n, Ingenier√≠a de Features y Entrenamiento**
- Acceso a datos: local, object storage, bases Oracle y terceros
- Exploraci√≥n de datos: Feature Types, heatmaps, estad√≠sticas
- Feature Engineering: codificaci√≥n, imputaci√≥n, recomendaciones
- Entrenamiento de modelos: AutoML, ADSTuner
- Evaluaci√≥n de modelos y explicaci√≥n (interpretabilidad local/global)

### 6. **Pol√≠ticas, Tenencia y Configuraci√≥n IAM**
- Compartments, grupos de usuarios, grupos din√°micos
- Sintaxis de pol√≠ticas: verbs, resource types
- Pol√≠ticas requeridas y √∫tiles para logging, m√©tricas, red y servicios relacionados
- Ejemplo de configuraci√≥n manual y con OCI Resource Manager
- Acceso y estructura del Terraform Script

### 7. **Networking para Data Science**
- Componentes de red: VCN, Subnets, VNICs, DRG, NAT, Service Gateway
- Patrones: red por defecto vs red personalizada
- Uso del VCN Wizard
- Requisitos para conectar workloads a activos externos

### 8. **Autenticaci√≥n en APIs de OCI**
- Interfaces disponibles: ADS SDK, Python SDK, CLI
- Diferencias entre autenticaci√≥n y autorizaci√≥n
- Resource Principals: seguridad, rotaci√≥n de certificados
- Archivos de configuraci√≥n y claves API (.pem)
- Notebooks de ejemplo para crear credenciales</br></br>



---
---
# *** 1. WELCOME TO DATA SCIENCE ***
---
---

# üéì Lecci√≥n 1.1: Course Overview
## üìò Introducci√≥n al curso de Oracle Cloud Infrastructure Data Science

### 1. Bienvenida

¬°Bienvenido al curso de **OCI Data Science**!
La ciencia de datos es el arte y la ciencia de extraer valor de los datos para resolver problemas reales y de negocio.

Este es un gran momento para **capacitarte o recapacitar a tu equipo** y responder a la creciente demanda de profesionales en ciencia de datos.

---

### 2. ¬øQu√© es OCI?

Usaremos el t√©rmino **OCI** para referirnos a **Oracle Cloud Infrastructure**, la plataforma en la que se basa este curso.

---

### 3. Equipo del curso

A lo largo del curso escuchar√°s a varios especialistas, entre ellos:

- Wes Prichard  
- John Peach  
- John Stanesby  
- JR Gauthier  
- Lyudmil Pelov  
- Praveen Patil  
- Hemant Gahankari  

Adem√°s, decenas de personas colaboraron en el desarrollo del curso.

---

### 4. Audiencia objetivo

Este curso est√° dise√±ado principalmente para:

- üë©‚Äçüî¨ Cient√≠ficos de datos
- ü§ñ Ingenieros de ML
- üß† Ingenieros de IA

Se espera que tengas:

- Experiencia en Python para ML
- Conocimiento general de librer√≠as open source (ej. scikit-learn, pandas, etc.)
- Idealmente, al menos 1 a√±o de experiencia en roles afines
- Familiaridad b√°sica con OCI

---

### 5. Objetivo del curso

Prepararte para:

- Usar OCI Data Science y servicios relacionados
- Construir, entrenar, desplegar y gestionar modelos ML
- Aplicar buenas pr√°cticas en la nube
- Aprobar el examen de certificaci√≥n de OCI Data Science

---

### 6. Estructura del curso

El curso se divide en 5 m√≥dulos principales:

| M√≥dulo | Contenido |
|--------|----------|
| **1. Introducci√≥n a Data Science** | Qu√© es OCI Data Science y c√≥mo configurar tu tenancy |
| **2. Configuraci√≥n del entorno** | Uso del entorno de trabajo en OCI Data Science |
| **3. Ciclo de vida del ML** | Capacidades de OCI para cada etapa del ciclo de vida |
| **4. Pr√°cticas de MLOps** | Escalado, monitoreo y automatizaci√≥n |
| **5. Servicios relacionados de OCI** | Otros servicios √∫tiles para soluciones de ciencia de datos |

üîπ Cada m√≥dulo incluye lecciones con demostraciones grabadas.  
üîπ Se recomienda seguir los m√≥dulos en orden.

---

### 7. Laboratorio de pr√°ctica

Incluye un laboratorio de punta a punta con el caso de uso:

> **Predicci√≥n de rotaci√≥n de empleados**  
> Predice la probabilidad de que un empleado deje la organizaci√≥n seg√∫n m√∫ltiples caracter√≠sticas.

üìå Requiere una cuenta de Oracle Cloud (puede ser gratuita).  
üìå Se recomienda acceder al repositorio de ejemplos en GitHub: `oci-data-science-ai-samples`.

---

### 8. Comunidad y soporte

- Si ten√©s dudas, pod√©s usar el formulario **Ask Your Instructor**.
- Tambi√©n pod√©s unirte a la **comunidad de Oracle University (OU)** para interactuar con otros estudiantes y expertos.

---

### 9. Consejos para el curso y el examen

- Tom√° notas seg√∫n tu conocimiento previo
- Us√° las transcripciones para seguir el contenido
- Hac√© pausas cada hora y movete
- Complet√° los ejercicios pr√°cticos y el laboratorio
- Realiz√° el examen de pr√°ctica antes del examen oficial

---

### 10. Mejora continua

El equipo de OCI est√° en constante mejora del curso.
Tus comentarios y calificaciones ayudan a optimizar la experiencia de aprendizaje.

---
---

# üéØ Lecci√≥n 1.2: Expert Tips ‚Äì Introducci√≥n  
## üìò Consejos pr√°cticos para profesionales de ciencia de datos en OCI

### 1. Bienvenida

Gracias por elegir el curso **OCI Data Science Professional** y por dar el paso hacia tu certificaci√≥n.  
Soy **Hemant Gahankari**, l√≠der principal de entrenamiento en Oracle University.

---

### 2. ¬øQu√© hacemos como cient√≠ficos de datos o ingenieros de ML?

Nuestro trabajo diario incluye:

- üì• Obtener y preparar datos
- üß† Construir y entrenar modelos
- üìä Evaluar resultados
- üöÄ Desplegar y escalar modelos
- üîÅ Automatizar pipelines de machine learning

üîπ Con los servicios de **OCI Data Science** y **OCI AI**, podemos realizar todas estas tareas de forma eficiente.

---

### 3. ¬øQu√© incluye esta serie?

A trav√©s de una serie de **videos de consejos expertos**, aprender√°s a usar funciones potentes y a la vez simples de:

- OCI Data Science Service
- OCI AI Services

üîπ El objetivo es ayudarte a aplicar estas herramientas en tus proyectos reales de forma pr√°ctica y efectiva.

---
---
# *** 2. INTRODUCTION AND CONFIGURATION ***
---
---

# üß† 2.1 Lecci√≥n: Data Science ‚Äì Introducci√≥n (Parte 1)
## üìò M√≥dulo : Introducci√≥n y configuraci√≥n

### 1. Bienvenida

Hola, soy **Wes Pritchard**, gerente principal de producto para Data Science y AI Services en Oracle.  
Esta lecci√≥n presenta el servicio **OCI Data Science Cloud Service**.

---

### 2. Breve historia de la ciencia de datos

| A√±o | Evento |
|-----|--------|
| 1300s | William Ockham propone la **navaja de Ockham**: preferir soluciones simples |
| 1700s | Tobias Mayer recopila datos lunares ‚Üí precursor del an√°lisis cuantitativo |
| 1952 | Arthur Samuel (IBM) acu√±a el t√©rmino **machine learning** con un juego de damas |
| 1962 | John Tukey predice el impacto de la computaci√≥n en el an√°lisis de datos |
| 1997 | Deep Blue (IBM) vence a Kasparov en ajedrez con 200 mil millones de c√°lculos |
| 2008 | DJ Patil y Jeff Hammerbacher acu√±an el t√©rmino **data science** en LinkedIn y Facebook |
| 2021 | Anthony Klotz define la **Gran Renuncia** ‚Üí caso de uso para predicci√≥n de rotaci√≥n laboral |

---

### 3. Caso de uso del curso

Usaremos el caso de **rotaci√≥n de empleados** para conectar el aprendizaje autom√°tico con un problema real de negocio.

üîπ En el laboratorio final, construir√°s tu propio modelo predictivo.

---

### 4. Evoluci√≥n del dato

Antes: solo datos estructurados de aplicaciones empresariales  
Ahora: tambi√©n datos **no estructurados** como:

- Sensores
- Apps m√≥viles
- Redes sociales
- Voz, texto, im√°genes, video, documentos

üîπ Las organizaciones quieren usar **todos los datos** para:

- Mejorar operaciones
- Anticipar demanda
- Prevenir fallas
- Crear mejores experiencias

---

### 5. Arquitectura de Oracle AI

| Capa | Descripci√≥n |
|------|-------------|
| **Datos** | Base de todo: estructurados y no estructurados |
| **Servicios ML** | Para cient√≠ficos de datos: entrenar, desplegar, gestionar |
| **Servicios AI** | Modelos preentrenados o entrenables v√≠a API |
| **Aplicaciones** | Consumen los modelos: apps, procesos, anal√≠tica |

üîπ OCI Data Science es el servicio central para cient√≠ficos de datos.  
üîπ Compatible con frameworks open source y Python.

---

### 6. Servicios complementarios

- **Oracle Database ML**: algoritmos integrados
- **OCI Data Labeling**: etiquetado de datos para entrenar modelos
- **AI Services**: modelos listos para usar v√≠a API
- **Infraestructura OCI**: anal√≠tica, grafos, integraci√≥n y gesti√≥n de datos

üîπ Estos servicios se combinan para crear arquitecturas flexibles y escalables.

---

### 7. Principios fundamentales del servicio

| Principio | Descripci√≥n |
|----------|-------------|
| **1. Aceleraci√≥n individual** | Facilita el trabajo del cient√≠fico de datos con librer√≠as open source y potencia de c√≥mputo escalable |
| **2. Colaboraci√≥n** | Permite compartir activos, evitar duplicaciones y asegurar reproducibilidad y trazabilidad |
| **3. Nivel empresarial** | Infraestructura gestionada, integrada con seguridad OCI, sin necesidad de aprovisionamiento manual |

---

### 8. Caracter√≠sticas del servicio

- Servicio en la nube para **construir, entrenar, desplegar y gestionar modelos ML**
- Soporte completo para **Python** y librer√≠as **open source**
- Interfaz basada en **JupyterLab notebooks**
- Modelos almacenados en el **Model Catalog**
- Despliegue como **endpoints HTTP** sobre infraestructura gestionada

---

### 9. Terminolog√≠a clave

| T√©rmino | Definici√≥n |
|--------|------------|
| **Project** | Contenedor colaborativo para notebooks, modelos y activos |
| **Notebook Session** | Entorno JupyterLab con librer√≠as preinstaladas y recursos configurables (CPU/GPU, almacenamiento) |
| **Conda** | Sistema de gesti√≥n de entornos y paquetes para Python |
| **ADS SDK** | Librer√≠a Python de Oracle para automatizar el flujo de trabajo de ciencia de datos |
| **Model** | Representaci√≥n matem√°tica del negocio y los datos |
| **Model Catalog** | Repositorio centralizado para almacenar, rastrear y compartir modelos |
| **Model Deployment** | Despliegue de modelos como endpoints HTTP para inferencia en tiempo real |
| **Data Science Job** | Tareas ML repetibles sobre infraestructura gestionada |

---

### 10. Acceso al servicio

| M√©todo | Descripci√≥n |
|--------|-------------|
| **OCI Console** | Interfaz web principal para notebooks y recursos |
| **REST API** | Acceso program√°tico a funcionalidades del servicio |
| **SDKs** | Interfaces para Java, Python, JS, .NET, Go, Ruby |
| **CLI** | Acceso r√°pido y completo desde terminal, sin scripting obligatorio |

---

### 11. Disponibilidad global

- OCI Data Science est√° disponible en **regiones distribuidas globalmente**
- Incluye regiones comerciales, gubernamentales y dedicadas
- Oracle agrega nuevas regiones frecuentemente ‚Üí [oracle.com/cloud](https://oracle.com/cloud)

---

### 12. Conclusi√≥n

En esta lecci√≥n conociste:

- Los principios que gu√≠an OCI Data Science
- Sus componentes clave
- La terminolog√≠a que se usar√° en todo el curso

üîú En la pr√≥xima lecci√≥n: **provisionamiento y configuraci√≥n del entorno cloud** para usar OCI Data Science en todo el ciclo de vida del ML.

---

---

# üß∞ 2.2 Lecci√≥n: ADS SDK Overview
## üìò Introducci√≥n al Accelerated Data Science SDK

### 1. Bienvenida

Hola, soy **John Peach**, cient√≠fico de datos en el equipo de OCI Data Science.  
En este m√≥dulo vas a conocer los objetivos y capacidades del **ADS SDK**.

---

### 2. ¬øQu√© es ADS SDK?

- Librer√≠a dise√±ada **por y para cient√≠ficos de datos**
- Cubre todo el **ciclo de vida del machine learning**
- Integra servicios de OCI en flujos de trabajo reales

üîπ Ejemplo: integraci√≥n con **Autonomous Database** y **Big Data Service** mediante clases como `SecretKeeper` para gestionar credenciales de forma segura.

---

### 3. Capacidades destacadas

| Funci√≥n | Descripci√≥n |
|--------|-------------|
| üîç Exploraci√≥n de datos | Feature types, visualizaci√≥n inteligente |
| üéØ Optimizaci√≥n | `ADSTuner` para ajuste de hiperpar√°metros |
| ‚öôÔ∏è AutoML | Entrenamiento automatizado de modelos |
| üß† Explicabilidad | Interpretaci√≥n de modelos para generar confianza |

---

### 4. Versiones disponibles

| Versi√≥n | Acceso |
|--------|--------|
| **P√∫blica** | Instalaci√≥n v√≠a GitHub o PyPi |
| **Privada (OCI)** | Incluida en entornos Conda de OCI con AutoML y explicabilidad activados

---

### 5. Formas de acceso

- Preinstalado en entornos **Conda** de OCI Data Science
- Instalaci√≥n manual v√≠a:
  - `pip install oracle-ads`
  - Clonaci√≥n desde GitHub

---

### 6. Funcionalidades clave

#### üîó Conexi√≥n a fuentes de datos
- ADS ofrece **conectores** para m√∫ltiples or√≠genes
- Permite limitar la transferencia de datos cuando son muy grandes
- Acceso directo a:
  - üì¶ Almacenamiento local (block storage)
  - ‚òÅÔ∏è Object Storage v√≠a protocolo **OCI + APE Spec** ‚Üí compatible con `pandas`

#### üìä Visualizaci√≥n de datos
- Smart plotting: gr√°ficos autom√°ticos seg√∫n tipo de dato
- Feature types: visualizaci√≥n reutilizable por tipo de medici√≥n
- Correlaciones entre variables

#### üß™ Ingenier√≠a de features
- ADS analiza los datos y sugiere transformaciones
- Mejora la calidad del modelo con recomendaciones autom√°ticas

#### üèãÔ∏è‚Äç‚ôÇÔ∏è Entrenamiento de modelos
- AutoML con Oracle Labs
- `ADSTuner` para optimizaci√≥n manual
- Clases para empaquetar modelos y prepararlos para despliegue

#### üìà Evaluaci√≥n de modelos
- M√©tricas est√°ndar con pocas l√≠neas de c√≥digo

#### üß† Interpretabilidad
- Explicaci√≥n de qu√© aprende el modelo
- Herramientas para comunicar resultados a otros

#### üöÄ Despliegue de modelos
- Soporte para modelos comunes y gen√©ricos
- Despliegue con pocas l√≠neas de c√≥digo

---

### 7. Conexi√≥n a fuentes de datos

ADS facilita el acceso a m√∫ltiples or√≠genes:

| Origen | Acceso |
|--------|--------|
| **Oracle DB** | Con `SecretKeeper` y credenciales en OCI Vault |
| **Autonomous DB** | Integraci√≥n directa con `ADBSecretKeeper` |
| **Cloud externos** | Compatible con S3, GCS, Azure, Dropbox, etc. v√≠a `pandas` |
| **NoSQL** | Conexi√≥n v√≠a `DataSetFactory` |
| **Big Data Service (BDS)** | Acceso directo a HDFS sin copiar datos |
| **Web (HTTP/HTTPS)** | Lectura directa de archivos a `DataFrame`

---

### 8. Visualizaci√≥n y an√°lisis exploratorio

- üìä Clases `FeatureType` para visualizaci√≥n reutilizable
- üìà Estad√≠sticas resumen por feature
- üî• Mapas de correlaci√≥n
- üé® Personalizaci√≥n y reutilizaci√≥n en distintos proyectos

---

### 9. Ingenier√≠a de features

- Clase `ADSDataSet` envuelve un `DataFrame` de `pandas`
- Sugerencias autom√°ticas de transformaci√≥n
- Soporte para:
  - Codificaci√≥n categ√≥rica
  - Imputaci√≥n de nulos
  - Recomendaciones para mejorar calidad del modelo

---

### 10. Entrenamiento de modelos

| M√©todo | Descripci√≥n |
|--------|-------------|
| **AutoML** | Entrenamiento automatizado con m√∫ltiples algoritmos |
| **ADSTuner** | Optimizaci√≥n de hiperpar√°metros |

üîπ ADS empaqueta los artefactos del modelo, los guarda en el **Model Catalog** y los prepara para producci√≥n.

---

### 11. Evaluaci√≥n de modelos

- Comparaci√≥n entre modelos con `ADSEvaluator`
- M√©tricas y gr√°ficos autom√°ticos seg√∫n tipo de problema:
  - Clasificaci√≥n binaria
  - Multiclase
  - Regresi√≥n

üîπ Evita la necesidad de generar gr√°ficos manualmente.

---

### 12. Interpretabilidad y explicabilidad

ADS ofrece herramientas **agn√≥sticas al tipo de modelo**:

| Tipo | Descripci√≥n |
|------|-------------|
| **Local** | Explica predicciones espec√≠ficas (modelo tipo caja negra) |
| **Global** | Explica comportamiento general del modelo |

üîπ Herramientas incluidas:
- Gr√°ficos de dependencia parcial (PDP)
- Gr√°ficos ALE (Accumulated Local Effects)
- Pruebas de escenarios "what-if"

---

### 13. Despliegue de modelos

- Framework de despliegue con clases espec√≠ficas
- Compatible con:
  - AutoML Oracle Labs
  - PyTorch
  - scikit-learn
  - TensorFlow
  - Modelos gen√©ricos

üîπ Despliegue con pocos comandos  
üîπ Integraci√≥n con **OCI Logging** para:
  - Logs de acceso
  - Logs de predicci√≥n

---

### 14. Conclusi√≥n del m√≥dulo

En este m√≥dulo aprendiste:

- Objetivos del ADS SDK
- C√≥mo instalar y acceder a la librer√≠a
- Conexi√≥n a m√∫ltiples fuentes de datos
- Visualizaci√≥n y an√°lisis exploratorio
- Ingenier√≠a de features guiada
- Entrenamiento y optimizaci√≥n de modelos
- Evaluaci√≥n automatizada
- Interpretabilidad y explicabilidad
- Despliegue seguro y escalable

---

Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de la primera parte de la lecci√≥n *Tenancy Configuration Basics*, estructurada como ficha t√©cnica para tu manual de OCI Data Science.

---

# üõ†Ô∏è 2.3 Lecci√≥n: Tenancy Configuration Basics
## üìò Fundamentos de configuraci√≥n de tenancy en OCI para ciencia de datos

### 1. Bienvenida

Hola, soy **Jon Stanesby**. En esta lecci√≥n repasamos los conceptos b√°sicos de configuraci√≥n de tenancy en Oracle Cloud Infrastructure (OCI), aplicados al uso de **OCI Data Science**.

---

### 2. Componentes clave

| Componente | Descripci√≥n |
|------------|-------------|
| **Compartments** | Contenedores l√≥gicos para organizar recursos |
| **User Groups** | Grupos de usuarios con permisos compartidos |
| **Dynamic Groups** | Grupos de recursos que cumplen reglas din√°micas |
| **Policies** | Reglas que otorgan acceso a grupos dentro de compartimentos

---

### 3. Flujo de configuraci√≥n

1. üîπ Asignar usuarios a grupos de usuarios  
2. üîπ Crear grupos din√°micos para recursos de ciencia de datos  
3. üîπ Definir pol√≠ticas que otorguen acceso dentro de compartimentos

---

### 4. Compartments

- Permiten **organizar y controlar el acceso** a recursos en la nube
- Solo los grupos con permisos pueden acceder
- Primer paso: **planificar** c√≥mo organizar los recursos de ciencia de datos
- Luego: crear uno o varios compartimentos

üîπ Proceso r√°pido para crear un compartimento:

1. Ir a **Identity Console**
2. Seleccionar **Compartments**
3. Hacer clic en **Create Compartment**
4. Ingresar nombre y descripci√≥n
5. Confirmar con **Create**

---

### 5. User Groups

- Agrupan usuarios individuales en OCI
- Permiten otorgar acceso a recursos dentro de compartimentos

üîπ Pasos para configurar grupos:

1. Crear usuarios  
2. Crear grupos  
3. Agregar usuarios a grupos

---

### 6. Dynamic Groups

- Agrupan **recursos** (no personas) que cumplen reglas definidas
- Ejemplos: notebook sessions, job runs, model deployments
- La membres√≠a cambia din√°micamente seg√∫n las reglas

üîπ Los recursos act√∫an como **principales** (principals)  
üîπ Pueden hacer llamadas a APIs seg√∫n las pol√≠ticas del grupo din√°mico

Ejemplo:  
Un notebook session puede acceder a Object Storage si su grupo din√°mico tiene una pol√≠tica que lo permite.

---

### 7. Reglas de coincidencia

- Se definen con el **OCID del compartimento**
- El grupo din√°mico incluir√° todos los recursos que cumplan las reglas

üîπ Lo que esos recursos pueden hacer depende de las **pol√≠ticas** asociadas

---

### 8. Pol√≠ticas

- Definen qu√© pueden hacer los usuarios o recursos en OCI
- Se aplican a nivel de **grupo** y **compartimento**

üîπ Sintaxis b√°sica:

```
Allow group <nombre_del_grupo> to <verbo> <tipo_de_recurso> in compartment <nombre_del_compartimento>
```

| Elemento | Significado |
|----------|-------------|
| **Group name** | Nombre del grupo de usuarios o din√°mico |
| **Verb** | Nivel de acceso (ej. read, manage) |
| **Resource type** | Tipo de recurso (ej. object-storage, data-science) |
| **Compartment name** | Nombre del compartimento destino

---

### 9. Verbos en pol√≠ticas (niveles de acceso)

| Verbo | Permisos otorgados |
|-------|--------------------|
| **inspect** | Listar recursos (sin metadatos) |
| **read** | `inspect` + ver metadatos y contenido |
| **use** | `read` + modificar (sin crear/eliminar) |
| **manage** | Todos los permisos (crear, modificar, eliminar) |

---

### 10. Tipos de recursos

- Pod√©s escribir pol√≠ticas para recursos individuales (ej. `data-science-model`)
- O usar tipos agregados como **data-science-family** para abarcar todos los recursos de ciencia de datos

---

### 11. Pol√≠ticas requeridas para Data Science

| Pol√≠tica | Sintaxis |
|----------|----------|
| Acceso total para usuarios | `Allow group <grupo> to manage data-science-family in compartment <nombre>` |
| Acceso para recursos (notebooks, jobs, deployments) | `Allow dynamic-group <grupo> to manage data-science-family in compartment <nombre>` |

---

### 12. Pol√≠ticas para m√©tricas y logs

| Acci√≥n | Sintaxis |
|--------|----------|
| Leer m√©tricas | `Allow group <grupo> to read metrics in compartment <nombre>` |
| Acceder a logs | `Allow dynamic-group <grupo> to use log-content in compartment <nombre>` |
| Gestionar grupos de logs | `Allow group <grupo> to manage log-groups in compartment <nombre>` |
| Usar contenido de logs | `Allow group <grupo> to use log-content in compartment <nombre>` |

---

### 13. Pol√≠ticas para redes personalizadas

| Acci√≥n | Sintaxis |
|--------|----------|
| Servicio accede a red | `Allow service data-science to use virtual-network-family in compartment <nombre>` |
| Grupo de usuarios accede | `Allow group <grupo> to use virtual-network-family in compartment <nombre>` |
| Grupo din√°mico accede | `Allow dynamic-group <grupo> to use virtual-network-family in compartment <nombre>` |

---

### 14. Pol√≠ticas √∫tiles adicionales

- Acceso a Object Storage:

```
Allow group <grupo> to manage object-family in compartment <nombre>
Allow dynamic-group <grupo> to manage object-family in compartment <nombre>
```

---

### 15. Pasos pr√°cticos en la consola

#### Crear un compartimento

1. Ir a **Identity > Compartments**
2. Hacer clic en **Create Compartment**
3. Ingresar nombre, descripci√≥n y etiquetas (opcional)
4. Guardar el **OCID** para usarlo en reglas

#### Crear usuarios

1. Ir a **Identity > Users**
2. Hacer clic en **Create User**
3. Ingresar nombre, descripci√≥n y email
4. Repetir para cada usuario

#### Crear grupo de usuarios

1. Ir a **Identity > Groups**
2. Hacer clic en **Create Group**
3. Ingresar nombre y descripci√≥n
4. Agregar usuarios con **Add User to Group**

#### Crear grupo din√°mico

1. Ir a **Identity > Dynamic Groups**
2. Hacer clic en **Create Dynamic Group**
3. Ingresar nombre, descripci√≥n y reglas de coincidencia:
   - Notebook Sessions
   - Model Deployments
   - Job Runs
4. Usar el OCID del compartimento creado

#### Crear pol√≠ticas

1. Ir a **Identity > Policies**
2. Hacer clic en **Create Policy**
3. Ingresar nombre, descripci√≥n
4. Usar el **editor manual** para pegar las pol√≠ticas requeridas
5. Guardar y luego **editar** para agregar pol√≠ticas adicionales si es necesario

---

### 16. Conclusi√≥n

En esta lecci√≥n cubrimos:

- Conceptos clave: compartimentos, grupos, grupos din√°micos y pol√≠ticas
- Reglas de coincidencia para agrupar recursos
- Sintaxis de pol√≠ticas y niveles de acceso
- Pol√≠ticas requeridas y √∫tiles para ciencia de datos
- Pasos pr√°cticos para configurar el tenancy desde la consola

---

---

# ‚öôÔ∏è 2.4 Lecci√≥n: Configure a Tenancy with OCI Resource Manager
## üìò Automatizaci√≥n de configuraci√≥n con plantillas y Terraform

### 1. Introducci√≥n

Hola, soy **John Stanesby**.
En esta lecci√≥n aprender√°s a configurar tu **tenancy de OCI** para ciencia de datos usando **OCI Resource Manager (ORM)**.

---

### 2. ¬øPor qu√© usar Resource Manager?

- Evita la configuraci√≥n manual
- Usa una **plantilla preconfigurada** para Data Science
- Crea autom√°ticamente:
  - Grupos de usuarios
  - Grupos din√°micos
  - Pol√≠ticas requeridas

---

### 3. Recursos creados por la plantilla

| Recurso | Detalles |
|--------|----------|
| **User Group** | Nombre definido por el usuario |
| **Dynamic Group** | Nombre definido por el usuario |
| **Matching Rules** | Para: `datasciencenotebooksession`, `datasciencemodeldeployment`, `datasciencejobrun` |
| **Pol√≠ticas** | Permisos para gestionar recursos, leer m√©tricas y acceder a logs |

---

### 4. Flujo para ejecutar el stack ORM

1. üß± Crear el stack
2. üìÑ Seleccionar la plantilla
3. üì¶ Elegir el compartimento
4. ‚ñ∂Ô∏è Ejecutar el stack (`Apply`)
5. üë• Agregar usuarios al grupo creado

üîπ Las plantillas est√°n disponibles **solo desde la consola**  
üîπ El stack puede editarse posteriormente

---

### 5. Alternativa: usar Terraform

- Tambi√©n pod√©s usar tu propio script Terraform
- Repositorio p√∫blico disponible en GitHub

---

### 6. Ejemplo paso a paso

1. Ir a **Resource Manager > Stacks**
2. Hacer clic en **Create Stack**
3. Seleccionar **Template** como origen
4. Ir a **Service > Data Science**
5. Elegir el compartimento deseado
6. Completar variables adicionales (opcional)
7. Hacer clic en **Create** y ejecutar `Apply`
8. Agregar usuarios al grupo creado

---

### 7. Conclusi√≥n

En esta lecci√≥n aprendiste:

- C√≥mo usar la plantilla de Data Science en OCI Resource Manager
- Qu√© recursos se crean autom√°ticamente
- C√≥mo ejecutar el stack paso a paso
- D√≥nde acceder al script Terraform alternativo

---

---

# üåê 2.5 Lecci√≥n: Networking for Data Science  
## üìò Componentes, patrones y configuraci√≥n de red en OCI

### 1. Introducci√≥n

Hola, soy **Jon Stanesby**.  
En esta lecci√≥n exploramos los conceptos b√°sicos de **redes en la nube** aplicadas a OCI Data Science.

üîπ No se cubren temas avanzados de redes, solo lo esencial para configurar conectividad en tus workloads.

---

### 2. Componentes clave de red en OCI

| Componente | Descripci√≥n |
|------------|-------------|
| **VCN (Virtual Cloud Network)** | Red privada virtual en los data centers de Oracle |
| **Subnets** | Segmentos dentro de un VCN que agrupan VNICs |
| **VNICs (Virtual Network Interface Cards)** | Interfaces que conectan instancias a la red |
| **DRG (Dynamic Routing Gateway)** | Conexi√≥n privada entre VCN y red on-premises o entre regiones |
| **NAT Gateway** | Salida a internet sin exponer IP p√∫blica |
| **Service Gateway** | Acceso privado a servicios de Oracle (ej. Object Storage)

---

### 3. C√≥mo se conectan los componentes

- Las **subnets** contienen VNICs que determinan c√≥mo se conecta una instancia
- Los **routers virtuales** (DRG, NAT, Service Gateway) permiten:
  - Conexi√≥n privada entre VCNs o con red on-prem
  - Acceso a internet sin IP p√∫blica
  - Acceso a servicios de Oracle sin salir a internet

---

### 4. Recursos de Data Science como workloads

| Tipo | Ejemplo |
|------|---------|
| **Notebook Sessions** | C√≥digo interactivo |
| **Jobs / Job Runs** | Tareas programadas |
| **Model Deployments** | Inferencia en producci√≥n |

üîπ Todos estos se consideran **workloads** que pueden requerir acceso a recursos externos.

---

### 5. Acceso a recursos externos

- Archivos de c√≥digo, datos, librer√≠as, secretos, logs
- Otros workloads en OCI (ej. Data Flow)
- Pueden estar en internet p√∫blico o en red privada

üîπ Es necesario asegurar **conectividad de red** entre el workload y el recurso externo.

---

### 6. Patrones de red disponibles

| Tipo | Descripci√≥n |
|------|-------------|
| **Default Networking** | Conexi√≥n autom√°tica a VCN gestionado por OCI |
| **Custom Networking** | Conexi√≥n a subnet propia del usuario (BYON: Bring Your Own Network) |

---

### 7. Default Networking

- El workload se conecta v√≠a VNIC secundaria a una subnet preconfigurada
- Permite:
  - Salida a internet v√≠a NAT Gateway
  - Acceso a servicios OCI v√≠a Service Gateway

üîπ Ideal para comenzar r√°pido sin configurar red ni escribir pol√≠ticas

---

### 8. Custom Networking

- Se especifica una subnet propia del tenancy
- El workload se conecta v√≠a VNIC secundaria a esa subnet
- Permite acceso a recursos privados (ej. Git corporativo, base de datos on-prem)

üîπ Requiere:
  - Configuraci√≥n de VCN por el administrador de red
  - Pol√≠ticas adicionales (ver lecci√≥n de configuraci√≥n de tenancy)

---

### 9. Configuraci√≥n r√°pida con VCN Wizard

Pasos:

1. Ir a **Networking > Virtual Cloud Networks**
2. Hacer clic en **Start VCN Wizard**
3. Elegir **Create VCN with Internet Connectivity**
4. Ingresar nombre del VCN
5. Hacer clic en **Next > Create**
6. Ver el VCN creado en la consola

üîπ Si usaste **OCI Resource Manager**, este paso ya est√° hecho

---

### 10. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Componentes clave de red en OCI
- C√≥mo se conectan entre s√≠
- Tipos de workloads en Data Science
- Patrones de conectividad: default vs custom
- C√≥mo crear un VCN r√°pidamente

---
---

# üîê 2.6 Lecci√≥n: Authenticate to OCI APIs  
## üìò Autenticaci√≥n para acceder a servicios OCI desde ciencia de datos

### 1. Introducci√≥n

Hola, soy **Jon Stanesby**.  
En esta lecci√≥n aprender√°s c√≥mo **autenticarse ante las APIs de OCI** desde recursos de ciencia de datos como:

- üìì Notebook Sessions  
- ‚öôÔ∏è Jobs / Job Runs  
- üöÄ Model Deployments

---

### 2. ¬øPor qu√© autenticarse?

Para que tu c√≥digo pueda interactuar con otros servicios OCI, como:

- Leer/escribir en Object Storage  
- Ejecutar aplicaciones en Data Flow  
- Acceder a secretos, logs, bases de datos, etc.

üîπ La autenticaci√≥n verifica tu identidad como usuario o recurso autorizado.  
üîπ La autorizaci√≥n (permisos) se cubre en la lecci√≥n de **Tenancy Configuration**.

---

### 3. Interfaces comunes para autenticarse

| Interfaz | M√©todo de autenticaci√≥n |
|----------|-------------------------|
| **ADS SDK** | Resource Principal o archivo de configuraci√≥n |
| **OCI Python SDK** | Igual que ADS |
| **OCI CLI** | Igual que ADS |

---

### 4. ¬øQu√© es un Resource Principal?

- Funcionalidad de **IAM** que permite a los recursos actuar como actores autorizados
- Cada recurso tiene su propia identidad
- Se autentica mediante **certificados gestionados autom√°ticamente**
- Evita tener que guardar credenciales en notebooks o jobs

üîπ M√°s seguro y pr√°ctico que usar archivos de configuraci√≥n y claves API  
üîπ Ideal para jobs que no tienen interfaz interactiva

---

### 5. Funcionamiento del Resource Principal

- El token se **cachea por 15 minutos**
- Si cambi√°s la pol√≠tica o el grupo din√°mico, hay que esperar ese tiempo para que se refleje

üîπ El c√≥digo para activar el resource principal var√≠a seg√∫n la interfaz (ADS, SDK, CLI)

---

### 6. Alternativa: archivo de configuraci√≥n + clave API

- M√©todo por defecto si no se usa resource principal
- Requiere:
  - Subir archivo `config` a la carpeta OCI del notebook
  - Subir o generar archivos `.pem` correspondientes

üîπ Pod√©s usar el notebook `api_keys` para generar estos archivos  
üîπ Se accede desde **Notebook Examples** en el launcher de JupyterLab

---

### 7. Conclusi√≥n

En esta lecci√≥n aprendiste:

- La importancia de autenticarse para acceder a servicios OCI
- Qu√© interfaces usan autenticaci√≥n y c√≥mo
- Qu√© es un resource principal y c√≥mo funciona
- C√≥mo usar archivos de configuraci√≥n y claves API como alternativa




---
---
# üß† UNIDAD 3: Workspace Design and Setup (Dise√±o y configuraci√≥n del espacio de trabajo)
---
---

# üéì 3.1 Lecci√≥n: Projects

Instructor: *John Stanseby*
## 1. üìå Tema central: El proyecto como componente principal

Un **proyecto de ciencia de datos** en OCI es un espacio colaborativo donde los equipos organizan su trabajo en torno a un caso de uso o pregunta de negocio.  
Todos los recursos de ciencia de datos (como notebooks y modelos) se crean **dentro de un proyecto**.

---

## 2. üõ†Ô∏è Creaci√≥n de proyectos

### 1. Desde la **Consola de OCI**

Pasos:
- Iniciar sesi√≥n con pol√≠ticas adecuadas
- Ir a **Analytics & AI ‚Üí Machine Learning ‚Üí Data Science**
- Clic en **Create Project**
- Seleccionar el **compartimento**

Opciones recomendadas:
- **Nombre √∫nico** (si no se define, se genera autom√°ticamente con timestamp)
- **Descripci√≥n** (√∫til para otros usuarios)
- **Tags decorativos**: seleccionar namespace, clave y valor  
  ‚Üí Para m√°s de un tag: clic en *Add Additional Tags*

Al finalizar:
- Clic en **View Detail page** y luego en **Create**
- Se habilita la creaci√≥n de notebooks y modelos asociados al proyecto

---

### 2. Desde el **SDK de ADS (Python)**

Usar el objeto `ProjectCatalog` y el m√©todo `create_project`, especificando el `compartment_id`.  
Ejemplo: usar la variable de entorno del notebook para crear el proyecto en el mismo compartimento.

---

## 3.üßæ Gesti√≥n de proyectos

### üîç Visualizaci√≥n
- Ir a la **Project List page**
- Clic en un proyecto para ver detalles:  
  - Nombre, descripci√≥n  
  - OCID  
  - Fecha y autor de creaci√≥n  
  - Tags

### ‚úèÔ∏è Edici√≥n
- Solo se pueden editar:  
  - Nombre  
  - Descripci√≥n  
  - Tags (desde el men√∫ de detalles)

### üóëÔ∏è Eliminaci√≥n
- Requisito: el proyecto debe estar **vac√≠o**
- Eliminar notebooks, modelos y recursos asociados primero
- Confirmar escribiendo el **nombre exacto** del proyecto
- Estado pasa a **"deleting"**, luego a **"deleted"**
- Se puede filtrar por estado (ej. ocultar los eliminados)

---

## 4.üß© Consideraciones clave

| Elemento | Recomendaci√≥n |
|---------|----------------|
| Nombre | √önico, descriptivo |
| Descripci√≥n | Breve, clara, √∫til para terceros |
| Tags | Decorativos, funcionales, agrupables |
| Compartimento | Bien definido, con pol√≠ticas IAM adecuadas |
| Eliminaci√≥n | Solo si est√° vac√≠o, con confirmaci√≥n exacta |

---

# 3.2 Lecci√≥n: Notebook Sessions en OCI

## 1. üß† ¬øQu√© son?
- Interfaces JupyterLab gestionadas por OCI para construir y entrenar modelos ML.
- Infraestructura totalmente administrada: no requiere interacci√≥n directa con APIs de c√≥mputo o almacenamiento.

### ‚öôÔ∏è Caracter√≠sticas clave
- Soporte para CPU y GPU (AMD, Intel, Nvidia).
- Almacenamiento persistente para datos, notebooks y entornos.
- Actualizaciones y parches autom√°ticos.
- Escalables: pod√©s cambiar forma de c√≥mputo y tama√±o de almacenamiento.

### üõ†Ô∏è Creaci√≥n desde la consola
1. Crear un proyecto.
2. Ir a la p√°gina de detalles del proyecto ‚Üí *Create notebook session*.
3. Seleccionar compartimento (`HotelConciliacionML`, por ejemplo).
4. Elegir forma de c√≥mputo (ej. Standard 2.2).
5. Definir tama√±o de almacenamiento (m√≠nimo 50 GB).
6. Configurar red (default o custom con VCN y subnet).
7. Agregar tags decorativos.
8. Click en *Create* ‚Üí tarda unos minutos en activarse.

### üìã Gesti√≥n de sesiones
- **Visualizaci√≥n**: desde la lista de sesiones o detalles del proyecto.
- **Edici√≥n**: solo el nombre es editable cuando est√° activa.
- **Eliminaci√≥n**: requiere confirmar el nombre; se destruye instancia y volumen.
- **Activaci√≥n/Desactivaci√≥n**:
  - Activar: permite escalar recursos.
  - Desactivar: apaga instancia pero conserva el volumen (excepto boot volume).
  - Reactivar: se crea nueva instancia y se adjunta el volumen anterior.

### üìä M√©tricas disponibles
- Uso de CPU y memoria.
- Tr√°fico de red (bytes in/out).

---

# 3.3  Lecci√≥n: üß™ C√≥mo trabajar con JupyterLab en OCI

## 1. üß† ¬øQu√© es JupyterLab?
- Interfaz web de pr√≥xima generaci√≥n para notebooks.
- Utilizada en las *notebook sessions* de OCI por su familiaridad con data scientists.
- Permite integrar notebooks, editores de texto, terminales y componentes personalizados.

---

## 2.üì¶ Funcionalidades principales

### üîπ Soporte de formatos
- Compatible con: `.ipynb`, `.txt`, `.csv`, `.json`, `.md`, `.pdf`, im√°genes, y visualizaciones Vega/Vega Lite.

### üîπ Diferencias con JupyterLab open source
Aunque la estructura es similar, en OCI se agregan:
- **Launcher personalizado** con acceso directo a notebooks, terminales, editores y ejemplos.
- **Environment Explorer**: GUI para gestionar entornos Conda.
- **Extensi√≥n GitHub**: para control de versiones dentro del notebook.

---

## 3. üß≠ Componentes de la interfaz

### üîù Barra superior (Chrome bar)
- Logo de Oracle: vuelve a la consola principal.
- Nombre de la sesi√≥n: lleva al detalle del notebook.
- Tiempo restante: por defecto 1 hora de inactividad ‚Üí se puede extender hasta 24 horas.
- Icono de ayuda: acceso a documentaci√≥n.
- Cierre de sesi√≥n.

### üìÅ Barra lateral izquierda
- **Explorador de archivos**: navegar, abrir, crear y borrar carpetas.
- **Terminal y kernels activos**: detener procesos.
- **Extensi√≥n Git**: gesti√≥n de versiones (cubierta en otra lecci√≥n).
- **Comandos**: acceso a todos los comandos de JupyterLab.
- **Inspector de propiedades**: activo en notebooks.
- **Lista de pesta√±as abiertas**
- **Tabla de contenidos**: generada desde Markdown.
- **Gestor de extensiones instaladas**

üëâ Para ocultar la barra lateral: hacer doble clic en cualquier √≠cono.

---

## 4. üß© √Årea de trabajo principal
- Paneles de pesta√±as redimensionables.
- Actividad actual marcada con borde azul.
- **Code Consoles**: espacio temporal para ejecutar c√≥digo interactivo.
- **Kernel-backed documents**: permiten ejecutar c√≥digo desde cualquier archivo de texto.
- **Vista m√∫ltiple**: edici√≥n en vivo desde distintos editores o visores.
- **Gesti√≥n de kernels**: desde el men√∫ *Kernel*, se accede a acciones como reiniciar, detener o cambiar kernel.


---

## 5. üöÄ El Launcher: üéØ Objetivo
Explorar el uso del **Launcher**, la creaci√≥n de notebooks, el manejo de celdas, kernels, extensiones y herramientas visuales dentro de JupyterLab en OCI.

- Acceso r√°pido a:
  - Notebooks
  - Consolas
  - Editor de texto
  - Terminales
  - **Environment Explorer**
  - **Notebook Examples**

- Parte superior: enlaces √∫tiles para empezar, documentaci√≥n y ejemplos.
- Lado izquierdo: extensiones destacadas:
  - **Environment Explorer**: descubre y gestiona entornos Conda.
  - **Notebook Examples**: accede a tutoriales y casos de uso.

- Lado derecho: crear archivos nuevos (notebooks, Markdown, texto) o sesiones (terminal, consola).

---

## 6. üìì Creaci√≥n y uso de notebooks

### üîπ Crear notebook con kernel Python3
- Clic en el kernel ‚Üí *Create Notebook*
- Se genera un archivo con tips √∫tiles:
  - Verificaci√≥n de conectividad
  - Imports t√≠picos de ADS
  - Variables de entorno

### üîπ Acciones b√°sicas
- **Renombrar**: clic derecho ‚Üí *Rename*
- **Ejecutar c√≥digo**:
  - Clic en tri√°ngulo
  - Men√∫ *Run ‚Üí Selected Cell*
  - Atajo: `Shift + Enter`
- **Indicadores**:
  - ‚≠ê Estrella: celda en ejecuci√≥n
  - N√∫mero: orden de ejecuci√≥n

### üîπ Tipos de celda
- Cambiar entre `Code`, `Markdown`, etc.
- Ejemplo Markdown:  
  ```markdown
  # T√≠tulo
  ```

- Reordenar celdas: arrastrar desde el borde izquierdo

---

## 7. ‚úèÔ∏è Men√∫ Edit

- **Merge cells**: combinar celdas seleccionadas
- **Split cells**: dividir celdas
- **Cambiar kernel**: clic en nombre del kernel ‚Üí seleccionar otro

---

## 8. üìä Ejemplo avanzado: notebook de clasificaci√≥n binaria

- Desde el launcher ‚Üí *Notebook Examples* ‚Üí *Binary Classification Attrition* ‚Üí *Load Example*
- Ejecutar todas las celdas
- Para detener: *Kernel ‚Üí Interrupt Kernel*

---

## 9. üîç Herramientas visuales

### üîπ Variable Inspector
- Ver variables activas
- Posicionar junto al notebook: arrastrar pesta√±a hasta que se marque en azul

### üîπ Men√∫ View
- Mostrar n√∫meros de l√≠nea
- Colapsar/expandir celdas y salidas

---

## 10. üß∞ Explorador de archivos

- Crear archivos: clic derecho
- Subir archivos: arrastrar y soltar
- Visualizaci√≥n depende del tipo:
  - `.csv`: muestra columnas y filas

---

## 11. üñ•Ô∏è Terminal

- Comandos Linux est√°ndar (`ls`, etc.)
- Herramientas disponibles:
  - `ODSC conda CLI`
  - `Git CLI`
  - `OCI CLI`

---

## 12. üìö Men√∫ Help

- Acceso a:
  - Documentaci√≥n
  - FAQs
  - Material de referencia

---

## 13. üß© Aplicaci√≥n en tus flujos

Pod√©s usar JupyterLab para:
- Documentar pruebas con Markdown y tabla de contenidos
- Versionar c√≥digo con Git desde la sesi√≥n
- Ejecutar modelos y visualizar m√©tricas
- Usar terminal para automatizaciones con OCI CLI
- Explorar entornos Conda para pruebas familiares

---
---

# 3.04 Lecci√≥n: Conda Environments en OCI Data Science</h1>

## 1. üß™ ¬øQu√© es un Conda Environment?

Un **Conda Environment** es un contenedor de software que incluye:

- Int√©rprete (ej. Python)
- M√≥dulos y librer√≠as espec√≠ficas (ej. `scikit-learn`, `pandas`, `tensorflow`)
- Configuraciones personalizadas

Permite trabajar de forma **aislada, reproducible y compartible**.

---

## 2. üéØ Beneficios clave

- **Instalaci√≥n selectiva**: solo los paquetes que necesit√°s
- **Aislamiento**: distintos entornos para distintos modelos (ej. visi√≥n vs regresi√≥n)
- **Cambio r√°pido**: pod√©s alternar entre entornos sin conflictos
- **Compartibilidad**: se pueden compartir entre notebook sessions o con tu equipo
- **Reproducibilidad**: pod√©s volver a la versi√≥n exacta de librer√≠as usadas en un modelo

---

## 3. üß≠ Tipos de Conda Environments en OCI

| Tipo                        | ¬øQui√©n lo gestiona? | ¬øD√≥nde se usa?                          |
|-----------------------------|---------------------|------------------------------------------|
| **Data Science Conda**      | Oracle               | Preinstalados, listos para usar          |
| **Published Conda**         | Vos (el usuario)     | Guardados en Object Storage, compartibles |
| **Installed Conda**         | Notebook session     | Activos en tu sesi√≥n, persistentes en block volume |

---

## 4.üñ•Ô∏è Environment Explorer

Una interfaz gr√°fica dentro de JupyterLab que te permite:

- Ver entornos en **vista de tarjetas** o **lista**
- Buscar por palabra clave
- Filtrar por GPU, estado (activo/deprecado), tipo
- Instalar, clonar o eliminar entornos
- Ver detalles t√©cnicos y librer√≠as incluidas

---
---
# 3.05 Lecci√≥n: üß† Teor√≠a de los Entornos Conda en OCI Data Science

## 1. ¬øQu√© es un entorno Conda en OCI?

Un entorno Conda en el servicio de Data Science de Oracle Cloud Infrastructure (OCI) es un paquete preconfigurado de herramientas, librer√≠as y configuraciones que permite desarrollar, entrenar y desplegar modelos de machine learning de forma eficiente. Estos entornos est√°n basados en software open source y pueden personalizarse seg√∫n las necesidades del proyecto.

### ‚úÖ Ventajas:
- Ahorra tiempo en la configuraci√≥n inicial.
- Incluye librer√≠as optimizadas para tareas espec√≠ficas.
- Compatible con JupyterLab y el ecosistema de OCI.
- Permite trabajar con CPU o GPU seg√∫n el entorno elegido.

---

## 2. Acceso y uso

Los entornos Conda se acceden desde la pesta√±a **Launcher** de JupyterLab, mediante el bot√≥n **Environment Explorer**. Todos los entornos incluyen:

- **OCI Python SDK**: para interactuar con servicios de OCI.
- **ADS SDK (oracle-ads)**: para flujos de machine learning, AutoML, ingesti√≥n de datos y explicabilidad de modelos.

---

## 3. Tipos de entornos Conda

### üîß Seg√∫n aplicaci√≥n:
- **ONNX**: para portabilidad de modelos entre frameworks.
- **PyPGX**: para grafos y an√°lisis de redes.
- **PySpark**: para procesamiento distribuido con Apache Spark.

### üéØ Seg√∫n caso de uso:
- **Computer Vision**: procesamiento de im√°genes y video.
- **Data Exploration & Manipulation**: an√°lisis exploratorio y visualizaci√≥n.
- **Financial Services**: flujos espec√≠ficos para servicios financieros.
- **Natural Language Processing (NLP)**: procesamiento de texto y lenguaje.

---

## 4. Familias de entornos Conda

Los entornos se agrupan por:

- **Versi√≥n de Python** (ej. 3.6, 3.7).
- **Arquitectura** (CPU o GPU).
- **Versi√≥n del entorno** (v1, v2, etc.).

Ejemplo:  
`Natural Language Processing for CPU - Python 3.7 - v2`  
‚Üí Misma arquitectura y versi√≥n de Python que v1, pero con librer√≠as actualizadas.

---

## 5. Convenci√≥n de nombres

### üß© Basados en aplicaci√≥n:
`TensorFlow 2.7 for CPU - Python 3.7 - v1`

### üß™ Basados en tarea:
`Data Exploration and Manipulation for CPU - Python 3.7`

---

## 6. Entornos populares y sus librer√≠as clave

### üì∑ Computer Vision
- Tareas: detecci√≥n de objetos, reconocimiento facial, seguimiento ocular.
- Librer√≠as: `scikit-image`, `Pillow`, `PyTorch`, `OpenCV`.

### üìä Data Exploration & Manipulation
- Tareas: ingesti√≥n, visualizaci√≥n, an√°lisis exploratorio.
- Librer√≠as: `ADS`, `Kafka`, `pandas`, `pandaparallel`, `matplotlib`, `seaborn`, `plotly`, `bokeh`.

### ü§ñ General Machine Learning
- Tareas: ML supervisado, AutoML, explicabilidad.
- Librer√≠as: `xgboost`, `lightgbm`, `keras`, `TensorFlow`, `Oracle AutoML`, `Oracle MLX`.

### üìù Natural Language Processing
- Tareas: extracci√≥n de texto, frases clave, POS tagging.
- Librer√≠as: `nltk`, `keybert`, `pytorch-lightning`, `simpletransformers`.

### üîÑ ONNX
- Tareas: conversi√≥n y ejecuci√≥n de modelos en formato portable.
- Librer√≠as: `ONNX`, `ONNX Runtime`.

### üóÉÔ∏è Oracle Database
- Tareas: ETL, transformaciones, consultas SQL.
- Librer√≠as: `ipython-sql`, `SQLAlchemy`, `ADS Connector`.

### ‚ö° PyTorch
- Tareas: redes neuronales, aceleraci√≥n en CPU.
- Librer√≠as: `PyTorch`, `daal4py`, `oneAPI DAL`.

### üî• PySpark
- Tareas: procesamiento distribuido, MLlib.
- Librer√≠as: `PySpark`, `MLlib`, `sparksql-magic`.

### üß¨ TensorFlow
- Tareas: entrenamiento y despliegue de modelos de deep learning.
- Librer√≠as: `TensorFlow`, `TensorBoard`, `ADS`.

---

## 7. Conclusi√≥n

Los entornos Conda en OCI Data Science son una soluci√≥n modular, escalable y decorativa para acelerar proyectos de ciencia de datos. Permiten trabajar con herramientas de √∫ltima generaci√≥n sin preocuparse por la instalaci√≥n manual, y est√°n dise√±ados para adaptarse a distintos casos de uso, arquitecturas y versiones de Python.

---

## üß† Librer√≠as mencionadas en entornos Conda de OCI Data Science

| üìö Librer√≠a              | üß© Caracter√≠stica principal                                                                 | üóÇÔ∏è Categor√≠a del entorno Conda                     |
|--------------------------|---------------------------------------------------------------------------------------------|----------------------------------------------------|
| **oracle-ads (ADS SDK)** | SDK para ML en OCI: ingesti√≥n, AutoML, explicabilidad, despliegue.                         | Todos los entornos                                 |
| **OCI Python SDK**       | Acceso a servicios de OCI desde Python.                                                    | Todos los entornos                                 |
| **scikit-image**         | Procesamiento de im√°genes.                                                                 | Computer Vision                                    |
| **Pillow**               | Manipulaci√≥n de im√°genes.                                                                  | Computer Vision                                    |
| **PyTorch**              | Deep Learning con soporte GPU.                                                             | Computer Vision, NLP, General ML                   |
| **OpenCV**               | Algoritmos de visi√≥n por computadora.                                                      | Computer Vision                                    |
| **Kafka (Python)**       | Consumo de streams de datos.                                                               | Data Exploration & Manipulation                    |
| **pandas**               | Manipulaci√≥n de datos tabulares.                                                           | Data Exploration & Manipulation, General ML        |
| **pandaparallel**        | Paralelizaci√≥n de pandas.                                                                  | Data Exploration & Manipulation                    |
| **task**                 | (No especificado, posiblemente auxiliar).                                                  | Data Exploration & Manipulation                    |
| **Matplotlib**           | Visualizaci√≥n 2D.                                                                          | Data Exploration & Manipulation                    |
| **Seaborn**              | Visualizaci√≥n estad√≠stica.                                                                 | Data Exploration & Manipulation                    |
| **Plotly**               | Gr√°ficos interactivos.                                                                     | Data Exploration & Manipulation                    |
| **Bokeh**                | Visualizaci√≥n web interactiva.                                                             | Data Exploration & Manipulation                    |
| **xgboost**              | Algoritmo de boosting eficiente.                                                           | General Machine Learning                           |
| **lightgbm**             | Boosting r√°pido y ligero.                                                                  | General Machine Learning                           |
| **Keras con TensorFlow** | API de alto nivel para redes neuronales.                                                   | General Machine Learning                           |
| **Oracle MLX**           | Explicabilidad de modelos.                                                                 | General Machine Learning                           |
| **nltk**                 | Procesamiento de texto.                                                                    | Natural Language Processing                        |
| **keybert**              | Extracci√≥n de frases clave con BERT.                                                       | Natural Language Processing                        |
| **pytorch-lightning**    | Abstracci√≥n de PyTorch para NLP.                                                           | Natural Language Processing                        |
| **simpletransformers**   | Framework NLP con transformers.                                                            | Natural Language Processing                        |
| **ONNX**                 | Formato portable de modelos ML.                                                            | ONNX (Interoperabilidad y despliegue)              |
| **ONNX Runtime**         | Ejecuci√≥n de modelos ONNX.                                                                 | ONNX (Interoperabilidad y despliegue)              |
| **ipython-sql**          | Comandos SQL en notebooks.                                                                 | Oracle Database                                    |
| **SQLAlchemy**           | ORM para bases de datos.                                                                   | Oracle Database                                    |
| **daal4py**              | Aceleraci√≥n de scikit-learn en CPUs Intel.                                                 | PyTorch (optimizado para CPU)                      |
| **oneAPI DAL**           | Librer√≠a de Intel para an√°lisis de datos.                                                  | PyTorch (optimizado para CPU)                      |
| **PySpark**              | API Python para Apache Spark.                                                              | PySpark (procesamiento distribuido)                |
| **MLlib**                | ML en Spark.                                                                               | PySpark                                            |
| **sparksql-magic**       | Comandos Spark SQL en notebooks.                                                           | PySpark                                            |
| **TensorFlow**           | Framework de ML y Deep Learning.                                                           | TensorFlow                                         |
| **TensorBoard**          | Visualizaci√≥n de m√©tricas de entrenamiento.                                                | TensorFlow                                         |


---

# 3.06 Lecci√≥n: üß† Gesti√≥n de entornos Conda con la herramienta de l√≠nea de comandos `odsc`

## 1. Introducci√≥n
En este m√≥dulo aprender√°s a **gestionar entornos Conda** utilizando la herramienta de l√≠nea de comandos `odsc` incluida en el servicio **Oracle Cloud Infrastructure (OCI) Data Science**.

Antes de entrar en detalle, recordemos qu√© es un entorno Conda:  
Un **entorno Conda** es una colecci√≥n de software empaquetada que incluye int√©rprete, librer√≠as y configuraciones necesarias para ejecutar proyectos de ciencia de datos.  
En OCI existen:
- **Conda packs gestionados** por el equipo de Data Science Service.
- **Conda packs publicados por el usuario**, que pod√©s crear y compartir.

Aunque gran parte de la gesti√≥n se puede hacer con la interfaz gr√°fica **Environment Explorer**, la CLI `odsc` ofrece **mayor control y flexibilidad**.

---

## 2. Funcionalidades principales de `odsc conda`

Con la CLI pod√©s:

- **Explorar (browse)**: ver informaci√≥n detallada de entornos Conda en formato YAML (nombre, descripci√≥n, librer√≠as clave, *slug*).
- **Buscar (search)**: combinar `odsc conda list` con herramientas como `grep` para filtrar resultados.
- **Instalar (install)**: a√±adir entornos Conda gestionados o publicados.
- **Clonar (clone)**: copiar un entorno a otra ubicaci√≥n para modificarlo sin afectar el original.
- **Modificar (modify)**: actualizar o cambiar librer√≠as de un entorno instalado.
- **Publicar (publish)**: guardar entornos personalizados en Object Storage para compartirlos o usarlos en despliegues y *jobs*.
- **Eliminar (delete)**: borrar entornos que ya no necesites.
- **Crear (create)**: generar entornos personalizados a partir de un archivo `environment.yaml`.

---

## 3. Exploraci√≥n de entornos Conda

Pod√©s hacerlo de dos maneras:
1. **Environment Explorer** (GUI).
2. **L√≠nea de comandos** con:
   ```bash
   odsc conda list
   ```
   - Por defecto, muestra entornos **Data Science** gestionados.
   - Para listar solo los entornos instalados localmente en tu notebook:
     ```bash
     odsc conda list --local
     ```
   - Para listar entornos **publicados**:
     ```bash
     odsc conda list --override
     ```
     *(Requiere tener configurado el bucket de Object Storage y `odsc conda init`)*

---

## 4. B√∫squeda avanzada

No existe un comando espec√≠fico de b√∫squeda en la CLI, pero pod√©s filtrar resultados combinando `odsc conda list` con utilidades como `grep`, `awk` o `perl`.

Ejemplo para obtener nombres y *slugs*:
```bash
odsc conda list | grep -E "name:|slug:"
```

---

## 5. Instalaci√≥n de entornos Conda

- **Instalar un entorno gestionado**:
  ```bash
  odsc conda install --slug <nombre-del-slug>
  ```
- **Instalar un entorno publicado**:
  ```bash
  odsc conda install --slug <nombre-del-slug> --override
  ```
  *(El par√°metro `--override` indica que se debe instalar desde entornos publicados en Object Storage, no desde los gestionados por OCI)*

---

## 6. Buenas pr√°cticas

- **Clonar antes de modificar**: evita romper un entorno funcional.
- **Publicar entornos estables**: facilita la colaboraci√≥n y el despliegue.
- **Usar nombres descriptivos en el slug**: mejora la b√∫squeda y el mantenimiento.
- **Documentar cambios**: registra librer√≠as a√±adidas o actualizadas.

---

# üß† Gesti√≥n avanzada de entornos Conda con `odsc` (Parte 2)

## 7. Clonar entornos Conda

La clonaci√≥n permite **copiar e instalar** un entorno Conda existente, creando una **nueva versi√≥n personalizada** sin modificar el original.

**Comando base:**
```bash
odsc conda clone --from <slug_origen> --env <nombre_nuevo_entorno>
```

- **`--from`**: *slug* del entorno Conda instalado que quer√©s clonar.
- **`--env`**: nombre del nuevo entorno.  
  Al asignarlo, OCI genera autom√°ticamente un nuevo *slug*.

üí° **Ventaja**: Ideal para probar cambios importantes sin arriesgar la estabilidad del entorno original.

---

## 8. Modificar un entorno Conda

Cuando quer√©s **instalar nuevas librer√≠as** o **actualizar versiones**, no se usa `odsc`, sino la herramienta est√°ndar `conda`.

**Pasos:**
8.1. Activar el entorno:
   ```bash
   conda activate /home/datascience/conda/<slug_entorno>
   ```
8.2. Realizar cambios. Ejemplo: actualizar ADS a la √∫ltima versi√≥n:
   ```bash
   python3 -m pip install oracle-ads --upgrade
   ```

üîπ Los cambios afectan **solo** al entorno activado.

---

## 9. Publicar un entorno Conda

Publicar un entorno lo **empaqueta y sube a un bucket de Object Storage**, permitiendo:
- Compartirlo con tu equipo.
- Usarlo en *jobs* y despliegues de modelos.
- Garantizar **reproducibilidad**.

**Preparaci√≥n:**
9.1. Crear un bucket en **Object Storage**.
9.2. Anotar:
   - **Namespace** del bucket.
   - **Nombre** del bucket.
9.3. Inicializar la configuraci√≥n (solo una vez por sesi√≥n):
   ```bash
   odsc conda init --bucket_namespace <namespace> --bucket_name <nombre_bucket>
   ```

**Publicar:**
```bash
odsc conda publish --slug <slug_entorno>
```

---

## 10. Eliminar un entorno Conda

Para liberar espacio:
```bash
odsc conda delete --slug <slug_entorno>
```

---

## 11. Crear un entorno Conda desde cero

Pod√©s crear un entorno nuevo usando un **archivo de manifiesto Conda** (`environment.yaml`).

**Comando:**
```bash
odsc conda create --file <ruta/environment.yaml>
```

- Por defecto, se instalan paquetes base desde `/opt/base-env.yaml` para compatibilidad con JupyterLab.
- Si quer√©s evitarlo:
  ```bash
  odsc conda create --file <ruta/environment.yaml> --empty
  ```
  ‚ö†Ô∏è No recomendado, ya que podr√≠a impedir que el entorno aparezca como kernel en JupyterLab.

---

## 12. Resumen de funcionalidades vistas

| Acci√≥n        | Comando principal                         | Uso t√≠pico |
|---------------|-------------------------------------------|------------|
| **Explorar**  | `odsc conda list`                         | Ver entornos disponibles |
| **Buscar**    | `odsc conda list | grep ...`               | Filtrar por nombre o slug |
| **Instalar**  | `odsc conda install --slug ...`            | A√±adir entornos gestionados o publicados |
| **Clonar**    | `odsc conda clone --from ... --env ...`    | Crear copia editable |
| **Modificar** | `conda activate ...` + `pip install ...`   | Actualizar librer√≠as |
| **Publicar**  | `odsc conda publish --slug ...`            | Compartir en Object Storage |
| **Eliminar**  | `odsc conda delete --slug ...`             | Borrar entornos |
| **Crear**     | `odsc conda create --file ...`             | Nuevo entorno desde YAML |

üìå **Resumen**:  
La CLI `odsc` es la herramienta m√°s potente para gestionar entornos Conda en OCI. Te permite no solo instalar y explorar, sino tambi√©n clonar, modificar, publicar y crear entornos personalizados, asegurando control total sobre tu infraestructura de ciencia de datos.



---
# 3.07 Lecci√≥n: üß† Demo: Gesti√≥n de entornos Conda con la CLI `odsc`

## 1. Introducci√≥n

En esta demostraci√≥n aprender√°s a **gestionar entornos Conda** usando la herramienta de l√≠nea de comandos `odsc` en **OCI Data Science**.  
Veremos c√≥mo:

- Explorar (*browse*)
- Buscar (*search*)
- Instalar (*install*)
- Clonar (*clone*)
- Modificar (*modify*)
- Publicar (*publish*)
- Eliminar (*delete*) entornos Conda
- Crear un entorno personalizado desde cero usando un archivo **YAML**

El comando principal que utilizaremos es:

```bash
odsc
```

Al ejecutar `odsc --help`, ver√°s varios subcomandos. En este caso, trabajaremos con el subcomando:

```bash
odsc conda
```

---

## 2. Subcomandos disponibles

Al listar la ayuda de `odsc conda`, encontrar√°s opciones como:

- `list` ‚Üí listar entornos
- `initialize` ‚Üí inicializar configuraci√≥n
- `show-configuration` ‚Üí mostrar configuraci√≥n actual
- `publish` ‚Üí publicar entornos
- `install` ‚Üí instalar entornos
- ‚Ä¶ entre otros

---

## 3. Explorando entornos Conda

### 3.1 Listar entornos gestionados por OCI
```bash
odsc conda list
```
Devuelve un archivo **YAML** con informaci√≥n detallada:
- **name** ‚Üí nombre del conda-pack
- **slug** ‚Üí identificador √∫nico
- **type** ‚Üí `dataScience` (gestionado por OCI)

### 3.2 Listar entornos instalados localmente
```bash
odsc conda list --local
```
- Muestra entornos instalados en la sesi√≥n de notebook.
- El campo **type** ser√° `local`.

### 3.3 Listar entornos publicados
```bash
odsc conda list --override
```
- Muestra entornos publicados en Object Storage.
- Requiere configuraci√≥n previa (`odsc conda init`).

---

## 4. B√∫squeda de informaci√≥n

El listado en YAML puede ser extenso. Para filtrar, combinamos `odsc conda list` con herramientas como `grep` y expresiones regulares.

Ejemplo: obtener solo nombres y slugs
```bash
odsc conda list | grep -E "name:|slug:"
```

Para buscar entornos relacionados con *Data Exploration*:
```bash
odsc conda list | grep -i "data exploration"
```

---

## 5. Instalaci√≥n de un entorno Conda

Ejemplo: instalar un entorno de *Data Exploration*:

1. Buscar el slug:
   ```bash
   odsc conda list | grep -i "data exploration"
   ```
2. Instalar:
   ```bash
   odsc conda install --slug <slug_encontrado>
   ```
3. El sistema pedir√° la versi√≥n a instalar.
4. Descargar√° y extraer√° el entorno.

Verificar instalaci√≥n:
```bash
odsc conda list --local | grep <slug>
```

---

## 6. Clonaci√≥n de un entorno Conda

Para modificar un entorno sin afectar el original:

```bash
odsc conda clone --from <slug_origen> --env "Mi Data Exploration"
```

- `--from`: slug del entorno original.
- `--env`: nombre del nuevo entorno (OCI generar√° un slug autom√°ticamente).
- El sistema pedir√° la versi√≥n y luego empaquetar√° e instalar√° la copia.

---

## 7. Flujo de trabajo t√≠pico en esta demo

1. **Listar** entornos gestionados (`odsc conda list`).
2. **Filtrar** por nombre o slug con `grep`.
3. **Instalar** el entorno deseado (`odsc conda install`).
4. **Verificar** instalaci√≥n (`odsc conda list --local`).
5. **Clonar** para personalizar (`odsc conda clone`).

---
# üß† Gesti√≥n avanzada de entornos Conda con `odsc` (Parte final del cap√≠tulo)

## 8. Verificar el *slug* del entorno clonado

Despu√©s de clonar un entorno Conda, es importante identificar su **slug** (identificador √∫nico).  
Para hacerlo:

```bash
odsc conda list --local | grep -E "name:|slug:"
```

- `--local` ‚Üí lista solo los entornos instalados en la sesi√≥n de notebook.
- `grep` ‚Üí filtra para mostrar √∫nicamente los campos `name` y `slug`.

---

## 9. Modificar un entorno Conda

Para modificar un entorno (a√±adir librer√≠as, cambiar versiones, etc.) **no** se usa `odsc conda`, sino la herramienta est√°ndar `conda`.

**Pasos:**
1. Activar el entorno:
   ```bash
   conda activate /home/datascience/conda/<slug_entorno>
   ```
2. Realizar cambios. Ejemplo: instalar la librer√≠a `pendulum`:
   ```bash
   python3 -m pip install pendulum
   ```
3. Desactivar el entorno:
   ```bash
   conda deactivate
   ```

üí° **Nota:** Los cambios afectan √∫nicamente al entorno activado.

---

## 10. Publicar un entorno Conda

Publicar un entorno lo empaqueta y lo sube a un **bucket de Object Storage**, permitiendo:
- Compartirlo con otros usuarios.
- Usarlo en *jobs* y despliegues de modelos.
- Garantizar reproducibilidad.

**Pasos:**
1. Crear un bucket en Object Storage (ej. `published-conda-environments`).
2. Anotar:
   - **Namespace** del bucket.
   - **Nombre** del bucket.
3. Inicializar la configuraci√≥n (solo una vez por sesi√≥n):
   ```bash
   odsc conda init --bucket_namespace <namespace> --bucket_name <nombre_bucket>
   ```
4. Publicar el entorno:
   ```bash
   odsc conda publish --slug <slug_entorno>
   ```

---

## 11. Verificar publicaci√≥n

Para confirmar que el entorno est√° publicado:
```bash
odsc conda list --override | grep -E "name:|slug:"
```
- `--override` ‚Üí lista entornos publicados en Object Storage en lugar de los gestionados por OCI.

En el bucket, la estructura ser√°:
```
Conda Environments/
   CPU/
      My Data Exploration/
         v1/
            <archivos del entorno>
```

---

## 12. Eliminar un entorno Conda

Para liberar espacio en la sesi√≥n de notebook:
```bash
odsc conda delete --slug <slug_entorno>
```
El sistema pedir√° confirmaci√≥n antes de eliminarlo.

---

## 13. Crear un entorno Conda desde un archivo YAML

Otra forma de crear un entorno es a partir de un **archivo de manifiesto Conda** (`environment.yaml`).

**Comando:**
```bash
odsc conda create --file <ruta/environment.yaml>
```

- Por defecto, se a√±aden paquetes base desde `/opt/base-env.yaml` para compatibilidad con JupyterLab.
- Para evitarlo:
  ```bash
  odsc conda create --file <ruta/environment.yaml> --empty
  ```
  ‚ö†Ô∏è No recomendado, ya que podr√≠a impedir que el entorno aparezca como kernel en JupyterLab.

---

üìå **Resumen**:  
Esta demo muestra c√≥mo usar `odsc conda` para explorar, buscar, instalar y clonar entornos Conda en OCI Data Science, combinando la potencia de la CLI con utilidades de filtrado como `grep` para trabajar de forma m√°s √°gil y precisa.


Resumen de operaciones vistas
| Acci√≥n        | Comando principal                         | Uso t√≠pico |
|---------------|-------------------------------------------|------------|
| **Listar**    | `odsc conda list`                         | Ver entornos disponibles |
| **Buscar**    | `odsc conda list | grep ...`               | Filtrar por nombre o slug |
| **Instalar**  | `odsc conda install --slug ...`            | A√±adir entornos gestionados o publicados |
| **Clonar**    | `odsc conda clone --from ... --env ...`    | Crear copia editable |
| **Modificar** | `conda activate ...` + `pip install ...`   | Actualizar librer√≠as |
| **Publicar**  | `odsc conda publish --slug ...`            | Compartir en Object Storage |
| **Eliminar**  | `odsc conda delete --slug ...`             | Borrar entornos |
| **Crear**     | `odsc conda create --file ...`             | Nuevo entorno desde YAML |


---
# 3.08 Lecci√≥n: üß† OCI Vault: Gesti√≥n segura de secretos y claves para Data Science

## 1. Introducci√≥n

En este m√≥dulo aprender√°s:

- Por qu√© es importante usar el servicio **OCI Vault** para compartir y proteger secretos.
- Conceptos clave como:
  - Tipos de claves.
  - Rotaci√≥n de claves.
  - Almacenamiento seguro de secretos en el Vault (en lugar de en tu c√≥digo).

---

## 2. ¬øQu√© es OCI Vault y por qu√© es importante?

En un flujo de trabajo de ciencia de datos, es habitual interactuar con otros servicios para:

- Conectarse a datos importantes.
- Almacenar y recuperar artefactos.
- Importar y exportar informaci√≥n.

Muchas de estas interacciones requieren **credenciales** (usuarios, contrase√±as, tokens, certificados).

**Mejor pr√°ctica de seguridad:**  
Nunca almacenar credenciales localmente o en el c√≥digo, ya que es una de las formas m√°s comunes de filtraci√≥n.  
En su lugar, se recomienda usar un servicio especializado: **OCI Vault**.

---

## 3. Funcionalidad principal de OCI Vault

- Servicio **gestionado por Oracle** para administrar de forma centralizada:
  - **Claves de cifrado**.
  - **Credenciales** y secretos.
- Soporta tres algoritmos de cifrado:
  - **AES** (Advanced Encryption Standard)
  - **RSA** (Rivest‚ÄìShamir‚ÄìAdleman)
  - **ECDSA** (Elliptic Curve Digital Signature Algorithm)
- Integraci√≥n con:
  - **OCI SDK**
  - **CLI de OCI**
  - **Clientes API**
  - **ADS SDK** (con m√∫ltiples puntos de integraci√≥n entre Data Science y otros servicios OCI)

Esto facilita almacenar credenciales en el Vault y conectarse a los recursos necesarios sin exponer datos sensibles en c√≥digo o archivos de configuraci√≥n.

---

## 4. Elementos principales del servicio

- **Vaults**: contenedores l√≥gicos para almacenar claves y secretos.
- **Keys**: entidades l√≥gicas que representan una o m√°s versiones de material criptogr√°fico.
- **Secrets**: credenciales o datos sensibles cifrados.

El Vault elimina la necesidad de guardar claves y secretos en archivos de configuraci√≥n o en el c√≥digo.

---

## 5. Mejores pr√°cticas

Tanto ingenieros DevOps como cient√≠ficos de datos deber√≠an usar el Vault para **mejorar la postura de seguridad** de sus aplicaciones y servicios.

---

## 6. Tipos de Vault

Al crear un Vault, se puede elegir entre:

### üîπ Virtual Private Vault
- Partici√≥n dedicada en un **HSM** (*Hardware Security Module*).
- Hasta **1.000 versiones de claves**.
- Mejor aislamiento.
- Permite **copias de seguridad** en Object Storage.
- Soporta **recuperaci√≥n ante desastres** y **replicaci√≥n entre regiones**.

### üîπ Vault en partici√≥n compartida (opci√≥n por defecto)
- Comparte la partici√≥n HSM con otros clientes de Oracle.
- Seguridad garantizada, pero sin funciones avanzadas como backup a Object Storage.
- **Menor coste**: se cobra solo por el n√∫mero de claves, versiones y secretos almacenados.

---

## 7. ¬øQu√© son las claves (*Keys*)?

- Entidades l√≥gicas que representan una o m√°s versiones de material criptogr√°fico.
- El material criptogr√°fico se genera para un algoritmo espec√≠fico (AES, RSA o ECDSA).
- Se utilizan para:
  - **Cifrar datos**.
  - **Firmar digitalmente** informaci√≥n.


---

# üîê OCI Vault ‚Äì Tipos de claves, rotaci√≥n y gesti√≥n de secretos

## 8. T√©cnicas de cifrado y descifrado

Las tecnolog√≠as de cifrado utilizan distintos enfoques:

- **AES** ‚Üí Cifrado sim√©trico: la misma clave puede cifrar y descifrar los datos.
- **RSA** y **ECDSA** ‚Üí Cifrado asim√©trico: una clave cifra y la otra descifra.

---

## 9. Tipos de claves en OCI Vault

En el servicio Vault existen tres tipos conceptuales de claves:

### 9.1 Master Encryption Key (Clave maestra de cifrado)
- Claves que cre√°s o import√°s en tu Vault.
- Defin√≠s:
  - Algoritmo de cifrado (AES, RSA, ECDSA).
  - Forma de la clave (*key shape*): n√∫mero de bits (AES/RSA) o ID de curva el√≠ptica (ECDSA).

### 9.2 Data Encryption Key (Clave de cifrado de datos)
- Generadas a partir de una clave maestra.
- Se cifran din√°micamente con la clave maestra (**envelope encryption**).
- Permiten:
  - Usar m√∫ltiples claves para distintos datos.
  - Rotar claves sin afectar todo el sistema.
  - Reducir el impacto si una clave se ve comprometida (solo afecta a los datos cifrados con ella).

### 9.3 Wrapping Keys
- Usadas para proteger (envolver) otras claves durante su transporte o almacenamiento.

---

## 10. Uso de claves en servicios OCI

Servicios como **Block Storage** o **File Storage** pueden:
- Usar claves gestionadas por Oracle.
- Usar claves maestras personalizadas desde tu Vault.

Ejemplo: un bucket de Object Storage o un volumen de bloque puede usar una clave de cifrado de datos espec√≠fica.

---

## 11. Rotaci√≥n de claves maestras

- Cada clave tiene una **versi√≥n** asignada al crearse.
- Al rotar:
  - Se genera autom√°ticamente una nueva versi√≥n.
  - O pod√©s importar otra clave.
- **Mejor pr√°ctica**: rotar peri√≥dicamente para limitar la cantidad de datos cifrados con una misma versi√≥n.
- El Vault usa el **OCID** de la versi√≥n anterior para descifrar datos cifrados con ella.
  - Versiones antiguas ‚Üí ya no cifran, pero s√≠ pueden descifrar.

---

## 12. Componentes clave del servicio Vault

1. **Keys** ‚Üí Claves de cifrado.
2. **HSM** (*Hardware Security Module*) con certificaci√≥n **FIPS 140-2 Nivel 3**.
3. **Secrets** ‚Üí Datos sensibles como contrase√±as, tokens o credenciales.

---

## 13. Gesti√≥n de secretos

- **Qu√© son**: credenciales necesarias para acceder a servicios OCI o aplicaciones externas.
- **Ventajas de almacenarlos en Vault**:
  - Mayor seguridad que en c√≥digo o archivos de configuraci√≥n.
  - Recuperaci√≥n bajo demanda.
  - C√≥digo m√°s robusto: si cambian las credenciales, solo se actualizan en Vault.
- **Funcionamiento**:
  - Guard√°s localmente el **OCID** del secreto.
  - El c√≥digo solicita las credenciales al Vault cuando las necesita.
  - Se usan y luego se descartan.
- **Control de acceso**:
  - M√°s f√°cil restringir acceso al secreto que al notebook.
- **Creaci√≥n de secretos**:
  - Desde la **Consola OCI**.
  - Program√°ticamente con **OCI SDK**, **CLI** o **REST API**.
- **Versionado**:
  - Cada secreto tiene un OCID √∫nico que no cambia.
  - Al rotar, se crea una nueva versi√≥n con el contenido actualizado.
  - Rotar peri√≥dicamente reduce el impacto de una posible exposici√≥n.

---

## Resumen del m√≥dulo

En este cap√≠tulo aprendiste:

OCI Vault es la herramienta centralizada para almacenar y gestionar claves y secretos de forma segura en OCI. Protege credenciales, evita filtraciones y se integra con m√∫ltiples servicios y SDKs, ofreciendo opciones de aislamiento y recuperaci√≥n seg√∫n las necesidades y presupuesto.

- Qu√© es el servicio **OCI Vault** y su importancia.
- Tipos de Vault y tipos de claves.
- Concepto de versiones y rotaci√≥n de claves.
- Gesti√≥n segura de secretos y credenciales.
- Por qu√© **no** almacenar credenciales en c√≥digo, sino en el Vault.


---
# 3.09 Lecci√≥n: üîê Gesti√≥n de cifrado y secretos en OCI: Oracle Managed Keys vs Customer Managed Keys

## 1. Introducci√≥n

En este m√≥dulo aprender√°s:

- Las distintas formas de gestionar el cifrado en OCI:
  - **Oracle Managed Keys** (claves gestionadas por Oracle).
  - **Customer Managed Keys** (claves gestionadas por el cliente).
- C√≥mo usar el **OCI SDK** para almacenar y recuperar secretos desde el Vault.
- Clases especializadas del **ADS SDK** dise√±adas para integrarse con el Vault y simplificar el acceso a recursos seguros en flujos de trabajo de ciencia de datos.

---

## 2. Cifrado en OCI

OCI utiliza cifrado en m√∫ltiples puntos del servicio.  
Al trabajar con recursos, se te pedir√° elegir entre:

- **Oracle Managed Keys** ‚Üí Claves maestras gestionadas por Oracle en su Vault interno.
- **Customer Managed Keys** ‚Üí Claves maestras almacenadas en tu propio Vault.

### 2.1 Oracle Managed Keys
- Por defecto, OCI cifra y descifra datos usando claves maestras gestionadas por Oracle.
- Ejemplo: al aprovisionar un **Block Volume**, **Object Storage Bucket** o un **OKE Cluster**, Oracle usa una de sus claves maestras para generar la **Data Encryption Key** que cifrar√° los datos.

### 2.2 Customer Managed Keys
- La clave maestra est√° en tu Vault.
- Se usa para generar las **Data Encryption Keys**.
- Aunque no uses el Vault, **todos los datos en reposo (data at rest)** en OCI est√°n cifrados por defecto y no se puede desactivar.
- Obligatorio en ciertos contextos, como **Security Zones**, donde no se permite usar claves gestionadas por Oracle.

üí° **Nota**: *Customer Managed Key* no es lo mismo que *Bring Your Own Key (BYOK)*.  
En este caso, la clave puede haber sido:
- Importada previamente a tu Vault.
- Generada directamente por el servicio Vault.

En ambos casos:
- La clave es tuya.
- Gestion√°s su rotaci√≥n.
- Sos responsable de su ciclo de vida.

---

## 3. Recursos que requieren elecci√≥n de tipo de clave

- Block Volumes y Boot Volumes.
- File Systems.
- Object Storage.
- Kubernetes Secrets (OKE).
- Autonomous Container Databases.
- OCI Streaming Pools.
- Y m√°s.

---

## 4. Configuraci√≥n de una Customer Managed Key

1. Seleccionar la opci√≥n **Customer Managed Key**.
2. Localizar tu Vault.
3. Elegir la clave maestra que deseas usar.
4. Esa clave generar√° las **Data Encryption Keys** que cifrar√°n los datos.

---

## 5. Trabajo con secretos en Python

### 5.1 Opciones
- **OCI SDK**:
  - API general para trabajar con el Vault.
  - Muy potente, pero m√°s compleja.
  - No est√° pensada espec√≠ficamente para flujos de trabajo de ciencia de datos.
- **ADS SDK**:
  - Clases adaptadas a Data Science.
  - M√°s simple para casos de uso comunes de cient√≠ficos de datos.

---

## 6. Ejemplo: creaci√≥n y almacenamiento de credenciales

**Problema com√∫n**: credenciales almacenadas en c√≥digo o archivos de configuraci√≥n ‚Üí inseguro y dif√≠cil de mantener.

**Ejemplo motivador**: credenciales para conectarse a una **Autonomous Database** (o cualquier base de datos).

6.1. Crear un diccionario Python con:
   - Nombre de la base de datos.
   - Usuario.
   - Contrase√±a.
   ```python
   credentials = {
       "dbname": "...",
       "username": "...",
       "password": "..."
   }
   ```

6.2. **Vault y clave ya creados**.

6.3. **Codificaci√≥n Base64**:
   - No se puede almacenar un objeto binario (diccionario Python) directamente en el Vault.
   - Convertir a JSON y luego codificar en Base64.
   - Usar `Base64SecretContentDetails`.

6.4. **Creaci√≥n del objeto de detalles del secreto**:
   - Incluir:
     - Compartment OCID.
     - Vault ID.
     - Key ID.
     - Descripci√≥n.
     - Nombre del secreto.
     - Contenido codificado en Base64.

---

## 7. Almacenamiento del secreto en el Vault

7.1. Cargar configuraci√≥n OCI:
   ```python
   config = oci.config.from_file()
   ```
7.2. Crear cliente de Vault:
   ```python
   vault_client = oci.vault.VaultsClient(config)
   ```
7.3. Usar `vaults_client_composite_operations` para:
   - Llamar a `create_secret_and_wait_for_state`.
   - Pasar el objeto de detalles del secreto.
   - Esperar hasta que el estado sea **ACTIVE**.

---

# üîê Recuperaci√≥n de secretos y uso del ADS SDK con OCI Vault

## 8. Recuperar secretos desde el Vault con OCI SDK

Para recuperar secretos almacenados en el Vault usando el **OCI SDK**:

8.1. **Cliente de secretos**:
   - Usar la clase `SecretsClient`.
   - Requiere el objeto de configuraci√≥n (`config`) que ya cargamos previamente.

8.2. **M√©todo principal**:
   - `get_secret_bundle(secret_ocid)` ‚Üí devuelve un **response object**.

8.3. **Estructura de acceso**:
   - `response.data` ‚Üí devuelve un **secret bundle**.
   - `secret_bundle_content` ‚Üí contiene el objeto con el contenido codificado en Base64.
   - `content` ‚Üí el valor real del secreto en Base64.

8.4. **Decodificaci√≥n**:
   - Crear un m√©todo auxiliar que:
     - Decodifique Base64.
     - Convierta el JSON resultante en un diccionario Python.

**Flujo resumido**:
```python
# 1. Crear cliente de secretos
secret_client = oci.secrets.SecretsClient(config)

# 2. Obtener el bundle
secret_bundle = secret_client.get_secret_bundle(secret_ocid)

# 3. Extraer y decodificar
decoded_secret = base64_to_dict(secret_bundle.data.secret_bundle_content.content)
```

---

## 9. Uso del ADS SDK para simplificar la gesti√≥n de secretos

El **ADS SDK** ofrece clases especializadas para almacenar y recuperar secretos en OCI Vault, pensadas para flujos de trabajo de ciencia de datos:

- **ADBSecretKeeper** ‚Üí Autonomous Database (incluye opci√≥n de almacenar el *wallet file*).
- **BDSSecretKeeper** ‚Üí OCI Big Data Service (HDFS, Hive, Kerberos).
- **MySQLDBSecretKeeper** ‚Üí Oracle MySQL Database.
- **AuthTokenSecretKeeper** ‚Üí Tokens de autenticaci√≥n (ej. Streaming, GitHub).

---

## 10. Ejemplo: MySQLDBSecretKeeper

### 10.1 Guardar credenciales
```python
from ads.secrets import MySQLDBSecretKeeper

# Crear objeto
keeper = MySQLDBSecretKeeper(
    vault_id="<Vault_OCID>",
    key_id="<Key_OCID>",
    credentials={
        "dbname": "...",
        "host": "...",
        "port": 3306,
        "username": "...",
        "password": "..."
    }
)

# Guardar en el Vault
keeper.save(name="MySQL_Creds", description="Credenciales MySQL de producci√≥n")
```

### 10.2 Recuperar credenciales (mejor pr√°ctica)
Usar un **context manager** para no dejar las credenciales en memoria m√°s tiempo del necesario:
```python
with MySQLDBSecretKeeper() as keeper:
    creds = keeper.load_secret(secret_ocid="<Secret_OCID>")
    # creds es un diccionario con las credenciales
```

---

## 11. Ventajas del ADS SDK frente al OCI SDK puro

- **Menos c√≥digo**: guardar ‚Üí 2 l√≠neas, recuperar ‚Üí 1 l√≠nea.
- **Adaptado a casos de uso de Data Science**.
- **Soporte para m√∫ltiples servicios** (ADB, BDS, MySQL, tokens).
- **Manejo simplificado de formatos** (no requiere codificaci√≥n/decodificaci√≥n manual en Base64).

---

## 12. Resumen del m√≥dulo

En este cap√≠tulo aprendiste que:

- Entendiste la diferencia entre claves gestionadas por Oracle y por el cliente.
- Viste c√≥mo elegir y configurar una Customer Managed Key.
- Aprendiste a crear y almacenar credenciales seguras en el Vault usando Python y el OCI SDK.
- Los servicios que usan cifrado pueden tener su clave maestra gestionada por Oracle o por el cliente en su Vault.
- Las credenciales pueden convertirse de diccionario Python ‚Üí JSON ‚Üí Base64 y almacenarse en el Vault con el OCI SDK.
- El proceso con OCI SDK implica:
  - Crear `VaultsClient` y `SecretsClient`.
  - Usar `create_secret_and_wait_for_state` para almacenar.
  - Usar `get_secret_bundle` para recuperar.
  - Decodificar Base64 y reconstruir el diccionario.
- El **ADS SDK** simplifica enormemente este flujo con clases como `MySQLDBSecretKeeper`, `ADBSecretKeeper`, `BDSSecretKeeper` y `AuthTokenSecretKeeper`.


---

# 3.10 Lecci√≥n: üìÇ Sistemas de Control de Versiones en Ciencia de Datos (Parte 1)

## 1. Introducci√≥n

En este m√≥dulo veremos:

- Qu√© es un **sistema de control de versiones** (*Version Control System*, VCS).
- C√≥mo se utilizan en ciencia de datos.
- C√≥mo configurar uno y ejecutar comandos b√°sicos.

Los sistemas de control de versiones, tambi√©n llamados **sistemas de gesti√≥n de c√≥digo fuente** (*Source Code Management Systems*), permiten gestionar distintas versiones de c√≥digo, documentos, datos, an√°lisis y otros recursos similares.  
Aunque fueron creados para el desarrollo de software tradicional, los cient√≠ficos de datos los han adoptado para gestionar y versionar sus an√°lisis.

---

## 2. Uso en ciencia de datos

Ejemplo:  
Los usuarios de ciencia de datos utilizan sistemas de control de versiones para **rastrear las distintas versiones de sus notebooks de JupyterLab**. Esto facilita:

- Gestionar cambios.
- Compartir trabajo con otros.
- Mantener un historial de versiones.

Existen m√∫ltiples sistemas de repositorios: CVS, Bazaar, Subversion, Perforce, CodeCommit, Mercurial, Helix Core, entre otros.  
Sin embargo, **Git** es el m√°s popular y est√° integrado en el **OCI Data Science Service**, por lo que este m√≥dulo se centrar√° casi exclusivamente en Git.

---

## 3. Qu√© entendemos por ‚Äúc√≥digo‚Äù

En este contexto, ‚Äúc√≥digo‚Äù se refiere a **cualquier recurso que se rastree en un sistema de control de versiones**:

- C√≥digo fuente.
- Documentos.
- Informes.
- Datos recopilados.
- An√°lisis estad√≠sticos o de machine learning.
- Otros productos de trabajo.

---

## 4. Concepto de repositorio

Un sistema de control de versiones puede gestionar m√∫ltiples recursos, cada uno en un **repositorio** independiente.

üì¶ **Analog√≠a**:  
- El repositorio es como un **archivo o gabinete** que contiene un proyecto o an√°lisis.
- Cada repositorio mantiene un **historial de cambios** del c√≥digo base.

---

## 5. Funciones clave de un repositorio

- **Almacenamiento central** del c√≥digo.
- **Versionado**: seguimiento de versiones de desarrollo y de lanzamiento.
- **Colaboraci√≥n**: integraci√≥n de cambios de varios usuarios (*merge*).
- **Historial**: archivo de estados previos del c√≥digo y documentaci√≥n.
- **Ramas (branches)**: copias independientes del c√≥digo para trabajar en paralelo.
- **Commits**: puntos de guardado que permiten volver a un estado anterior.

Ejemplo:  
- Cre√°s un modelo de ML que funciona ‚Üí lo **commite√°s**.
- Prob√°s una mejora ‚Üí falla ‚Üí revert√≠s al commit anterior.

---

## 6. Tipos de sistemas de control de versiones

### üîπ Centralizados
- Un servidor central recibe todos los cambios.
- Ventajas: f√°cil de configurar, control administrativo.
- Ejemplos: Subversion, CVS, Perforce.

### üîπ Distribuidos
- No dependen de un √∫nico servidor.
- Cada desarrollador clona el repositorio completo en su m√°quina.
- Ventajas:
  - Trabajar sin conexi√≥n.
  - Mayor flexibilidad.
  - Creaci√≥n r√°pida de ramas.
  - Sin punto √∫nico de fallo.
- Ejemplos: Git, Bazaar, Mercurial.

---

## 7. Uso en ciencia de datos

Para un cient√≠fico de datos, un sistema distribuido como Git permite:

- Crear repositorios locales sin pedir permisos en un servidor central.
- Trabajar y analizar datos localmente.
- Archivar el repositorio al finalizar el proyecto.

**Limitaci√≥n**:  
En colaboraci√≥n, cada persona debe configurar su sistema para compartir cambios con cada otro miembro, lo que no escala bien en equipos grandes.

---

# üìÇ Sistemas de Control de Versiones en Ciencia de Datos (Parte 2)

## 8. Configuraci√≥n h√≠brida en sistemas distribuidos

Para evitar la complejidad de que cada miembro de un equipo se conecte con todos los dem√°s, normalmente se configura **un nodo central** al que todos env√≠an (*push*) sus cambios.  
Cuando alguien quiere las √∫ltimas actualizaciones, las descarga (*pull*) desde ese nodo.

En la pr√°ctica, los sistemas de control de versiones distribuidos no siempre funcionan de forma totalmente distribuida.  
Muchos equipos optan por un **modelo h√≠brido**: por ejemplo, usar Git (distribuido) pero con un servidor central para compartir.

---

## 9. Uso de Git en el flujo de trabajo de ciencia de datos

**Git** permite:

- Rastrear cambios en un conjunto de archivos.
- Revertir a versiones anteriores.
- Versionar no solo c√≥digo, sino tambi√©n:
  - Notebooks de JupyterLab.
  - Informes.
  - Otros productos de trabajo.

En equipos, un repositorio compartido permite que cada miembro contribuya y fusione (*merge*) sus cambios.  
Esto es clave para proyectos de ciencia de datos y construcci√≥n de modelos.

---

## 10. Ventajas de Git como sistema distribuido

- **Velocidad**: la mayor√≠a de operaciones son locales.
- **Trabajo offline**: solo se necesita conexi√≥n para *push* o *pull*.
- **Tolerancia a fallos**: incluso con un servidor central, se puede compartir directamente entre compa√±eros si el servidor cae.

---

## 11. Extensi√≥n de Git en OCI Data Science

OCI Data Science integra una **extensi√≥n de Git en JupyterLab**:

- Interfaz gr√°fica amigable.
- Acceso desde el √≠cono de Git o el men√∫ Git.
- Funciones:
  - Crear o clonar repositorios.
  - *Push* y *pull*.
  - *Stage* de cambios para commit.
  - Comparar versiones.
- Compatible con:
  - GitHub
  - Bitbucket
  - GitLab
  - OCI Code Repository
  - Instalaciones propias de Git

---

## 12. Terminolog√≠a b√°sica en Git

- **Commit**: instant√°nea del estado actual del c√≥digo.
  - Identificado por un **SHA ID** (hash √∫nico de 40 caracteres).
  - Puede tener etiquetas (*tags*) legibles.
- **Repositorio (repo)**: directorio que contiene todos los cambios de un proyecto.
  - Local o remoto.
  - Colecci√≥n de commits.
- **√Årea de trabajo (working area)**:
  - Archivos de la versi√≥n actual en la que trabaj√°s.
  - En notebooks, se almacenan en el **block storage local**.
- **Staging**:
  - Paso previo al commit.
  - Indica a Git qu√© archivos modificados se incluir√°n en la nueva versi√≥n.

---

## 13. Flujo de trabajo de un commit en Git

1. **√Årea de trabajo**: crear o modificar archivos.
2. **Staging**: seleccionar qu√© cambios incluir.
3. **Commit**:
   - Guardar cambios en el repositorio.
   - A√±adir un comentario descriptivo.
   - Registrar autor y fecha.
4. **Compartir**:
   - *Push* ‚Üí enviar cambios a otro repositorio/peer.
   - *Pull* ‚Üí traer cambios de otro repositorio/peer.

üí° **Buenas pr√°cticas**:
- Hacer commits frecuentes y peque√±os.
- No incluir en *staging* archivos irrelevantes o que no deban ser rastreados.

---

## 14. OCI Code Repository

- Servicio similar a GitHub o Bitbucket, pero integrado en OCI.
- Funciona como **peer central**.
- Integrado con el sistema de **Identity and Access Management (IAM)** de OCI.
- Permite:
  - Commits.
  - Actualizaciones.
  - Creaci√≥n de ramas (*branches*).
  - Control de acceso seguro.

---

# üìÇ Sistemas de Control de Versiones en Ciencia de Datos (Parte 3)

## 15. Gesti√≥n y visualizaci√≥n de repositorios en OCI

- En la **consola de OCI** pod√©s ver:
  - El **almacenamiento** utilizado por cada repositorio.
  - El **OCID** asignado a cada repo al crearlo.
- Con ese OCID pod√©s:
  - Editar el contenido.
  - Clonar el repo a otro peer.
  - Eliminar repos que ya no necesites.
  - Ver el historial de cambios y commits.
  - Navegar por ramas (*branches*).
  - Consultar el tama√±o del repositorio.

---

## 16. Trabajo con repositorios remotos y externos

En **OCI Data Science** pod√©s trabajar con repositorios remotos como:

- GitLab
- Bitbucket
- Tus propios repos Git

Tambi√©n pod√©s **conectar repos externos** (ej. GitHub) al **OCI Code Repository**.  
La conexi√≥n incluye:
- Tipo (GitHub, GitLab, etc.).
- Nombre.
- Referencia a un **secreto en OCI Vault** que almacena el *personal access token* de tu cuenta.

üí° **Ventaja**:  
Una vez definida la conexi√≥n, los cambios en tu repo de GitHub se **replican autom√°ticamente** en el OCI Code Repository.

---

## 17. Permisos y pol√≠ticas

Para dar acceso a repos y otros recursos, deb√©s crear **pol√≠ticas IAM**.  
Con un repositorio OCI o externo, pod√©s:

- Clonarlo v√≠a **HTTPS** o **SSH keys**.
- Crear una copia local.
- Agregar o eliminar archivos.
- Hacer commits.
- Trabajar con ramas y operaciones t√≠picas de GitHub.

---

## 18. Git vs GitHub

- **Git** ‚Üí Sistema de control de versiones.
- **GitHub** ‚Üí Servicio en la nube que aloja proyectos Git.

---

## 19. Conexi√≥n mediante SSH

- **SSH** permite conectar y autenticarte a servidores remotos sin ingresar usuario/token cada vez.
- Pasos:
  1. Instalar y configurar Git (nombre y email).
  2. Crear cuenta en GitHub (si no la ten√©s).
  3. Generar un **par de claves SSH** (privada y p√∫blica).
  4. Agregar la clave p√∫blica a GitHub.
  5. Autenticar tu repo local con GitHub.

---

## 20. Flujo b√°sico de trabajo con Git y GitHub

1. Tener un repo local y uno remoto (GitHub).
2. Si empez√°s de cero:
   - Crear repo vac√≠o en GitHub.
   - Clonarlo en tu notebook:
     ```bash
     git clone <URL>
     ```
3. Crear/modificar archivos.
4. Hacer commit en el repo local.
5. Hacer push al repo remoto para compartir cambios.

---

## 21. Comandos b√°sicos de Git

| Comando         | Funci√≥n |
|-----------------|---------|
| `git init`      | Inicializa un nuevo repo o convierte un directorio existente en repo Git. |
| `git clone`     | Crea una copia local de un repo remoto y los vincula. |
| `git add`       | A√±ade archivos al *staging area* para el pr√≥ximo commit. |
| `git commit`    | Guarda una instant√°nea de los archivos en *staging*. |
| `git remote`    | Gestiona conexiones entre repos locales y remotos. |
| `git fetch`     | Descarga commits y datos del repo remoto sin fusionar. |
| `git push`      | Sube commits locales al repo remoto. |
| `git pull`      | Descarga y fusiona cambios del repo remoto al local. |

---

## 22. Resumen del m√≥dulo

En este cap√≠tulo vimos:

- Qu√© es un sistema de control de versiones y sus tipos (centralizado y distribuido).
- Definici√≥n y usos de un repositorio de c√≥digo.
- Importancia del control de versiones en ciencia de datos.
- Extensi√≥n de Git en JupyterLab.
- Terminolog√≠a clave: commit, repo, √°rea de trabajo, staging.
- OCI Code Repository y su integraci√≥n con repos externos como GitHub.
- Pasos para configurar un repo remoto.
- Comandos esenciales de Git.



---
---
# 3.11 Lecci√≥n: üìÇ Demo: Creaci√≥n y uso de un repositorio Git local y remoto en GitHub

## 1. Objetivo de la demo
El objetivo de esta demostraci√≥n es:

- Crear un nuevo repositorio Git local.  
- Hacer commits de archivos en el repositorio.  
- Conectar con un repositorio en GitHub.  
- Enviar (*push*) y recibir (*pull*) archivos entre ambos.  

---

## 2. Configuraci√≥n inicial de Git

1. Abrir una terminal.  
2. Git ya est√° instalado, solo hay que configurarlo:  
   ```bash
   git config user.name "Tu Nombre"
   git config user.email "tu_email@ejemplo.com"
   ```
   - Esto permite que cada commit registre qui√©n lo realiz√≥.  
3. Verificar configuraci√≥n:  
   ```bash
   git config --list
   ```

---

## 3. Crear un repositorio local

1. En el explorador de archivos ‚Üí **Nuevo Folder** ‚Üí nombrarlo `demo`.  
2. En JupyterLab ‚Üí √≠cono de Git ‚Üí **Initialize Repository**.  
3. Ahora el directorio es un repositorio Git local.  

---

## 4. Autenticaci√≥n con GitHub mediante SSH

GitHub requiere autenticaci√≥n para hacer *push*. Esto se hace con un **par de claves SSH**.

1. Generar clave SSH:  
   ```bash
   ssh-keygen -t rsa -C "tu_email@ejemplo.com"
   ```
   - Se crean dos archivos:  
     - **Clave privada** (mantener en secreto).  
     - **Clave p√∫blica** (se puede compartir).  

2. Copiar la clave p√∫blica al portapapeles.  

3. Iniciar el agente SSH:  
   ```bash
   eval "$(ssh-agent -s)"
   ssh-add -k ~/.ssh/id_rsa
   ```

4. En GitHub ‚Üí **Settings ‚Üí SSH and GPG Keys ‚Üí New SSH Key** ‚Üí pegar la clave p√∫blica.  

---

## 5. Crear un repositorio en GitHub

1. En GitHub ‚Üí **New Repository** ‚Üí nombrarlo `demo`.  
2. Copiar la URL SSH (ejemplo: `git@github.com:usuario/demo.git`).  
3. En JupyterLab ‚Üí Git ‚Üí **Add Remote Repository** ‚Üí pegar la URL.  
4. Verificar conexi√≥n:  
   ```bash
   git remote -v
   ```

---

## 6. Flujo de trabajo: crear, trackear y commitear archivos

1. Crear un nuevo notebook (`File ‚Üí New ‚Üí Notebook`).  
2. Git lo mostrar√° como **Untracked**.  
3. Hacer clic derecho ‚Üí **Stage** para rastrearlo.  
4. Hacer commit:  
   - Mensaje: `"Initial Commit"`.  
   - Confirmar.  

---

## 7. Push al repositorio remoto

1. Configurar upstream (solo la primera vez):  
   ```bash
   git push --set-upstream origin master
   ```
2. Luego, simplemente:  
   ```bash
   git push
   ```

3. Verificar en GitHub ‚Üí el archivo y el mensaje de commit aparecen en el repo remoto.  

---

## 8. Ejemplo de actualizaci√≥n

1. Editar el notebook (ej. agregar c√°lculos).  
2. Guardar cambios.  
3. En la pesta√±a Git ‚Üí archivo aparece como **Changed**.  
4. Hacer **Stage** ‚Üí **Commit** (ej. mensaje `"some math"`).  
5. Hacer **Push to Remote**.  
6. Verificar en GitHub ‚Üí cambios reflejados.  

---

## 9. Resumen de la demo

En esta demostraci√≥n:

- Configuramos Git con nombre y correo.  
- Creamos un repositorio local.  
- Generamos un par de claves SSH y lo vinculamos a GitHub.  
- Creamos un repositorio en GitHub y lo enlazamos con el local.  
- Creamos un notebook, lo rastreamos, lo commiteamos y lo subimos a GitHub.  
- Finalmente, hicimos cambios, los volvimos a commitear y los sincronizamos con el remoto.  

---

üìå **Conclusi√≥n**:  
Este flujo demuestra c√≥mo **integrar Git y GitHub en un entorno de ciencia de datos con JupyterLab**, permitiendo versionar notebooks, colaborar y mantener sincronizados los repositorios locales y remotos.


---
---
# UNIDAD 4: Machine Learning Lifecycle  (CICLO DE VIDA APRENDIZAJE AUTOMATICO)
---
---

# üîÑ4.01 Lecci√≥n:  M√≥dulo Machine Learning Lifecycle  
## üìò Cap√≠tulo: ML Lifecycle Overview 

### 1. Introducci√≥n

Bienvenido al m√≥dulo sobre el ciclo de vida del aprendizaje autom√°tico (*Machine Learning Lifecycle*).  
Esta primera lecci√≥n ofrece una **visi√≥n general** del ciclo de vida de ML.  
Soy Wes Prichard, gerente principal de producto para Data Science y Servicios de IA en Oracle.

---

### 2. ¬øPor qu√© es importante el ciclo de vida de ML?

Las organizaciones buscan herramientas **vers√°tiles y productivas** para sus cient√≠ficos de datos, y desean que esas herramientas cubran **todo el ciclo de vida del aprendizaje autom√°tico**.  
Cuanto m√°s f√°cil y eficiente sea este ciclo, m√°s r√°pido y frecuentemente se podr√°n obtener resultados valiosos para la organizaci√≥n.

---

### 3. Las 6 etapas del ciclo de vida

Usaremos una versi√≥n simplificada del ciclo de vida, compuesta por **6 pasos**:

1. **Acceso a los datos**  
2. **Exploraci√≥n y preparaci√≥n de los datos**  
3. **Modelado** (construcci√≥n y entrenamiento del modelo)  
4. **Validaci√≥n del modelo**  
5. **Despliegue del modelo**  
6. **Monitoreo del modelo** (que puede llevar a su actualizaci√≥n o retiro)

üîπ Todo comienza con un **problema de negocio**, que define el objetivo del modelo.

---

### 4. Un proceso iterativo

Construir un modelo de ML es un proceso **iterativo**.  
Los pasos se repiten y ajustan hasta que el rendimiento del modelo sea satisfactorio.

üí° Existen representaciones m√°s complejas del ciclo de vida, como **CRISP-DM** (*Cross Industry Standard Process for Data Mining*), que pod√©s explorar por tu cuenta.  
Para este curso, usaremos el ciclo simplificado como marco para abordar las tareas clave del cient√≠fico de datos.

---

### 5. Acceso y adquisici√≥n de datos

Todo modelo de ML comienza con **datos**.  
En OCI Data Science, es √∫til almacenar los datos en la sesi√≥n de notebook para acceder r√°pidamente.

- El primer paso es **acceder y recopilar los datos** en el notebook.
- Conocer el **ecosistema de datos** de la organizaci√≥n ayuda a identificar fuentes potenciales.

#### Fuentes de datos comunes:
- **Sistemas de gesti√≥n de datos empresariales** (bases de datos, data lakes).
- **Pipelines de ingesti√≥n** desarrollados por ingenieros de datos y ML.
- **Datos no estructurados**: logs, texto, im√°genes, videos.
- **Cat√°logo de datos**: √∫til para localizar conjuntos existentes.
- **Fuentes externas**:
  - Datos p√∫blicos (gobiernos, open data).
  - Scraping web.
  - Proveedores de datos.
  - Encuestas, sensores, c√°maras, clickstream.

---

### 6. Exploraci√≥n y preparaci√≥n de datos

Una vez obtenidos los datos, el cient√≠fico de datos debe:

- **Explorar** y **visualizar** los datos.
- **Transformarlos** y repetir el proceso si es necesario.
- **Prepararlos**: limpieza y procesamiento antes del an√°lisis.

#### Tareas t√≠picas:
- Identificar y corregir datos corruptos, duplicados o incompletos.
- Determinar si los datos est√°n **etiquetados** (ej. im√°genes con bounding boxes).
- Si no lo est√°n, usar servicios como **OCI Data Labeling Cloud Service**.

---

### 7. An√°lisis exploratorio y estad√≠stico

Despu√©s de la limpieza, se analizan las **features** (variables):

- Identificar relaciones entre variables.
- Decidir transformaciones adicionales.
- Usar herramientas de an√°lisis estad√≠stico y visualizaci√≥n.

#### Preguntas clave:
- ¬øQu√© tipo de features hay?
- ¬øCu√°l es la distribuci√≥n de valores?
- ¬øHay valores nulos o inv√°lidos?
- ¬øExisten outliers?
- ¬øHay sesgos o correlaciones?
- ¬øEs necesario normalizar o transformar (ej. log)?
- ¬øC√≥mo manejar categor√≠as con cola larga?

---

### 8. Ingenier√≠a de features

Durante la exploraci√≥n, se pueden crear nuevas features que representen mejor los datos.

Ejemplo:  
En un dataset de tr√°fico con conteo por hora, pod√©s crear una feature que agrupe las horas en franjas como:

- Madrugada  
- Ma√±ana  
- Tarde  
- Noche  

Para features categ√≥ricas, suele ser necesario convertirlas en binarias (una por categor√≠a).

---

### 9. Modelado (inicio)

La etapa de modelado consiste en:

- Elegir el algoritmo de ML adecuado.
- Seleccionar las features que alimentar√°n el modelo.

üîπ En el primer paso, el cient√≠fico de datos debe decidir **qu√© tipo de modelo** es apropiado para resolver el problema planteado.

---

### 10. Tipos de aprendizaje autom√°tico

Existen dos tipos principales:

- **Aprendizaje supervisado**:  
  - El modelo aprende a partir de datos de entrada asociados a una **salida o etiqueta**.  
  - Ejemplos: clasificaci√≥n, regresi√≥n.

- **Aprendizaje no supervisado**:  
  - El modelo trabaja con datos **sin etiquetas**.  
  - Ejemplo: segmentaci√≥n de clientes ‚Üí el modelo asigna los segmentos autom√°ticamente.

---

### 11. Selecci√≥n de algoritmos y entrenamiento

- Se utilizan diferentes clases de modelos para problemas supervisados y no supervisados.
- Los cient√≠ficos de datos suelen probar **m√∫ltiples algoritmos** y generar **varios candidatos de modelos**.
- No se sabe de antemano cu√°l funcionar√° mejor ‚Üí se experimenta.

Durante el entrenamiento:

- Se prueban distintos **subconjuntos de features** como entrada.
- Reducir el n√∫mero de variables:
  - Disminuye el costo computacional.
  - Mejora la generalizaci√≥n.
  - Puede mejorar el rendimiento.

---

### 12. Divisi√≥n del conjunto de datos

- **Training set** ‚Üí para entrenar el modelo.  
- **Testing set** ‚Üí para evaluar el rendimiento en datos no vistos.

---

### 13. Evaluaci√≥n del modelo

Una vez entrenado, se debe evaluar su **idoneidad**.

- Hay herramientas open-source para calcular y visualizar m√©tricas.
- Elegir las m√©tricas adecuadas depende del **problema de negocio**.

#### Ejemplos:

- **Clasificaci√≥n**:
  - M√©trica com√∫n: **accuracy**.
  - Pero en casos como detecci√≥n de enfermedades raras, es mejor usar:
    - **Precisi√≥n** y **recall**.
    - **Matriz de confusi√≥n**: TP, TN, FP, FN.

- **Regresi√≥n**:
  - **RMSE** (error cuadr√°tico medio).
  - **MAE** (error absoluto medio).
  - **R¬≤** (coeficiente de determinaci√≥n).

- **No supervisado**:
  - Se busca que los **clusters** tengan alta cohesi√≥n interna.

---

### 14. Guardado de modelos

- Los modelos se guardan en formatos como:
  - **Pickle**
  - **ONNX**
  - **PMML**
- OCI Data Science ofrece un **cat√°logo de modelos** para preservarlos.

Seg√∫n el objetivo, el trabajo puede ser:

- Prueba de concepto.
- Experimentaci√≥n.
- Despliegue en producci√≥n.

---

### 15. Despliegue del modelo

Proceso de poner el modelo en uso.  
Tambi√©n se debe desplegar el **pipeline de transformaci√≥n de datos**.

- Los cient√≠ficos de datos colaboran con **ingenieros MLOps**.
- El despliegue puede ser:
  - **Batch**: inferencias programadas (ej. cada hora/d√≠a).
  - **Tiempo real**: activadas por eventos (ej. detecci√≥n de fraude en pagos).

#### Consideraciones:
- ¬øQu√© tan r√°pido se necesita la respuesta? ¬øMilisegundos o segundos?
- ¬øCu√°ntas solicitudes se esperan?
- ¬øQu√© tama√±o tienen los datos?

---

### 16. Monitoreo del modelo

Paso desafiante pero esencial para mantener la **eficacia** del modelo.

Dos componentes:

1. **Monitoreo estad√≠stico (drift)**:
   - Las m√©tricas pueden degradarse con el tiempo.
   - Ejemplo: valores fuera del rango del entrenamiento, cambios en la distribuci√≥n.

2. **Monitoreo operacional (ops)**:
   - Latencia de respuesta.
   - Uso de memoria y CPU.
   - Rendimiento y confiabilidad del sistema.
   - Logs y m√©tricas para diagn√≥stico.

---

### 17. Iteraci√≥n continua

El aprendizaje autom√°tico es un proceso **altamente iterativo**.  
Los pasos se repiten m√∫ltiples veces hasta alcanzar el objetivo de negocio.

---

### 18. Pr√≥ximas lecciones

En las siguientes lecciones, veremos c√≥mo **OCI Data Science** ayuda a los cient√≠ficos de datos a ejecutar cada etapa del ciclo de vida de ML.

---
# üì• 4.02 Lecci√≥n: Access Data ‚Äì üîç Acceso a datos en OCI Data Science

## 1. Introducci√≥n

Hola y bienvenido a la siguiente lecci√≥n del curso de Oracle Cloud Infrastructure Data Science.  
Soy Himanshu Raj, cient√≠fico de datos y l√≠der senior de entrenamiento en AI/ML en Oracle.

En esta lecci√≥n aprenderemos sobre el **primer paso del ciclo de vida del aprendizaje autom√°tico**:  
üëâ **Acceder a los datos**.

Tambi√©n veremos:

- Por qu√© necesitamos datos.
- C√≥mo se recopilan.
- Cu√°les son las fuentes clave para acceder a datos en OCI Data Science.

---

### 2. ¬øPor qu√© necesitamos datos?

Toda aplicaci√≥n o servicio, digital o no, **genera informaci√≥n**.  
Esta informaci√≥n puede clasificarse seg√∫n su tama√±o o fuente:

- **Datos por lotes (batch)**: generados con el tiempo por cargas diarias (ej. backups, migraciones).
- **Datos de servicios de streaming**: mensajes o logs de eventos de usuario e IoT.
- **Datos de aplicaciones**: generados por llamadas a APIs, eventos de aplicaciones, archivos de log, etc.

üîÅ Estos datos deben ser **tra√≠dos a OCI** para su preprocesamiento y entrenamiento de modelos.  
Pod√©s acceder a ellos desde la **interfaz gr√°fica** o desde la **l√≠nea de comandos** usando librer√≠as espec√≠ficas.

---

### 3. ¬øQu√© rol cumple el dato en ciencia de datos?

La ciencia de datos es una disciplina multidisciplinaria que necesita datos para:

- Formular hip√≥tesis y extraer conclusiones.
- Realizar investigaciones basadas en datos.
- Resolver problemas concretos.

üí° Preguntas clave:
- ¬øQu√© tipo de datos necesito para resolver este problema?
- ¬øCon los datos que ya tengo, puedo resolver problemas existentes?

---

### 4. Fuentes clave de datos en OCI Data Science

Estas son algunas de las fuentes m√°s comunes (aunque no las √∫nicas):

- **OCI Object Storage**
- **Almacenamiento local**
- **Oracle Autonomous Databases**
- **MySQL**
- **Amazon S3**
- **Endpoints HTTPS**
- **DatasetBrowser**
- **PyArrow**

---

### 5. Acceso a Oracle Object Storage

Para cargar un `DataFrame` desde Object Storage:

- Us√° el ejemplo proporcionado, reemplazando el nombre del bucket y archivo.
- Pod√©s autenticarte usando:
  - **API Key**
  - **Resource Principal** (usualmente en funciones serverless)

üîê El m√≥dulo `set_auth` permite habilitar o deshabilitar la identidad del principal o del par de claves en una sesi√≥n abierta.

üìö Para m√°s detalles, consult√° la documentaci√≥n de la clase ADS.

---

### 6. Acceso a almacenamiento local

Pod√©s acceder a archivos locales usando funciones como:

```python
pandas.read_csv("ruta/al/archivo.csv")
```

---

### 7. Acceso a Oracle Autonomous Databases

OCI Data Science soporta ambos servicios de Autonomous Database.

- Us√° `ads.read_sql`, que es **15 veces m√°s r√°pido** que `pandas.read_sql`.
- Esto se debe a que **evita el ORM** y est√° optimizado para bases de datos Oracle.

#### Si us√°s un wallet file:
- Defin√≠ los par√°metros de conexi√≥n y la ubicaci√≥n del wallet.
- Luego ejecut√° la consulta con `ads.read_sql`.

#### Si no us√°s wallet:
- Defin√≠ `hostname` y `port` en el diccionario `connection_parameters`.
- ‚ö†Ô∏è Esta opci√≥n est√° disponible solo en **ADS versi√≥n 2.5.6 o superior**.

üîê Se recomienda usar **bind variables** para evitar ataques de inyecci√≥n SQL.

üìâ El rendimiento puede verse afectado por factores como la red, latencia, etc.

### 8. Optimizaci√≥n del acceso a bases de datos

El **tiempo de respuesta** de una base de datos puede mejorar significativamente mediante:

- Uso de **√≠ndices**.
- Escritura de **consultas SQL eficientes**.

üîπ Aunque la red de OCI es muy r√°pida, factores como VPNs o topolog√≠as complejas pueden afectar el rendimiento.  
Es importante considerar el **tiempo necesario para acceder a los datos**.

---

### 9. Acceso a MySQL

Pod√©s seguir los mismos pasos que con Oracle Autonomous Database, pero:

- Deb√©s definir el motor como `"MySQL"`.
- Esta funcionalidad est√° disponible a partir de **ADS versi√≥n 2.5.6**.

Para guardar un `DataFrame` en MySQL:

```python
ads.to_sql(df, engine="MySQL", ...)
```

---

### 10. Acceso a Amazon S3

- Archivos p√∫blicos o privados de **Amazon S3** pueden ser accedidos v√≠a `pandas`.
- Para archivos privados, deb√©s pasar las **credenciales correctas** usando el diccionario `storage_options` de ADS.

---

### 11. Acceso v√≠a HTTP/HTTPS

Tambi√©n pod√©s acceder a datos desde **URLs** usando `pandas`:

```python
pd.read_csv("https://ejemplo.com/datos.csv")
```

---

### 12. Uso de DatasetBrowser

ADS incluye el m√©todo `DatasetBrowser` para acceder f√°cilmente a conjuntos de datos bien definidos desde bibliotecas de referencia como:

- **Seaborn**
- **Scikit-learn**
- **GitHub**

Pod√©s listar los datasets disponibles con:

```python
DatasetBrowser.list()
```

Y abrir uno espec√≠fico con:

```python
DatasetBrowser.open("nombre_dataset")
```

---

### 13. Acceso a datos con PyArrow y OCI FS

ADS tambi√©n permite editar y procesar datos grandes usando **PyArrow** a trav√©s de **OCI File Systems (OCI FS)**.

- OCI FS es un sistema de archivos Pythonic que:
  - Contiene informaci√≥n de conexi√≥n.
  - Permite operaciones t√≠picas de sistema de archivos.

---

### 14. Detecci√≥n de tipos sem√°nticos de datos

ADS detecta autom√°ticamente los **tipos sem√°nticos** al abrir un dataset:

- **Categ√≥ricos**: ej. color de ojos, talla de camisa.
- **Ordinales**: ej. nivel educativo (primaria, secundaria, universidad).
- **Continuos**: ej. altura, versiones de software.
- **Fechas y horas**: formato datetime.

Pod√©s inspeccionar los tipos con:

```python
df.feature_types
df.show_in_notebook()
```

---

### 15. Fuentes y formatos soportados por ADS

ADS soporta m√∫ltiples fuentes y formatos de datos en OCI Data Science.  
üìö Est√°n listados en la [documentaci√≥n oficial](https://docs.oracle.com/es-ww/iaas/Content/data-science/using/overview.htm)¬π.

üîπ No se soportan directamente:
- Archivos `.txt`, `.doc`, `.pdf`
- Im√°genes sin procesar
- Estructuras como `list`, `tuple`, `range`

Pero ADS incluye un **m√≥dulo de extracci√≥n de texto** para convertir `.PDF` o `.DOC` en texto plano.

---

### 16. Cierre de la lecci√≥n

Esperamos que esta lecci√≥n te haya sido √∫til para aprender c√≥mo acceder a datos desde fuentes comunes en Oracle Data Science.  
Este paso es esencial para iniciar cualquier flujo de trabajo de machine learning.

---

---

# üîç 4.03 Lecci√≥n: Data Exploration and Preparation  
## üìò Exploraci√≥n y preparaci√≥n de datos en OCI Data Science

### 1. Introducci√≥n

Hola y bienvenido a esta nueva lecci√≥n del curso de Oracle Cloud Infrastructure Data Science.  
Soy Himanshu Raj, cient√≠fico de datos y l√≠der de entrenamiento en AI/ML en Oracle.

En esta lecci√≥n abordaremos el **segundo paso del ciclo de vida del aprendizaje autom√°tico**:  
üëâ **Exploraci√≥n y preparaci√≥n de datos**.

Veremos:

- Por qu√© es necesario el preprocesamiento.
- Qu√© pasos incluye.
- Herramientas de transformaci√≥n de ADS.
- C√≥mo dividir los datos en conjuntos de entrenamiento, prueba y validaci√≥n.

---

### 2. ¬øPor qu√© preprocesar los datos?

Los datos reales suelen tener:

- Valores faltantes.
- Errores.
- Outliers.
- Formatos inconsistentes.

üîß Por eso, antes de buscar patrones, debemos **limpiar y transformar** los datos.

El preprocesamiento puede incluir varios pasos, seg√∫n el problema y el tipo de datos.  
üí° Es com√∫n que esta etapa sea la m√°s extensa del ciclo de vida de ML.

---

### 3. Operaciones b√°sicas sobre datos

Cuando los datos provienen de m√∫ltiples fuentes, debemos **combinarlos**.  
ADS permite realizar operaciones como:

- Agregar o eliminar filas/columnas.
- Filtrar.
- Concatenar vertical u horizontalmente.
- Unir por columnas o √≠ndices.

üìå Las operaciones de `pandas` tambi√©n se aplican a objetos `ADSData`.

---

### 4. Limpieza y validaci√≥n

Es importante verificar:

- Formatos y unidades.
- Convenciones de nombres.
- Tipos de datos.
- Valores nulos.
- Duplicados.
- Estad√≠sticas descriptivas.

---

### 5. Imputaci√≥n de valores faltantes

Los valores faltantes pueden deberse a errores humanos o t√©cnicos.  
Ejemplo: coordenadas GPS incorrectas por mal clima.

Opciones:

- ‚ùå Eliminar filas incompletas (no recomendado).
- ‚úÖ Imputar con:
  - Media o mediana (para datos num√©ricos).
  - Moda (para datos categ√≥ricos).

---

### 6. Codificaci√≥n de variables categ√≥ricas

- **Label Encoding** (`label_encoder`): convierte categor√≠as en n√∫meros.  
  ‚ö†Ô∏è No recomendable para datos ordinales.

- **One Hot Encoding**:
  - Convierte una columna categ√≥rica en varias columnas binarias.
  - Se puede hacer con `pandas.get_dummies()` o `fit_transform()`.

---

### 7. Detecci√≥n de outliers

Los outliers pueden ser errores o datos v√°lidos pero at√≠picos.

- Se detectan con:
  - Visualizaciones: scatterplot, boxplot.
  - Estad√≠sticas: desviaci√≥n est√°ndar, distribuci√≥n gaussiana.
  - Algoritmos de ML (supervisado o no supervisado).

üìå En aprendizaje no supervisado, se asume que los outliers son pocos y no siguen la misma tendencia.

---

### 8. Escalado de caracter√≠sticas

El escalado ajusta las variables a una misma escala.  
Es √∫til en algoritmos sensibles a distancias (ej. regresi√≥n).

- **Normalizaci√≥n (Min-Max)**: valores entre 0 y 1.
- **Estandarizaci√≥n**: media 0, desviaci√≥n est√°ndar 1 ‚Üí distribuci√≥n normal.

---

### 9. Reducci√≥n de dimensionalidad

La **dimensionalidad** es el n√∫mero de variables de entrada.

- Alta dimensionalidad = mayor costo computacional.
- Dos enfoques:
  - **Selecci√≥n de caracter√≠sticas**: elegir un subconjunto.
  - **Extracci√≥n de caracter√≠sticas**: crear nuevas variables a partir de las existentes.

---

### 10. Preprocesamiento de texto

Para datos textuales, se aplican t√©cnicas como:

- Vectorizaci√≥n.
- Eliminaci√≥n de stop words.
- Tokenizaci√≥n.
- POS tagging.
- Stemming y lematizaci√≥n.

---

### 11. Herramientas de transformaci√≥n en ADS

#### a. `suggest_recommendations`

- Detecta problemas en el dataset.
- Sugiere transformaciones.
- Pod√©s aceptar los cambios desde el men√∫.
- Luego se obtiene el dataset transformado con `get_transformed_dataset()`.

#### b. `auto_transform`

- Aplica todas las recomendaciones autom√°ticamente.
- Imputa valores faltantes.
- Elimina columnas altamente correlacionadas.
- Maneja clases desbalanceadas (upsampling/downsampling).
- Elimina claves primarias y columnas sin valor predictivo.

#### c. `visualize_transforms`

- Muestra visualmente las transformaciones aplicadas.
- Solo funciona con transformaciones autom√°ticas.

---

### 12. Ejemplo pr√°ctico

En un dataset de rotaci√≥n de empleados:

- ADS detecta tipos de datos.
- Sugiere transformaciones.
- Muestra correlaciones fuertes y desbalance de clases.
- Visualiza el flujo de transformaci√≥n.

üìå Los resultados var√≠an seg√∫n el dataset.

---

### 13. Divisi√≥n de datos

Dividir el dataset en:

- **Entrenamiento**
- **Prueba**
- **Validaci√≥n**

Permite evaluar la **generalizaci√≥n** del modelo.

Por defecto, ADS usa:

- 80% entrenamiento
- 10% prueba
- 10% validaci√≥n

üí° En datasets peque√±os, puede ser mejor usar 70% o 60% para entrenamiento.

---

### 14. Conclusi√≥n

Esta lecci√≥n cubri√≥:

- Preprocesamiento de datos reales.
- Herramientas de transformaci√≥n en ADS.
- Codificaci√≥n, imputaci√≥n, escalado y detecci√≥n de outliers.
- Divisi√≥n en conjuntos de entrenamiento, prueba y validaci√≥n.

---
# üß™ 4.04 Lecci√≥n: Demo de Preprocesamiento con ADS  
## üìò Ejemplo pr√°ctico en OCI Data Science

### 1. Introducci√≥n

En esta demo realizaremos un ejercicio pr√°ctico de preprocesamiento de datos usando **Accelerated Data Science (ADS)** en una sesi√≥n de notebook de OCI Data Science.

Usaremos el dataset **Employee Attrition**, que contiene:

- **1.470 filas**
- **36 caracter√≠sticas**:
  - 22 ordinales
  - 11 categ√≥ricas
  - 3 constantes

Las variables incluyen informaci√≥n demogr√°fica, nivel de compensaci√≥n, caracter√≠sticas del puesto, satisfacci√≥n laboral y m√©tricas de desempe√±o.  
üìâ El dataset est√° **desbalanceado**: hay menos empleados que se van que los que se quedan.

---

### 2. Carga del dataset

1. Se importan las librer√≠as necesarias, incluyendo ADS.
2. Se carga el `DataFrame` desde **Object Storage** usando el m√©todo de **resource principal**.
3. Se define el bucket, el namespace y se usa `DatasetFactory.open()` para acceder al dataset.
4. Se establece la **feature objetivo**: `attrition`.

---

### 3. Transformaciones sugeridas

#### a. `suggest_recommendations`

- Detecta problemas en el dataset.
- Muestra mensajes con variables afectadas, acciones sugeridas y c√≥digo para aplicarlas.

#### b. `auto_transform`

- Aplica autom√°ticamente todas las transformaciones recomendadas.
- Optimiza el dataset:
  - Imputa valores faltantes.
  - Elimina columnas altamente correlacionadas.
  - Maneja clases desbalanceadas.
  - Elimina claves primarias y columnas sin valor predictivo.

#### c. `visualize_transforms`

- Permite visualizar las transformaciones aplicadas.
- Muestra diferencias entre aplicar o no `auto_transform`.

---

### 4. Codificaci√≥n de variables categ√≥ricas

Ejemplo con la variable `job_function`:

- Se observan tres categor√≠as distintas.
- Se usa el codificador categ√≥rico de ADS:
  ```python
  from ads.dataset.labelencoder import LabelEncoder
  ```
- Las categor√≠as se transforman en valores num√©ricos.

---

### 5. Balanceo de clases

- Se realiza **upsampling** usando:
  ```python
  from ads.dataset.helper import upsample
  ```
- Se observa la repetici√≥n de muestras en la clase minoritaria (`attrition = yes`).
- Se comparan los conteos antes y despu√©s del balanceo.

---

### 6. Divisi√≥n del dataset

Una vez completadas las transformaciones:

- Se divide el dataset en:
  - **Entrenamiento** (80%)
  - **Prueba** (10%)
  - **Validaci√≥n** (10%)

üìå Estos valores pueden ajustarse seg√∫n el tama√±o del dataset.

---

### 7. Recursos adicionales

- Documentaci√≥n oficial de ADS  
- Laboratorios en GitHub: [oracle-samples/oci-data-science-ai-samples](https://github.com/oracle-samples/oci-data-science-ai-samples)¬π  
- Ejemplos de notebooks en la sesi√≥n de Data Science

---


# üìä 4.05 Lecci√≥n: Data Visualization and Profiling  
## üìò Visualizaci√≥n de datos y perfilado en OCI Data Science

### 1. Introducci√≥n

Hola, soy Jon Stanesby. En esta lecci√≥n aprenderemos sobre **visualizaci√≥n de datos** y **perfilado**.

La visualizaci√≥n de datos es una parte esencial de la **exploraci√≥n y an√°lisis de datos** en ciencia de datos moderna.  
Es uno de los primeros pasos para **extraer valor** de los datos, ya que permite identificar patrones y relaciones de forma r√°pida y accesible, incluso sin formaci√≥n t√©cnica especializada.

---

### 2. ¬øQu√© es Data Visualization (DV)?

DV es la **presentaci√≥n gr√°fica de los datos** para ilustrar hallazgos y explicar resultados.  
Es clave para:

- Analizar datos.
- Tomar decisiones basadas en datos.
- Comunicar patrones y relaciones de forma clara.

---

### 3. Herramientas de visualizaci√≥n modernas

Las herramientas de DV suelen:

- Conectarse con fuentes de datos (bases relacionales, cloud, on-premise).
- Ofrecer m√∫ltiples opciones de visualizaci√≥n.
- Sugerir autom√°ticamente el tipo de gr√°fico seg√∫n los datos.
- Integrar IA/ML para facilitar tareas a usuarios no t√©cnicos.
- Permitir acceso y colaboraci√≥n en toda la organizaci√≥n.
- Ofrecer flexibilidad entre control manual y automatizaci√≥n.

üîπ Busc√° herramientas con:
- Interfaz intuitiva (point & click, drag & drop).
- Capacidad de edici√≥n r√°pida.
- Visualizaci√≥n autom√°tica de datos.

---

### 4. Visualizaci√≥n inteligente con ADS

ADS ofrece herramientas de visualizaci√≥n **autom√°ticas y personalizables**:

- Detecta autom√°ticamente el tipo de datos.
- Genera gr√°ficos √≥ptimos para cada variable.
- Permite usar cualquier librer√≠a de visualizaci√≥n (Seaborn, Matplotlib, etc.).

#### Visualizaciones comunes en ADS:
- Estad√≠sticas resumen.
- Gr√°ficos de distribuci√≥n.
- Mapas de correlaci√≥n.
- Detecci√≥n de anomal√≠as (valores faltantes, alta cardinalidad).

---

### 5. M√©todos autom√°ticos en ADS

#### a. `corr` (correlaci√≥n)
- Calcula matrices de correlaci√≥n por tipo de variable:
  - **Continua-Continua**: coeficiente de Pearson (‚àí1 a 1).
  - **Continua-Categ√≥rica**: ratio de correlaci√≥n (0 a 1).
  - **Categ√≥rica-Categ√≥rica**: Cramer's V (0 a 1).

#### b. `show_in_notebook`
- Muestra una vista completa del dataset:
  - Tipo de problema (regresi√≥n, clasificaci√≥n binaria o multiclase).
  - N√∫mero de filas y columnas.
  - Tipos de features.
  - Visualizaciones por columna.
  - Mapa de correlaci√≥n.
  - Encabezado del dataset.

üìå Usa una muestra inteligente con 95% de confianza y 1% de intervalo.

#### c. `plot`
- Herramienta autom√°tica de gr√°ficos.
- Se define `x` (y opcionalmente `y`).
- ADS elige el tipo de gr√°fico seg√∫n los tipos de datos.

Ejemplos:

- `x = attrition` (categ√≥rica binaria) ‚Üí gr√°fico de barras.
- `x = edad` (continua) ‚Üí histograma.
- `x = categ√≥rica`, `y = continua` ‚Üí violin plot.
- `x = continua`, `y = continua` ‚Üí heatmap gaussiano + scatterplot.

---

### 6. Sistema de tipos de features

ADS extiende los `DataFrames` de Pandas para:

- Separar representaci√≥n f√≠sica vs significado de los datos.
- Almacenar propiedades y m√©todos por feature.
- Usar herencia m√∫ltiple para definir caracter√≠sticas.
- Validar y advertir sobre calidad de datos.

üìå `feature_plot`:
- Sobre una serie ‚Üí gr√°fico univariado.
- Sobre un `DataFrame` ‚Üí tabla con visualizaci√≥n por feature.

---

### 7. Visualizaci√≥n personalizada

ADS permite usar librer√≠as externas:

#### a. `call` method
- Permite definir tu propia rutina de visualizaci√≥n.

Ejemplos:

- `Seaborn.pairplot(df)` ‚Üí relaciones entre pares de features.
- `Matplotlib` ‚Üí gr√°ficos personalizados.
- Dataset de terremotos en California ‚Üí visualizaci√≥n geogr√°fica.

---

### 8. Conclusi√≥n

En esta lecci√≥n aprendiste a:

- Generar visualizaciones autom√°ticas con ADS.
- Personalizar gr√°ficos seg√∫n tus necesidades.
- Usar m√©todos como `corr`, `plot`, `feature_plot`, `show_in_notebook`.
- Integrar librer√≠as externas para visualizaci√≥n avanzada.

---

# üß† 4.06 Lecci√≥n: Model Training  
## üìò Entrenamiento de modelos en OCI Data Science

### 1. Introducci√≥n

Hola, soy Jon Stanesby. En esta lecci√≥n aprenderemos sobre el **entrenamiento de modelos**, una etapa cr√≠tica dentro de la fase de modelado del ciclo de vida del aprendizaje autom√°tico.

---

### 2. ¬øQu√© es el entrenamiento de modelos?

El entrenamiento de modelos construye la **mejor representaci√≥n matem√°tica** de las relaciones entre:

- Las **features** y la **etiqueta objetivo** (en aprendizaje supervisado).
- Todas las **features** (en aprendizaje no supervisado).

üîπ El proceso genera un **artefacto** que captura estos patrones.  
üîπ Se selecciona el **mejor algoritmo** considerando m√∫ltiples dimensiones.

---

### 3. Componentes del proceso de entrenamiento

#### a. Funci√≥n de puntuaci√≥n (`score function`)
- Indica qu√© tan bien se ajusta el modelo.
- Puede ser una funci√≥n de error o de m√°xima verosimilitud.

#### b. Funci√≥n de p√©rdida (`loss function`)
- Compara las predicciones del modelo con los valores reales.
- Calcula una **puntuaci√≥n de p√©rdida** como n√∫mero √∫nico.

üìä Ejemplo gr√°fico:
- Puntos verdes ‚Üí datos reales.
- L√≠nea negra ‚Üí predicciones.
- Flechas rojas ‚Üí error (p√©rdida).

#### c. Funci√≥n de actualizaci√≥n (`update function`)
- Ajusta los par√°metros del modelo en cada iteraci√≥n.

---

### 4. Frameworks y entornos de entrenamiento

En ciencia de datos, **open source** se refiere a c√≥digo libre y modificable.  
Los frameworks open source:

- Son accesibles.
- Tienen comunidades activas.
- Fomentan la innovaci√≥n y soluci√≥n de bugs.

üîπ OCI Data Science combina frameworks **propietarios de Oracle** y **open source**.  
üîπ Pod√©s instalar librer√≠as externas desde la terminal o iniciar con tu propio set de herramientas.

---

### 5. Formas de entrenar modelos en OCI

Pod√©s entrenar modelos de varias maneras:

- üß™ **Notebooks**: escribiendo y ejecutando c√≥digo Python en JupyterLab.
- ‚öôÔ∏è **Entornos Conda**: usando ADS, MLX o AutoML (veremos m√°s adelante).
- üßµ **Jobs**: se cubren en el m√≥dulo 4.

---

### 6. Conclusi√≥n

En esta lecci√≥n vimos:

- Qu√© es el entrenamiento de modelos.
- C√≥mo se representa matem√°ticamente la relaci√≥n entre variables.
- Qu√© funciones intervienen en el proceso.
- Qu√© frameworks y entornos se pueden usar.
- Qu√© opciones ofrece OCI para entrenar modelos.

---

# üöÄ 4.07 Lecci√≥n: Expert Tips: Training a ML model on OCI
## üìò Entrenamiento y escalado de modelos AML en Oracle Cloud

### 1. Introducci√≥n

¬°Felicitaciones por llegar tan lejos en el curso de ciencia de datos!
Soy Himanshu Raj, l√≠der senior de entrenamiento en AI/ML en Oracle.

En este video experto hablaremos sobre c√≥mo **entrenar y escalar modelos de aprendizaje autom√°tico (AML)** en Oracle Cloud Infrastructure (OCI).

---

### 2. Entrenamiento b√°sico de modelos AML

Pod√©s entrenar f√°cilmente un modelo AML usando **jobs** del servicio de ciencia de datos.

üîπ ¬øQu√© necesit√°s?

- C√≥digo fuente alojado en **GitHub**.
- Resultados almacenados en **OCI Object Storage**.
- Definir recursos y ejecuci√≥n con **ADS**:
  - Usando c√≥digo Python.
  - O mediante archivos **YAML**.

---

### 3. Entrenamiento distribuido en OCI

Para escalar horizontalmente y paralelizar tareas de entrenamiento en datasets grandes o cargas intensivas:

‚úÖ OCI Data Science permite **entrenamiento distribuido** con ayuda de ADS.

üîπ Frameworks soportados:

- **Dask**
- **PyTorch Distributed**
- **Horovod**
- **TensorFlow Distributed**

üìå Esto permite reducir tiempos de entrenamiento sin perder precisi√≥n.

---

### 4. Implementaci√≥n y comunidad

- Pod√©s usar **Docker** o **GitHub** para tus implementaciones.
- La documentaci√≥n oficial detalla c√≥mo configurar cada framework.
- Se recomienda compartir tus casos de uso en la comunidad **OU**.

---

### 5. AutoMLx en OCI

Tambi√©n cubrimos **AutoML** en el curso.

üîπ Te recomendamos explorar el paquete **AutoMLx**, disponible en el **conda pack** de OCI.

- AutoMLx proporciona un pipeline que:
  - Encuentra y ajusta autom√°ticamente el mejor modelo.
  - A partir de una tarea de predicci√≥n y un dataset de entrenamiento.

Pod√©s elegir el motor paralelo (`task` o `local`) usando la funci√≥n `INIT`.

---

### 6. Recursos y seguimiento

- Consult√° la documentaci√≥n de **ADS** y de las clases alias.
- Revis√° las **release notes** para estar al d√≠a con nuevas funcionalidades.
- Compart√≠ tus avances y dudas en la comunidad **OU**.

---

### 7. Conclusi√≥n

En esta lecci√≥n aprendiste:

- C√≥mo entrenar modelos AML en OCI usando jobs.
- C√≥mo escalar horizontalmente con entrenamiento distribuido.
- C√≥mo usar AutoMLx para automatizar el ajuste de modelos.
- D√≥nde encontrar documentaci√≥n y c√≥mo participar en la comunidad.

---

# ü§ñ 4.08 Lecci√≥n: AutoML en Accelerated Data Science (ADS)  
## üìò Construcci√≥n y entrenamiento automatizado de modelos en OCI

### 1. Introducci√≥n

Hola, soy John Stanesby. En esta lecci√≥n aprenderemos a construir y entrenar modelos usando **AutoML** en **Accelerated Data Science (ADS)**.

AutoML significa **aprendizaje autom√°tico automatizado**.  
Durante la fase de modelado del ciclo de vida de ML, se construyen m√∫ltiples modelos con distintos algoritmos y configuraciones de hiperpar√°metros.  
AutoML automatiza este proceso, optimizando el rendimiento y la precisi√≥n.

---

### 2. ¬øPor qu√© AutoML?

El aprendizaje autom√°tico requiere muchas **iteraciones y experimentaci√≥n**.  
Es raro obtener el modelo √≥ptimo en el primer intento.  
AutoML ayuda a:

- Elegir y refinar modelos.
- Ajustar hiperpar√°metros.
- Mejorar resultados sin intervenci√≥n manual.

---

### 3. Enfoques comunes de AutoML

#### a. Optimizaci√≥n bayesiana
- Usa modelos probabil√≠sticos para evaluar configuraciones.
- Ejemplo: **AutoSkLearn** con Random Forest y meta-aprendizaje.

#### b. Sistemas de recomendaci√≥n
- Basados en similitud con datasets previos.
- Usan **factorizaci√≥n matricial probabil√≠stica**.

#### c. Algoritmos evolutivos
- Ejemplo: **TPOT**, que optimiza pipelines con Scikit-learn.

üîπ Todos requieren m√∫ltiples iteraciones.  
üîπ Oracle AutoML usa un enfoque **no iterativo** m√°s eficiente.

---

### 4. Enfoque de Oracle AutoML

- Usa **meta-modelos proxy** para predecir el rendimiento de configuraciones.
- Evita el problema de **cold start** mediante meta-aprendizaje.
- Solo construye y ajusta el **mejor pipeline candidato**.

---

### 5. Ciclo completo sin escribir c√≥digo

AutoML permite ejecutar todo el ciclo de ML sin escribir c√≥digo:

- Entrena m√∫ltiples modelos.
- Ajusta hiperpar√°metros.
- Eval√∫a y compara resultados.

üîπ Mejora la productividad y reduce el tiempo de c√≥mputo.

---

### 6. Flujo t√≠pico de AutoML

1. Selecci√≥n de modelo.
2. Ajuste de hiperpar√°metros.
3. Selecci√≥n de features predictivas.
4. Evaluaci√≥n de generalizaci√≥n.

---

### 7. Etapas automatizadas por Oracle AutoML

#### a. Selecci√≥n de algoritmo
- Identifica el mejor algoritmo seg√∫n el dataset y la tarea.
- Usa meta-aprendizaje para predecir rendimiento.

#### b. Muestreo adaptativo
- Eval√∫a muestras desde subconjuntos hasta el dataset completo.
- Detecta desbalance de clases.
- Usa meta-aprendizaje para predecir rendimiento por muestra.

#### c. Selecci√≥n de caracter√≠sticas
- Elimina atributos irrelevantes, constantes o con alta cardinalidad.
- Genera rankings de features.
- Eval√∫a subconjuntos para determinar el √≥ptimo.

#### d. Ajuste de hiperpar√°metros
- Optimiza configuraciones sin b√∫squeda exhaustiva.
- Ejemplo: profundidad m√°xima y porcentaje m√≠nimo de divisi√≥n en √°rboles de decisi√≥n.

---

### 8. Par√°metros y visualizaci√≥n

- `n_jobs`: controla el paralelismo (‚àí1 = todos los n√∫cleos).
- `log_level`: controla la verbosidad.
- Visualizaci√≥n disponible en cada etapa del pipeline.

üìå Si hay menos de 1.000 datos, no se ejecuta muestreo adaptativo.

---

### 9. Personalizaci√≥n

- `model_list`: define qu√© algoritmos considerar.
- M√©tricas personalizadas:
  - `roc_auc` (clasificaci√≥n binaria)
  - `recall_macro` (multiclase)
  - `neg_mean_squared_error` (regresi√≥n)
- `time_budget`: define tiempo m√°ximo en segundos.
- `minimum_feature_list`: protege features clave de ser eliminadas.

---

### 10. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es AutoML y c√≥mo funciona en ADS.
- Enfoques comunes y ventajas del m√©todo de Oracle.
- Flujo de trabajo completo y etapas automatizadas.
- C√≥mo personalizar y visualizar el proceso.

---

# üß™ 4.09 Lecci√≥n: Demo: Construcci√≥n de un Clasificador con AutoMLx
## üìò Clasificaci√≥n binaria con el dataset de ingresos del censo

### 1. Introducci√≥n

Hola y bienvenido a esta demo.  
Construiremos un **clasificador binario** usando la herramienta **Oracle AutoMLx** con el dataset p√∫blico **Census Income** del repositorio UCI Machine Learning.

üîπ Exploraremos las opciones de AutoMLx que permiten al usuario controlar el proceso de entrenamiento automatizado.  
üîπ Evaluaremos distintos modelos entrenados por AutoML.

üì¶ Usaremos el entorno Conda:  
**Oracle AutoML and Model Explanation for Python 3.8**, versi√≥n **2.0**.

---

### 2. Flujo t√≠pico de modelado en ML

Las tareas de modelado incluyen:

1. **Preprocesamiento**: limpieza, imputaci√≥n, ingenier√≠a de caracter√≠sticas, normalizaci√≥n.
2. **Selecci√≥n de modelo**: seg√∫n el dataset y la tarea de predicci√≥n.
3. **Ajuste de hiperpar√°metros**: para mejorar el rendimiento.

‚ö†Ô∏è Estos pasos son intensivos en tiempo y requieren experiencia t√©cnica.  
Adem√°s, no existe una soluci√≥n universal: el mejor modelo y configuraci√≥n var√≠an seg√∫n el dataset.

---

### 3. Ventajas de AutoMLx

Con una simple API en Python, AutoMLx permite:

- Iniciar r√°pidamente el proceso de ciencia de datos.
- Obtener un modelo ajustado y un conjunto de caracter√≠sticas √≥ptimas.
- Automatizar tareas clave del ciclo supervisado (clasificaci√≥n o regresi√≥n).

---

### 4. Preparaci√≥n del entorno

- Se ejecutan comandos m√°gicos para visualizar gr√°ficos con `matplotlib` y recargar m√≥dulos.
- Se importan librer√≠as necesarias:
  - `gzip`, `pandas`, `numpy`, `matplotlib`, `sklearn`, `seaborn`
  - Para tareas de acceso, preprocesamiento, visualizaci√≥n y operaciones matem√°ticas.

Luego se importa la librer√≠a AutoMLx y la funci√≥n `init`.

---

### 5. Carga del dataset

- Se usa `fetch_openml` de `scikit-learn` para descargar el dataset desde OpenML.
- Se especifica `as_frame=True` para obtener un `DataFrame` de `pandas`.

üìå Objetivo del dataset:  
Predecir si el ingreso anual de una persona **excede los $50,000**.

---

### 6. Exploraci√≥n inicial

- El dataset contiene columnas como `age`, `workclass`, `education`, `race`, etc.
- Mezcla de datos num√©ricos y categ√≥ricos ‚Üí desaf√≠o para entrenar modelos.
- Algunas columnas est√°n mal etiquetadas como `category` (ej. `age`, `hours-per-week`).

üîç Se usa `.dtypes` para inspeccionar los tipos de datos.  
Tambi√©n se calcula el porcentaje de valores faltantes por columna.

‚úÖ AutoMLx maneja autom√°ticamente los valores faltantes:
- Elimina columnas con demasiados nulos.
- Imputa valores seg√∫n el tipo de feature.

---

### 7. Visualizaci√≥n de la variable objetivo

- Se analiza la distribuci√≥n de la variable `income`.
- Se observa cu√°ntas personas ganan m√°s o menos de $50,000.

---

### 8. Divisi√≥n de datos

- Se separan variables predictoras (`X`) y objetivo (`y`).
- Se define `train_size = 0.7` ‚Üí 70% entrenamiento, 30% prueba.
- Se corrigen columnas mal etiquetadas ‚Üí se convierten a `int`.

üîÅ La variable `income` se transforma a binaria:
- `>50K` ‚Üí `1`
- `<=50K` ‚Üí `0`

üìä Resultado:
- **24,189 filas** para entrenamiento.
- **14 columnas** en total.

---

### 9. Configuraci√≥n de AutoMLx

- Se inicia el motor con `init`:
  - Por defecto: `dask` (paralelismo).
  - En este caso: `local` con `n_jobs = 2`.

üîß Se crea una instancia de AutoMLx para tareas supervisadas (clasificaci√≥n o regresi√≥n).

### 10. Etapas del pipeline AutoMLx

  1. **Preprocesamiento**:
    - Limpieza, imputaci√≥n, ingenier√≠a y normalizaci√≥n de features.

  2. **Selecci√≥n de algoritmo**:
    - Identifica el mejor clasificador para el dataset.
    - Algoritmos disponibles:
      - `AdaBoost`, `DecisionTree`, `TorchMLP`, `LinearSVC`, `LogisticRegression`, `XGBoost`, `GaussianNB`, entre otros.

  3. **Muestreo adaptativo**:
    - Selecciona subconjuntos de datos para entrenar.
    - Actualiza la estrategia de muestreo seg√∫n el rendimiento de modelos anteriores.
    - Se enfoca en regiones del espacio de caracter√≠sticas m√°s prometedoras.

### 11. Selecci√≥n de caracter√≠sticas y ajuste de hiperpar√°metros
Despu√©s del muestreo adaptativo, AutoMLx:

Selecciona un subconjunto de caracter√≠sticas relevantes.

Ajusta los hiperpar√°metros del modelo para maximizar el rendimiento.

üîπ Todo esto se realiza autom√°ticamente dentro del pipeline.

### 12. Entrenamiento del modelo
Se crea una instancia del pipeline con automl.PipeLine.

Se define la tarea como classification.

Se entrena el modelo con fit(x_train, y_train).

üìå Se usa cv=5 para aplicar validaci√≥n cruzada con 5 folds.

### 13. Selecci√≥n del modelo
Algunos algoritmos como SVC y KNeighborsClassifier se deshabilitan si el dataset tiene m√°s de 10.000 muestras o 1.000 features.

El modelo elegido fue LGBMClassifier (Light Gradient Boosting).

Se complet√≥ el muestreo adaptativo en los 5 folds.

### 14. Predicci√≥n y evaluaci√≥n
Se usa predict_proba(x_test) para obtener probabilidades de clase.

Se eval√∫a con ROC AUC ‚Üí resultado: 0.91.

### 15. Resumen del pipeline
AutoMLx genera un resumen con:

Features seleccionadas: age, workclass, education_num, etc.

Algoritmo elegido: LGBMClassifier.

Hiperpar√°metros ajustados.

M√©tricas de CPU y memoria.

Validaci√≥n media por algoritmo.

üîç Se puede visualizar con print_summary().

### 16. Visualizaci√≥n de selecci√≥n de algoritmos
Se grafican los scores predichos por algoritmo usando Bayesian Optimization.

M√©trica usada: negative log loss.

Menor valor ‚Üí mejor rendimiento.

LGBM fue el mejor algoritmo seg√∫n esta m√©trica.

### 17. Muestreo adaptativo
Busca el subconjunto m√≠nimo de datos que mantiene el rendimiento.

En este caso, no se encontr√≥ un subconjunto suficiente ‚Üí se usa el dataset completo.

### 18. Selecci√≥n de caracter√≠sticas
AutoMLx aplica una estrategia inteligente:

Elige algoritmo de selecci√≥n (ej. RFE, SFS, PCU).

Rankea las features (correlaci√≥n, tests estad√≠sticos).

Eval√∫a subconjuntos con validaci√≥n cruzada.

Identifica el subconjunto m√°s peque√±o sin p√©rdida de rendimiento.

üìå Features seleccionadas: age, workclass, education_num, marital_status, etc. üìå Features eliminadas: 4 columnas no relevantes.

### 19. Matriz de confusi√≥n
Se usa confusion_matrix() de scikit-learn.

Argumentos:

Etiquetas verdaderas (y_test)

Predicciones (y_pred)

Etiquetas binarias (<=50K, >50K)

Se normaliza por filas ‚Üí porcentajes.

Se visualiza como heatmap con:

Eje X: predicci√≥n

Eje Y: valor real

### 20. Personalizaci√≥n del AutoML
Pod√©s limitar los algoritmos considerados:

python
model_list = ["LogisticRegression"]
üîπ AutoMLx solo optimizar√° entre los modelos especificados.

### 21. Validaci√≥n personalizada
Pod√©s definir un conjunto de validaci√≥n personalizado para evaluar la calidad de los modelos y configuraciones:

python
fit(x_train, y_train, validation_data=(x_val, y_val))
üîπ Esto permite controlar c√≥mo se eval√∫an los modelos durante el entrenamiento.

### 22. Optimizaci√≥n de m√∫ltiples modelos
Por defecto, AutoMLx ajusta los hiperpar√°metros del mejor modelo seleccionado. Pero pod√©s optimizar los top-N modelos:

python
model_list = ["LogisticRegression", "XGBClassifier", "LGBMClassifier"]
top_n = 2
üîπ En este ejemplo, se ajustan los dos mejores modelos entre los tres especificados. üîπ Resultado: ROC AUC = 0.855

### 23. M√©tricas de evaluaci√≥n personalizadas
AutoMLx permite cambiar la m√©trica de optimizaci√≥n:

Por defecto:

Clasificaci√≥n binaria: neg_log_loss

Regresi√≥n: neg_mean_squared_error

üîπ Pod√©s usar otras m√©tricas como:

Clasificaci√≥n binaria: accuracy, f1, roc_auc, precision, recall

Multiclase: recall_macro, f1_macro, accuracy

Regresi√≥n: r2, explained_variance, mean_absolute_error

Ejemplo:

python
score_metric = "accuracy"
üîπ Resultado: ROC AUC ‚âà 0.855

### 24. Funciones de puntuaci√≥n definidas por el usuario
Pod√©s crear tu propia funci√≥n de evaluaci√≥n:

python
from sklearn.metrics import make_scorer, f1_score

def custom_score(model, X, y):
    y_pred = model.predict(X)
    return f1_score(y, y_pred)

scorer = make_scorer(custom_score)
üîπ Se pasa como argumento score_metric al pipeline.

### 25. L√≠mite de tiempo (Time Budget)
AutoMLx permite definir un presupuesto de tiempo en segundos:

python
time_budget = 10
üîπ Si se excede el tiempo, se detiene el proceso y se usan par√°metros por defecto. üîπ Se muestra un mensaje indicando el timeout. üîπ Resultado: ROC AUC con configuraci√≥n por defecto.

### 26. Lista m√≠nima de features
Pod√©s forzar que ciertas features no sean eliminadas durante la selecci√≥n:

python
minimum_features = ["fnlwgt", "native-country"]
üîπ Esto garantiza que esas columnas est√©n presentes en el modelo final. üîπ Tambi√©n pod√©s usar:

int: n√∫mero m√≠nimo de features.

float: proporci√≥n m√≠nima (ej. 0.5).

1.0: desactiva la selecci√≥n de features.

### 27. Conclusi√≥n
Esta demo mostr√≥ c√≥mo:

Cargar y preparar un dataset real.

Configurar y ejecutar AutoMLx.

Personalizar el pipeline con m√©tricas, modelos, tiempo y features.

Evaluar el rendimiento con ROC AUC y matriz de confusi√≥n.

üîß AutoMLx permite construir modelos precisos con m√≠nima intervenci√≥n manual, ideal para acelerar el ciclo de vida de ML.

Recurso GIT ejemplo: https://github.com/oracle-samples/automlx/blob/main/demos/OracleAutoMLx_Classification.ipynb

Principal: https://github.com/oracle-samples


---

# üéØ 4.10 Lecci√≥n: Hyperparameter Tuning con ADSTuner  
## üìò Ajuste de hiperpar√°metros en Oracle ADS

### 1. Introducci√≥n

Hola, soy Jon Stanesby.  
En esta breve lecci√≥n veremos c√≥mo ajustar hiperpar√°metros usando **ADSTuner**, una herramienta de Oracle ADS.

---

### 2. ¬øQu√© son los hiperpar√°metros?

- Son par√°metros que **controlan el proceso de aprendizaje** de un modelo.
- No se aprenden directamente de los datos.
- El ajuste de hiperpar√°metros consiste en:
  - Probar m√∫ltiples combinaciones.
  - Evaluar el rendimiento.
  - Elegir la mejor configuraci√≥n.

---

### 3. ¬øQu√© ofrece ADSTuner?

- Estrategias de b√∫squeda integradas para modelos comunes.
- Soporte para **espacios de b√∫squeda personalizados**.
- Compatible con cualquier librer√≠a ML que no tenga ajuste de hiperpar√°metros.
- Genera un **informe de ajuste** con:
  - Pruebas realizadas.
  - Mejores configuraciones.
  - Estad√≠sticas.

---

### 4. Inicializaci√≥n de ADSTuner

Para crear un objeto `ADSTuner` se necesita:

- Referencia al modelo a ajustar.
- Opcionalmente:
  - N√∫mero de folds para **validaci√≥n cruzada**.
  - Estrategia de b√∫squeda (`strategy`).

---

### 5. Estrategias de b√∫squeda

Pod√©s definir el espacio de b√∫squeda de dos formas:

#### a. Usar los valores por defecto
- ADSTuner ofrece dos opciones optimizadas:

| Tipo | Descripci√≥n |
|------|-------------|
| **Perfunctory** | Espacio peque√±o ‚Üí ajusta los hiperpar√°metros m√°s importantes. Ideal para pruebas r√°pidas. |
| **Detailed** | Espacio amplio ‚Üí ajusta m√°s hiperpar√°metros. √ötil cuando ya elegiste el tipo de modelo. |

#### b. Definir un espacio personalizado
- Se pasa un diccionario con los hiperpar√°metros y sus rangos.
- Ideal si ya ten√©s experiencia con el dataset.

---

### 6. Ejecuci√≥n del ajuste

Para ajustar el modelo:

```python
tuner.tune(X, y)
```

- `X`: observaciones
- `y`: variable objetivo

---

### 7. Criterios de parada

Pod√©s definir cu√°ndo detener el proceso con `exit_criterion`.  
ADSTuner se detiene cuando se cumple alguna condici√≥n:

- N√∫mero m√°ximo de iteraciones.
- Tiempo l√≠mite.
- Convergencia del score.

---

### 8. Modificaci√≥n del espacio personalizado

Pod√©s ajustar el espacio de b√∫squeda en tres formas:

- Agregar hiperpar√°metros.
- Eliminar hiperpar√°metros.
- Modificar rangos de hiperpar√°metros no categ√≥ricos.

---

### 9. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es el ajuste de hiperpar√°metros.
- C√≥mo usar ADSTuner en Oracle ADS.
- Qu√© estrategias de b√∫squeda est√°n disponibles.
- C√≥mo definir criterios de parada y espacios personalizados.

---

---

# üìä 4.11 Lecci√≥n: Model Evaluation
## üìò Evaluaci√≥n de modelos en Oracle ADS

### 1. Introducci√≥n

Hola, soy Himanshu Raj.
En esta lecci√≥n aprenderemos a **evaluar modelos de aprendizaje autom√°tico** usando Oracle ADS.

La evaluaci√≥n de modelos ocurre despu√©s de la fase de entrenamiento en el ciclo de vida de ML.
Los modelos solo son √∫tiles si sus **predicciones son de calidad**.

---

### 2. ¬øPor qu√© evaluar modelos?

- üìè **Benchmarking**: comparar el rendimiento entre modelos.
- üïµÔ∏è **Detecci√≥n de fallos**: por ejemplo, alta precisi√≥n pero baja exactitud.
- ‚öñÔ∏è **An√°lisis de trade-offs**: entender cu√°ndo y c√≥mo cada modelo funciona mejor.

---

### 3. ¬øC√≥mo se eval√∫a un modelo?

1. Se reserva un **conjunto de validaci√≥n** con etiquetas reales.
2. Se comparan las **predicciones** del modelo con los valores reales.
3. Se generan **m√©tricas** y **gr√°ficos** que resumen el rendimiento.

---

### 4. Evaluadores en ADS

ADS ofrece tres tipos de evaluadores:

| Tipo | Ejemplo de salida |
|------|-------------------|
| **Binaria** | 0 o 1 |
| **Multiclase** | colores, categor√≠as |
| **Regresi√≥n** | precios, longitudes |

Tambi√©n se puede combinar con m√©todos open source como `scikit-learn`.

---

### 5. Evaluaci√≥n de clasificaci√≥n binaria

- M√©tricas comunes: precisi√≥n, recall, F1, ROC AUC, matriz de confusi√≥n.
- Clases usadas: `ADSEvaluator`, `ADSModel`.
- Se convierte el modelo con `from_estimator()`.

Ejemplo:

```python
model = from_estimator(LogisticRegression())
evaluator = ADSEvaluator(model)
evaluator.metrics
evaluator.show_in_notebook(perfect=True)
```

üîπ Se puede agregar m√©tricas personalizadas con `add_metrics()`  
üîπ Ejemplo: `F2_Score`

üìä Gr√°ficos disponibles:
- Lift & Gain
- Curva Precision-Recall
- Matriz de confusi√≥n normalizada

---

### 6. Evaluaci√≥n de clasificaci√≥n multiclase

- M√©tricas: hamming loss, F1 (macro, micro, weighted), recall, ROC AUC.
- Se deben pasar los niveles de clase (`class=[0,1,2]`).
- Se usa `from_estimator()` y `show_in_notebook()` igual que en binaria.

üìä Gr√°ficos disponibles:
- Curva ROC multiclase
- Precisi√≥n por clase
- F1 por clase
- Curva PR multiclase

---

### 7. Evaluaci√≥n de regresi√≥n

- M√©tricas: R¬≤, varianza explicada, MSE, MAE, RMSE, residuales.
- Se usa `evaluator.metrics` y `evaluator.show_in_notebook`.

üìä Gr√°ficos disponibles:

| Gr√°fico | Descripci√≥n |
|--------|-------------|
| **Observed vs Predicted** | Comparaci√≥n directa entre valores reales y predichos |
| **QQ Plot** | Distribuci√≥n de residuales vs normal est√°ndar |
| **Residuals vs Predicted** | Verifica patrones en errores |
| **Residuals vs Observed** | Detecta sesgos en predicci√≥n |

---

### 8. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Por qu√© es importante evaluar modelos.
- Qu√© m√©tricas y gr√°ficos usar seg√∫n el tipo de problema.
- C√≥mo usar `ADSEvaluator` y `ADSModel` para generar evaluaciones completas.
- C√≥mo agregar m√©tricas personalizadas y visualizar resultados.

---


---

# üß† 4.12 Lecci√≥n: Expert Tips ‚Äì ADS Evaluators  
## üìò Consejos pr√°cticos para evaluar modelos en Oracle ADS

### 1. Introducci√≥n

Hola, soy Hemant Gahankari, l√≠der principal de entrenamiento en Oracle University.  
En este video veremos c√≥mo usar los **evaluadores de ADS** para simplificar la evaluaci√≥n de modelos.

---

### 2. Tipos de evaluadores en ADS

ADS ofrece tres tipos de evaluadores:

| Evaluador | Tipo de salida |
|-----------|----------------|
| **Binario** | 0 o 1 |
| **Multiclase** | Categor√≠as discretas |
| **Regresi√≥n** | Valores continuos |

üîπ Estos evaluadores permiten **calcular y graficar m√©tricas relevantes** de forma sencilla.

---

### 3. Ejemplo pr√°ctico: Clasificaci√≥n binaria

#### a. Flujo b√°sico

1. Importar `ADSEvaluator`.
2. Crear un dataset de clasificaci√≥n binaria.
3. Dividir en entrenamiento y prueba.
4. Entrenar modelos (ej. `LogisticRegression`, `RandomForestClassifier`).
5. Envolver los modelos con `ADSModel`.
6. Crear el objeto `evaluator` con `ADSEvaluator`.

#### b. M√©tricas

```python
evaluator.metrics
```

üîπ Muestra m√©tricas para cada modelo, tanto en entrenamiento como en prueba.

#### c. Gr√°ficos

```python
evaluator.show_in_notebook()
```

üîπ Genera gr√°ficos como matriz de confusi√≥n, curvas ROC, etc.

---

### 4. Conclusi√≥n

Los evaluadores de ADS:

- Simplifican el c√°lculo de m√©tricas.
- Automatizan la generaci√≥n de gr√°ficos.
- Permiten comparar m√∫ltiples modelos f√°cilmente.

üìå Se recomienda probarlos con distintos datasets para familiarizarse con su uso.

*** DOCUMENTACI√ìN:  Ver: https://accelerated-data-science.readthedocs.io/en/latest/ ***

---

---

# üß† 4.13 Lecci√≥n: Model Explanations ‚Äì Global Explainer
## üìò Explicabilidad global de modelos en Oracle ADS

### 1. Introducci√≥n

Hola, soy Himanshu Raj.  
En esta lecci√≥n aprenderemos sobre **explicabilidad de modelos**, una etapa clave dentro de la **validaci√≥n de modelos** en el ciclo de vida de ML.

---

### 2. ¬øQu√© es la explicabilidad?

- **Explicabilidad**: capacidad de explicar por qu√© un modelo hace una predicci√≥n.
- **Interpretabilidad**: grado en que un humano puede entender esa explicaci√≥n.

üîç La creciente complejidad de los algoritmos ML dificulta entender qu√© aprendi√≥ el modelo y por qu√© predice lo que predice.

---

### 3. Tipos de explicaciones

| Tipo | Descripci√≥n |
|------|-------------|
| **Global** | Explica el comportamiento general del modelo |
| **Local** | Explica una predicci√≥n espec√≠fica |
| **What-if** | Analiza c√≥mo cambios en features afectan la predicci√≥n |

üìå En esta lecci√≥n nos enfocamos en la **explicaci√≥n global**. Las otras se cubren en la pr√≥xima lecci√≥n.

---

### 4. T√©cnicas de explicaci√≥n global

Todas son **agn√≥sticas al modelo** (no dependen del tipo de algoritmo):

1. **Feature Permutation Importance**  
   - Estima la importancia de cada feature seg√∫n su impacto en la predicci√≥n.

2. **Feature Dependence Explanations**  
   - Eval√∫a la relaci√≥n entre valores de features y predicciones.

3. **Accumulated Local Effects (ALE)**  
   - A√≠sla el efecto de cada feature sobre la predicci√≥n.

---

### 5. Feature Permutation Importance

- Mide cu√°nto **empeora el error de predicci√≥n** al eliminar (reordenar) una feature.
- Se usa una m√©trica de evaluaci√≥n:
  - Clasificaci√≥n ‚Üí `F1 score`
  - Regresi√≥n ‚Üí `R¬≤`

#### ¬øC√≥mo funciona?

1. Se calcula el error base del modelo.
2. Se **reordenan aleatoriamente** los valores de una feature (se introduce ruido).
3. Se compara el nuevo error con el original.

üîπ Si el error aumenta ‚Üí la feature es importante.  
üîπ Si el error no cambia ‚Üí la feature no aporta valor.

---

### 6. Visualizaciones en ADS

ADS genera tres tipos de gr√°ficos para esta t√©cnica:

| Tipo | Descripci√≥n |
|------|-------------|
| **Box Plot** | Muestra la dispersi√≥n del impacto por feature |
| **Bar Chart** | Muestra la importancia promedio y desviaci√≥n est√°ndar |
| **Scatter Plot** | Muestra el impacto por iteraci√≥n del algoritmo |

üìå Features con mayor impacto aparecen m√°s arriba en los gr√°ficos.

---

### 7. Ejemplo: Titanic Dataset

- Modelo: `XGBClassifier` entrenado con AutoML de ADS.
- Gr√°fico de barras:
  - Eje X: importancia de la feature.
  - Barras largas ‚Üí mayor importancia.
  - Se muestra promedio y desviaci√≥n est√°ndar.

- Box plot:
  - Eje X: impacto en el score.
  - Eje Y: features ordenadas por importancia.
  - Se muestran m√≠nimo, cuartiles y m√°ximo.

- Scatter plot:
  - Impacto por iteraci√≥n.
  - Permite ver estabilidad del ranking.

---

### 8. Feature Dependence Explanations

- Eval√∫a el **efecto marginal** que tiene cada feature sobre la predicci√≥n.
- Es la segunda t√©cnica del explainer global.

---

### 9. ¬øC√≥mo funciona Feature Dependence?

1. Se selecciona una **feature** del modelo entrenado.
2. ADS toma m√∫ltiples valores de la distribuci√≥n de esa feature.
3. Se reemplaza el valor de esa feature en todos los registros por un valor fijo.
4. Se calcula la predicci√≥n del modelo sobre este dataset modificado.
5. Se repite el proceso para cada valor seleccionado.

üîπ Resultado: se obtienen **N datasets modificados**, cada uno con **M predicciones**.

---

### 10. M√©todos de explicaci√≥n en ADS

#### a. PDP (Partial Dependence Plot)
- Calcula el **promedio de predicciones** para cada valor de la feature.
- Resultado: N valores promedio.

#### b. ICE (Individual Conditional Expectation)
- Muestra las **predicciones individuales** para cada muestra.
- Resultado: N √ó M valores.

---

### 11. Tipos de gr√°ficos PDP

| Tipo | Visualizaci√≥n |
|------|----------------|
| **Una feature categ√≥rica** | Gr√°fico de barras (ej. sexo: mujer/hombre) |
| **Una feature num√©rica discreta** | L√≠nea o barras con valores en eje X y predicci√≥n promedio en eje Y |
| **Dos features** | Heatmap con predicci√≥n promedio como color |

---

### 12. Gr√°ficos ICE

- Para features continuas: l√≠neas individuales por muestra.
- Eje X: valores de la feature.
- Eje Y: predicci√≥n del modelo.

üîπ Se puede trazar la **mediana** para visualizar la tendencia.  
üîπ Para features categ√≥ricas: se usa **violin plot** (ej. sexo: mujer/hombre).

---

### 13. ALE (Accumulated Local Effects)

- M√©todo global **agn√≥stico al modelo**.
- Eval√∫a el efecto de una feature **aislando el impacto de otras**.
- M√°s robusto ante **features correlacionadas** que PDP.

---

### 14. ¬øC√≥mo funciona ALE?

1. Se selecciona una feature.
2. Se divide su distribuci√≥n en **intervalos configurables**.
3. Para cada intervalo:
   - Se identifican muestras similares (vecindario).
   - Se calcula la diferencia en la predicci√≥n al modificar el valor de la feature.
4. Se promedian las diferencias ‚Üí se obtiene el efecto acumulado.

üîπ Para features categ√≥ricas, se requiere un **orden estimado** (ej. usando similitud de distancia entre categor√≠as).

---

### 15. Interpretaci√≥n del gr√°fico ALE

- Para features categ√≥ricas: gr√°fico de **barras verticales**.
- Eje X: valores categ√≥ricos.
- Eje Y: cambio en la predicci√≥n respecto al promedio.
- Barras positivas ‚Üí aumentan la predicci√≥n.
- Barras negativas ‚Üí la reducen.

---

### 16. Conclusi√≥n

En esta lecci√≥n aprendiste:

- C√≥mo funcionan las explicaciones globales en ADS.
- Qu√© son PDP, ICE y ALE.
- C√≥mo interpretar sus gr√°ficos.
- Cu√°ndo usar cada t√©cnica seg√∫n el tipo de feature y modelo.

---

---

# üß† 4.14 Lecci√≥n: Model Explanations ‚Äì Local Explainer  
## üìò Explicaciones locales y an√°lisis What-If en Oracle ADS

### 1. Introducci√≥n

Ya vimos las explicaciones globales.  
Ahora exploraremos las otras dos t√©cnicas de explicabilidad:

| T√©cnica | Prop√≥sito |
|--------|-----------|
| **Local** | Explica por qu√© el modelo hizo una predicci√≥n espec√≠fica |
| **What-If** | Muestra c√≥mo cambian las predicciones al modificar los valores de entrada |

---

### 2. Explicaciones locales con LIME

ADS incluye una versi√≥n mejorada de **LIME** (Local Interpretable Model-Agnostic Explanations).

üîπ Idea clave: aunque el modelo global sea complejo, su comportamiento **local** puede aproximarse con un modelo simple (ej. lineal).

---

### 3. ¬øC√≥mo funciona LIME?

1. Se parte de un modelo entrenado.
2. Se selecciona una muestra espec√≠fica.
3. Se generan muestras sint√©ticas en su vecindario.
4. Se obtienen predicciones del modelo complejo.
5. Se entrena un **modelo sustituto** (ej. lineal) sobre esas predicciones.
6. Se interpretan los coeficientes del modelo sustituto como **importancia local de features**.

---

### 4. Estructura del panel de explicabilidad en ADS

#### a. Secci√≥n "Model"
- Columna izquierda: informaci√≥n del modelo y predicci√≥n real.
- Columna derecha: muestra seleccionada (valores de features).

#### b. Secci√≥n "Explainer"
- Columna izquierda: configuraci√≥n del explainer:
  - Algoritmo (LIME)
  - Modelo sustituto (lineal)
  - N√∫mero de muestras sint√©ticas (ej. 5.000)
  - Discretizaci√≥n de features continuas
- Columna derecha: leyenda para interpretar los gr√°ficos.

#### c. Secci√≥n "Explanations"
- Para clasificaci√≥n:
  - Se genera una explicaci√≥n por clase objetivo.
  - En binaria: una clase es el complemento de la otra.
  - En multiclase: se muestra c√≥mo cada feature favorece o perjudica a cada clase.

---

### 5. Visualizaci√≥n de importancia local

- Gr√°fico de **barras horizontales**.
- Ordenadas por importancia relativa.
- Barras a la derecha (positivas): aumentan la probabilidad de la clase.
- Barras a la izquierda (negativas): la reducen.

---

### 6. Calidad de la explicaci√≥n

ADS eval√∫a:

- **Distribuci√≥n de distancias** entre la muestra original y las sint√©ticas.
- **M√©tricas de ajuste** del modelo sustituto (clasificaci√≥n o regresi√≥n).

Esto permite verificar si la explicaci√≥n es confiable.

---

### 7. What-If Explainer

Permite explorar c√≥mo cambian las predicciones al modificar los valores de entrada.

#### a. Explore Sample
- Interfaz gr√°fica con una muestra editable.
- Al hacer clic en **Run Inference**, se recalcula la predicci√≥n.
- Se muestran valores originales y modificados.

#### b. Explore Predictions
- Explora predicciones sobre:
  - **Distribuci√≥n marginal** (una feature)
  - **Distribuci√≥n conjunta** (dos features)

üìä Ejemplos:

- Una feature (`age`): gr√°fico de `age` vs predicci√≥n.
- Dos features (`age`, `CRIM`): gr√°fico 2D con color indicando el valor predicho.

---

### 8. Conclusi√≥n

En esta lecci√≥n aprendiste:

- C√≥mo funciona LIME en ADS para explicaciones locales.
- C√≥mo interpretar la importancia de features en una predicci√≥n espec√≠fica.
- C√≥mo usar el m√≥dulo What-If para explorar sensibilidad del modelo.

---

---

# üß† 4.15 Lecci√≥n: Expert Tips ‚Äì Explainers  
## üìò Uso de objetos Explainer en Oracle AutoMLx

### 1. Introducci√≥n

Hola, soy Hemant Gahankari, l√≠der principal de entrenamiento en Oracle University.  
En este video veremos c√≥mo usar los objetos **Explainer** para aplicar t√©cnicas de explicabilidad en modelos de ML.

---

### 2. Requisitos

Para usar los objetos `Explainer`, necesit√°s:

- Tener instalada la librer√≠a **Oracle AutoMLx**.
- Usar el entorno Conda: `automlx_p28_cpu`.

---

### 3. Flujo b√°sico de uso

1. **Inicializar el motor AutoMLx**:
   ```python
   from automl import init
   init(engine="local")
   ```

2. **Entrenar un modelo**:
   ```python
   estimator.fit(X_train, y_train)
   ```

3. **Crear el objeto Explainer**:
   ```python
   explainer = Explainer(estimator)
   ```

4. **Aplicar m√©todos de explicabilidad**:
   - `explainer.global_explanation()`
   - `explainer.local_explanation(sample)`
   - `explainer.what_if(sample, feature_changes)`

---

### 4. Tipos de Explainers

Seg√∫n el tipo de datos, se usan clases espec√≠ficas:

| Tipo de datos | Clase recomendada |
|---------------|-------------------|
| Tabulares     | `TabularExplainer` |
| Texto         | `TextExplainer`    |

üîπ Cada clase tiene m√©todos adaptados para generar explicaciones relevantes.

---

### 5. Recomendaci√≥n

Se sugiere:
- Documentaci√≥n oficial: https://docs.oracle.com/en-us/iaas/tools/automlx/latest/legacy/v23.2.0/mlx.html
- Probar con distintos datasets.
- Explorar tanto explicaciones **globales** como **locales**.
- Familiarizarse con la interfaz `MLExplainer`.

---

---

# üì¶ 4.16 Lecci√≥n: Model Catalog
## üìò Introducci√≥n al cat√°logo de modelos en OCI

### 1. ¬øQu√© es el Model Catalog?

Hola, soy John Stanesby.
El cat√°logo de modelos en OCI permite:

- üìå **Almacenar modelos de forma inmutable**
- üîç **Rastrear su procedencia (provenance)**
- üîÑ **Compartir, reproducir y desplegar modelos**

---

### 2. ¬øQu√© contiene un modelo en el cat√°logo?

Un modelo incluye varios artefactos:

| Artefacto | Descripci√≥n |
|-----------|-------------|
| **Modelo entrenado** | Archivo serializado |
| **Hiperpar√°metros** | Configuraci√≥n usada |
| **Metadata** | Informaci√≥n del modelo |
| **Esquema de entrada/salida** | Formato esperado |
| **score.py** | Script para cargar el modelo y hacer inferencias |
| **runtime.yaml** | Entorno Conda para despliegue |
| **validate.py** | Pruebas opcionales de introspecci√≥n |
| **requirements.txt** | Dependencias necesarias |
| **README.md** | Instrucciones paso a paso |

---

### 3. Inmutabilidad del cat√°logo

- Los artefactos son **inmutables por dise√±o**.
- Para modificar un modelo ‚Üí se crea una **nueva versi√≥n**.
- Esto garantiza trazabilidad total en producci√≥n.

üìå L√≠mites de tama√±o:
- Desde consola: **100 MB**
- Desde ADS, SDK o CLI: **20 GB**

---

### 4. score.py

- Define c√≥mo cargar el modelo y realizar inferencias.
- Debe incluir:
  - Funci√≥n `load_model()`
  - Funci√≥n `predict()`
- Pod√©s agregar funciones auxiliares (ej. transformaciones personalizadas).

üìå El c√≥digo debe estar **al mismo nivel o por debajo** de `score.py`.  
Archivos por encima ser√°n ignorados ‚Üí puede fallar el despliegue.

---

### 5. runtime.yaml

- Define el entorno Conda para despliegue.
- Requerido si us√°s **model deployment** en OCI.
- Incluye:
  - `inference_environment_slug`
  - `inference_environment_type`: `data science` o `published`
  - `inference_environment_path`: ruta en Object Storage ‚Üí `bucket@namespace/path`

---

### 6. Versi√≥n del artefacto

- ADS extrae autom√°ticamente la versi√≥n del artefacto al guardarlo.
- El entorno de inferencia **puede coincidir o diferir** del entorno de entrenamiento.

---

## üìò Metadata, documentaci√≥n y pol√≠ticas en OCI

### 7. Versi√≥n de Python

- La versi√≥n de Python usada en el entorno Conda para despliegue.
- Valor por defecto: **Python 3.6**
- Versiones soportadas: **3.6 y 3.7**

---

### 8. Archivos adicionales

Adem√°s de `score.py` y `runtime.yaml`, pod√©s incluir otros archivos necesarios para ejecutar el modelo.

---

### 9. Tipos de documentaci√≥n en el cat√°logo

| Tipo | Prop√≥sito |
|------|-----------|
| **Input/Output Schema** | Define el formato de entrada/salida esperado |
| **Provenance** | Rastreabilidad: c√≥digo, datos, entorno |
| **Introspection Tests** | Pruebas de salud del modelo |
| **Taxonomy** | Descripci√≥n t√©cnica y funcional del modelo |

---

### 10. Input/Output Schema

- Define los **features requeridos** para hacer predicciones.
- Act√∫a como un **contrato de entrada** para los clientes del modelo.
- Solo se usa con fines de documentaci√≥n.
- El output schema es opcional.

---

### 11. Provenance (Procedencia)

- Si trabaj√°s en un repo Git, ADS puede extraer autom√°ticamente:
  - C√≥digo fuente
  - Entorno de entrenamiento
  - Recursos de c√≥mputo
  - Datos de entrenamiento
  - Features generadas

üîπ Esto mejora la **reproducibilidad** y la **auditor√≠a** del modelo.

---

### 12. Introspection Tests

- Son **opcionales**.
- Se ejecutan antes de guardar el modelo.
- Generan un archivo local: `test_json_output.json`
- Pod√©s guardar los resultados como parte del metadata.

---

### 13. Taxonom√≠a del modelo

Permite describir el modelo para facilitar su comprensi√≥n dentro del equipo.

| Campo | Ejemplo |
|-------|---------|
| **Use case type** | `binary classification`, `regression` |
| **Framework** | `scikit-learn`, `TensorFlow`, `PyTorch 1.9` |
| **Algorithm** | `cart algorithm` |
| **Hyperparameters** | JSON con configuraci√≥n |
| **Artifact test results** | JSON del test |
| **Custom metadata** | Clave, valor, categor√≠a, descripci√≥n |

üìå Tama√±o m√°ximo permitido para metadata combinada: **32 KB**

---

### 14. Acceso y pol√≠ticas

- El cat√°logo de modelos es un **repositorio centralizado y gestionado**.
- Los modelos pueden ser compartidos y cargados en notebooks.
- La documentaci√≥n incluye: provenance, tests, taxonomy y schema.

üîê Como cualquier recurso de OCI, el acceso requiere **pol√≠ticas espec√≠ficas**:

- Para gesti√≥n del cat√°logo.
- Para invocar el endpoint.
- Para permitir acceso a otros recursos (ej. Object Storage).

---

---

# üßæ 4.17 Lecci√≥n: Model Serialization  
## üìò Serializaci√≥n y gesti√≥n de modelos en el cat√°logo de OCI

### 1. ¬øQu√© es la serializaci√≥n?

Hola, soy John Stanesby.  
La **serializaci√≥n** es el proceso de convertir un objeto (ej. modelo de Python o TensorFlow) en un formato que pueda:

- üóÉÔ∏è Ser almacenado
- üì° Ser transmitido
- üîÅ Ser reconstruido m√°s adelante

üîπ Tambi√©n se conoce como **marshaling** en algunos contextos.

---

### 2. Formatos comunes de serializaci√≥n

| Formato | Uso |
|--------|-----|
| **JSON** | Texto legible por humanos |
| **XML** | Estructurado, interoperable |
| **HDF5** | Datos cient√≠ficos |
| **Pickle (Python)** | Byte array para objetos Python |

---

### 3. Clases de serializaci√≥n en ADS

- ADS ofrece clases espec√≠ficas para distintos frameworks:
  - `PyTorchModel`
  - `TensorFlowModel`
  - `GenericModel` (para otros casos)

üîπ No todos los tipos de modelos tienen clases dedicadas.

---

### 4. M√©todo `save()`

Guarda los artefactos del modelo en el cat√°logo:

- Recarga `score.py` y `runtime.yaml` desde disco.
- Si `ignore_introspection=False`, ejecuta pruebas de introspecci√≥n.
- Sugiere soluciones si detecta problemas.
- Devuelve el **OCID** del modelo.

üîç Tambi√©n pod√©s usar `introspect()` despu√©s de `prepare()`.

---

### 5. Uso de `prepare(GenericModel)`

- Convierte cualquier modelo en un objeto ADS.
- ADS genera c√≥digo est√°ndar que pod√©s modificar.
- Luego se guarda el objeto y su metadata en el cat√°logo.

---

### 6. Interfaces para guardar modelos

Pod√©s usar:

| Interfaz | Descripci√≥n |
|----------|-------------|
| **ADS SDK** | API de alto nivel para notebooks |
| **OCI Python SDK** | API oficial de OCI |
| **OCI Console** | Interfaz gr√°fica web |

---

### 7. Operaciones disponibles

Pod√©s:

- üìã Ver modelos
- ‚úèÔ∏è Editar metadata (no el modelo ni sus esquemas)
- üì¶ Mover entre compartimentos (no entre proyectos)
- ‚úÖ Activar / ‚ùå Desactivar modelos
- üóëÔ∏è Eliminar modelos (se conservan 30 d√≠as)
- üè∑Ô∏è Agregar etiquetas (definidas o libres)

---

### 8. Vistas del cat√°logo

| Vista | Contenido |
|-------|-----------|
| **Training Resource** | Notebook o job que entren√≥ el modelo |
| **Source Code** | Script de entrenamiento |
| **Taxonomy** | Descripci√≥n, atributos personalizados |
| **Deployments** | Despliegues asociados |
| **Introspection** | Estado de pruebas (`score.py`, `runtime.yaml`) |
| **Schemas** | Entrada/salida del modelo |

üìå Los esquemas no pueden editarse una vez definidos.

---

### 9. Activaci√≥n y eliminaci√≥n

- **Activar**: habilita el modelo para despliegue.
- **Desactivar**: lo inhabilita sin eliminarlo.
- **Eliminar**: requiere confirmar el nombre exacto (no distingue may√∫sculas/min√∫sculas).
- Modelos eliminados permanecen visibles por **30 d√≠as**.

---

### 10. Operaciones v√≠a CLI o SDK

Pod√©s realizar:

- `create`
- `update`
- `list`
- `delete`

---

---

# üöÄ 4.18 Lecci√≥n: Model Deployment  
## üìò Despliegue de modelos en OCI Data Science

### 1. Introducci√≥n

Hola, soy Himanshu Raj.  
En esta lecci√≥n aprender√°s a:

- Crear y administrar despliegues de modelos ML.
- Invocar endpoints de inferencia.
- Monitorear y desactivar/reactivar despliegues.

---

### 2. ¬øCu√°ndo desplegar un modelo?

Despu√©s del entrenamiento y evaluaci√≥n, los mejores modelos se guardan en el **Model Catalog**.  
Seg√∫n el uso previsto, pod√©s desplegar para:

| Tipo | Descripci√≥n |
|------|-------------|
| **Batch** | Predicciones programadas (ej. cada hora/d√≠a) |
| **Real-time** | Predicciones activadas por eventos (ej. detecci√≥n de fraude en pagos) |

üîπ El despliegue como **endpoint HTTP** es el m√©todo m√°s com√∫n.

---

### 3. Arquitectura del despliegue en OCI

| Componente | Funci√≥n |
|------------|--------|
| **Load Balancer** | Distribuye tr√°fico entre servidores |
| **VM Instances Pool** | Aloja el modelo, entorno Conda y servidor |
| **Model Artifact** | Archivo del modelo + c√≥digo de inferencia |
| **Conda Environment** | Dependencias Python (ej. NumPy, XGBoost) |
| **Logs** | Registros de inferencia para monitoreo/debugging |

---

### 4. Archivos clave del modelo

| Archivo | Prop√≥sito |
|--------|-----------|
| **score.py** | L√≥gica de inferencia |
| **runtime.yaml** | Entorno Conda y par√°metros de despliegue |

---

### 5. Configuraci√≥n del despliegue

Desde la consola:

1. Nombre del despliegue
2. Selecci√≥n del modelo desde el cat√°logo
3. Forma de c√≥mputo (`VM.Standard2.1`, etc.)
4. N√∫mero de instancias
5. Servicio de logging
6. Ancho de banda del load balancer

üìå F√≥rmula para calcular ancho de banda recomendado:

\[
\text{Bandwidth} = \frac{\text{Payload (KB)} \cdot \text{Requests/sec} \cdot 8}{1024} \cdot 1.2
\]

Ejemplo:  
Payload = 1024 KB  
Requests/sec = 120  
‚Üí Bandwidth ‚âà **1152 Mbps**

---

### 6. M√©todos para desplegar

| M√©todo | Herramienta |
|--------|-------------|
| `.deploy()` | ADS SDK |
| `oci ds model-deployment create` | OCI CLI |
| JSON config | OCI Console / CLI |

üîπ Se puede incluir configuraci√≥n de logs opcional.

---

### 7. Invocar el endpoint

Una vez activo, se puede invocar el modelo:

- Enviar datos como **HTTP request**
- Recibir predicci√≥n como **HTTP response**

üìå Opciones:

- OCI CLI
- OCI Python SDK
- OCI Java SDK
- Consola web

üìå L√≠mites:

- Tama√±o m√°ximo del payload: **10 MB**
- Timeout: **60 segundos** (no configurable)
- Si hay latencia ‚Üí usar **streaming inference**
- Codificaci√≥n: **base64**

---

### 8. Gesti√≥n del despliegue

Desde la consola pod√©s:

- Ver detalles (OCID, configuraci√≥n, logs)
- Cambiar nombre, modelo, forma de c√≥mputo, instancias (sin downtime si est√° activo)
- Editar m√∫ltiples par√°metros si est√° inactivo

---

### 9. Activar / Desactivar / Eliminar

| Acci√≥n | Efecto |
|--------|--------|
| **Desactivar** | Detiene instancias y facturaci√≥n. Endpoint queda inactivo. |
| **Reactivar** | Vuelve a habilitar el endpoint HTTP |
| **Eliminar** | Borra el despliegue (requiere confirmaci√≥n exacta del nombre) |

---

### 10. Monitoreo

Pod√©s usar:

| Herramienta | M√©tricas |
|-------------|----------|
| **OCI Logging** | Logs de acceso e inferencia (`score.py`) |
| **OCI Monitoring** | CPU, memoria, red, latencia, cantidad de requests |

üîπ Desde el men√∫ de opciones pod√©s:

- Explorar m√©tricas en detalle
- Crear alarmas por umbral

---

### 11. Conclusi√≥n

En esta lecci√≥n aprendiste:

- C√≥mo desplegar modelos como endpoints HTTP
- C√≥mo invocar, monitorear y administrar despliegues
- C√≥mo usar ADS SDK, OCI CLI y la consola web

---

---

# üöÄ 4.19 Lecci√≥n: Model Deployment (Demo)  
## üìò Despliegue de un modelo desde la consola de OCI

### 1. Ingreso al proyecto

- Ingres√° a tu espacio de trabajo en **OCI Data Science**.
- Seleccion√° tu proyecto (ej. `test-ds`).
- En el panel izquierdo, hac√© clic en **Model Deployments**.

---

### 2. Crear un nuevo despliegue

1. Hac√© clic en **Create model deployment**.
2. Verific√° que est√©s en el **compartimento correcto** (ej. `OCI Data Science`).
3. Ingres√° un **nombre √∫nico** (m√°x. 255 caracteres). Si no lo hac√©s, se genera uno autom√°ticamente.
   - Ejemplo: `test-model-deploy`
4. (Opcional) Agreg√° una descripci√≥n.

---

### 3. Seleccionar el modelo

- Hac√© clic en **Select** para elegir un modelo activo del cat√°logo.
- Ejemplo: `RF classifier`
- Luego hac√© clic en **Submit**.

---

### 4. Configurar recursos de c√≥mputo

- Seleccion√° la **forma de c√≥mputo (VM shape)**:
  - Ejemplo: 1 OCPU, 15 GB de RAM
- Eleg√≠ la **cantidad de instancias** (ej. 2) para balancear carga.

---

### 5. Habilitar logs (opcional)

- Hac√© clic en **Select** en la secci√≥n de logging.
- Activ√°:
  - **Access logs**: registra detalles de las solicitudes.
  - **Predict logs**: captura `stdout` y `stderr` del c√≥digo de inferencia (`score.py`).

---

### 6. Configurar balanceo de carga (opcional)

- En **Show Advanced Options**, pod√©s definir el ancho de banda del load balancer.
- F√≥rmula recomendada:

\[
\text{Bandwidth (Mbps)} = \frac{\text{Payload (KB)} \cdot \text{Requests/sec} \cdot 8}{1024} \cdot 1.2
\]

- Ejemplo:
  - Payload: 124 KB
  - Requests/sec: 120
  - Resultado ‚âà **1.152 Mbps**
- Para el demo, se deja en **10 Mbps**.

---

### 7. Crear el despliegue

- Hac√© clic en **Create**.
- Esper√° a que el estado cambie a **Active**.

---

### 8. Ver detalles del despliegue

- Hac√© clic en el nombre del despliegue (`test-model-deploy`).
- Pod√©s ver:
  - Informaci√≥n general
  - Configuraci√≥n de c√≥mputo
  - Etiquetas (tags)
  - Propietario del despliegue

---

### 9. Monitorear el despliegue

- M√©tricas disponibles:
  - Tasa de √©xito
  - Cantidad de solicitudes
  - Uso de CPU, memoria, red
- Logs disponibles:
  - Access logs
  - Predict logs
- Estado de la solicitud (`Work Request`): 100% completado

---

### 10. Invocar el modelo

Pod√©s invocar el endpoint usando:

| M√©todo | Herramienta |
|--------|-------------|
| **HTTP** | Link del endpoint |
| **OCI CLI** | Comando generado |
| **Python SDK** | C√≥digo de ejemplo |
| **Java SDK** | C√≥digo de ejemplo |

üìå L√≠mite de payload: **10 MB**  
üìå Timeout: **60 segundos**

---

### 11. Administrar el despliegue

- **Desactivar**: detiene instancias y facturaci√≥n.
- **Reactivar**: vuelve a habilitar el endpoint.
- **Eliminar**: borra el despliegue cuando ya no se necesita.

---

---

# ü§ó 4.20 Lecci√≥n: Hugging Face  
## üìò Despliegue de pipelines Hugging Face en OCI Data Science

### 1. Introducci√≥n

Hola, soy Hemant Gahankari, l√≠der principal de entrenamiento en Oracle University.  
En esta lecci√≥n veremos c√≥mo **desplegar pipelines de Hugging Face** en OCI Data Science.

---

### 2. ¬øQu√© es Hugging Face?

La librer√≠a **Hugging Face Transformers** permite construir pipelines para tareas como:

- üß† Procesamiento de lenguaje natural (NLP)
- üëÅÔ∏è Visi√≥n por computadora
- üîç Clasificaci√≥n, generaci√≥n, traducci√≥n, etc.

---

### 3. Flujo de despliegue en OCI

| Paso | M√©todo |
|------|--------|
| 1Ô∏è‚É£ Crear pipeline | `transformers.pipeline(...)` |
| 2Ô∏è‚É£ Envolver pipeline | `HuggingFacePipelineModel(pipeline)` |
| 3Ô∏è‚É£ Preparar artefactos | `.prepare()` |
| 4Ô∏è‚É£ Verificar despliegue | `.verify()` |
| 5Ô∏è‚É£ Guardar en cat√°logo | `.save()` |
| 6Ô∏è‚É£ Desplegar modelo | `.deploy()` |

üîπ Este flujo permite convertir un pipeline de Hugging Face en un **modelo desplegable** dentro de OCI.

---

### 4. Recomendaci√≥n

Se sugiere revisar la documentaci√≥n oficial de:

- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Oracle ADS + Hugging Face](https://docs.oracle.com/en-us/iaas/tools/ads-sdk/latest/user_guide/model_management/huggingface.html)

---

---

# üß† 4.21 Lecci√≥n: Model Deployment using TensorFlow
## üìò Despliegue de modelos TensorFlow con Oracle ADS

### 1. Introducci√≥n

Hola, soy Hemant Gahankari.  
En esta demo aprender√°s a **registrar y desplegar un modelo TensorFlow** usando la librer√≠a **Accelerated Data Science (ADS)** en OCI.
https://docs.oracle.com/en-us/iaas/Content/data-science/using/conda-tensor-fam.htm

https://docs.public.content.oci.oraclecloud.com/es-ww/iaas/releasenotes/changes/294a424f-a597-486e-97fc-51c82174b743/index.htm

---

### 2. Flujo general de despliegue

| Paso | Acci√≥n |
|------|--------|
| 1Ô∏è‚É£ Crear objeto de serializaci√≥n | `TensorFlowModel(model)` |
| 2Ô∏è‚É£ Preparar artefactos | `.prepare()` ‚Üí genera `score.py`, `runtime.yaml`, etc. |
| 3Ô∏è‚É£ Verificar artefactos | `.verify()` ‚Üí testea `load_model()` y `predict()` |
| 4Ô∏è‚É£ Guardar en cat√°logo | `.save()` |
| 5Ô∏è‚É£ Desplegar modelo | `.deploy()` ‚Üí crea endpoint HTTPS |
| 6Ô∏è‚É£ Invocar predicci√≥n | `.predict(data)` ‚Üí devuelve resultados |

üîπ ADS simplifica todo el proceso con m√©todos espec√≠ficos por framework.

---

### 3. Librer√≠as utilizadas

- `ads`: interacci√≥n con OCI Data Science
- `logging`: control de logs
- `os`: interacci√≥n con sistema operativo
- `pandas`: manejo de datos tabulares
- `tempfile`: archivos temporales
- `tensorflow`: entrenamiento del modelo
- `tensorflow_datasets`: carga de datasets (ej. Fashion-MNIST)
- `warnings`: supresi√≥n de advertencias
- `matplotlib`: visualizaci√≥n de im√°genes

---

### 4. Dataset: Fashion-MNIST

- üî¢ 60.000 ejemplos de entrenamiento
- üîç 10.000 ejemplos de prueba
- üì∑ Im√°genes en escala de grises de 28√ó28
- üéØ 10 clases (ropa, calzado, etc.)

---

### 5. Arquitectura del modelo

```text
Input ‚Üí Flatten ‚Üí Dense(128, ReLU) ‚Üí Dropout ‚Üí Dense(10, Softmax)
```

- **Loss**: `SparseCategoricalCrossentropy`
- **Optimizer**: `Adam`
- **M√©trica**: `Accuracy`
- **Resultado**: `Loss = 0.7899`, `Accuracy = 0.7235`

---

### 6. Predicci√≥n

- Cada muestra genera **10 valores** (uno por clase).
- El nodo con mayor valor indica la clase predicha.

üìå El objetivo de esta demo no es mejorar el modelo, sino **desplegarlo** usando `TensorFlowModel`.

---

### 7. Preparaci√≥n para despliegue

- Se convierte el modelo en objeto ADS con `TensorFlowModel(model)`.
- Se ejecutan:
  - `.prepare()` ‚Üí genera artefactos
  - `.verify()` ‚Üí testea `score.py`
  - `.save()` ‚Üí guarda en cat√°logo
  - `.deploy()` ‚Üí crea endpoint

üîπ ADS tambi√©n ofrece `summary_status()` para ver el estado de cada paso en formato `DataFrame`.

---
## üìò Creaci√≥n de artefactos y metadata del modelo

### 8. Creaci√≥n del objeto TensorFlowModel

- Se crea un modelo `Sequential` en TensorFlow.
- Se envuelve con `TensorFlowModel(model, artifact_dir=...)`.
- Se genera un **objeto de modelo ADS** que gestiona el despliegue.

---

### 9. Directorio de artefactos

- Se crea un **directorio temporal** para guardar los artefactos.
- ADS genera autom√°ticamente los archivos necesarios para el despliegue.

---

### 10. Seguimiento del progreso

- M√©todo: `summary_status()`
- Devuelve un `DataFrame` con los pasos del despliegue:

| Paso | Estado |
|------|--------|
| initiate | ‚úÖ |
| prepare | ‚úÖ |
| verify | ‚è≥ |
| save | ‚è≥ |
| deploy | ‚è≥ |
| predict | ‚è≥ |

---

### 11. Archivos generados por `.prepare()`

| Archivo | Descripci√≥n |
|--------|-------------|
| `input_schema.json` | Define los features de entrada |
| `model.h5` | Modelo serializado en formato HDF5 |
| `output_schema.json` | Define la variable objetivo |
| `runtime.yaml` | Entorno Conda para despliegue |
| `score.py` | Funciones `load_model()` y `predict()` |

üîπ El archivo `model.h5` puede renombrarse con `model_file_name`.

---

### 12. Verificaci√≥n del entorno

- `runtime.yaml` incluye:
  - Nombre del entorno Conda
  - Tipo de servicio (`data science`)
  - Versi√≥n de Python

---

### 13. Metadata del modelo

El objeto `TensorFlowModel` incluye atributos √∫tiles:

| Atributo | Contenido |
|----------|-----------|
| `runtime` | Configuraci√≥n de despliegue |
| `_input` | Metadata de features: tipo, nombre, requerido |
| `metadata_custom` | Metadata personalizada: categor√≠a, descripci√≥n, clave/valor |
| `metadata_provenance` | C√≥digo fuente, datos de entrenamiento, entorno (ideal si us√°s Git) |

üîπ Tambi√©n se incluyen estad√≠sticas descriptivas por feature.

---

## üìò Verificaci√≥n, despliegue, predicci√≥n y limpieza

### 14. Atributo `metadata_taxonomy`

- Almacena informaci√≥n sobre la **clasificaci√≥n del modelo**:
  - Framework
  - Tipo de uso (use case)
  - Par√°metros relevantes
  - Otros metadatos clave

---

### 15. Verificaci√≥n del artefacto (`.verify()`)

- Si modific√°s `score.py`, deb√©s ejecutar `.verify()` antes de guardar o desplegar.
- Esto permite:
  - Probar `load_model()` y `predict()` localmente
  - Depurar errores sin necesidad de desplegar

üîπ Se puede consultar el estado con `summary_status()`.

---

### 16. Guardar el modelo (`.save()`)

- Una vez verificado, se guarda en el **Model Catalog** con `.save()`.
- Esto:
  - Empaqueta los artefactos
  - Sube el modelo al cat√°logo
  - Devuelve el **OCID** del modelo

üîπ Confirm√° el guardado desde la consola o con `summary_status()`.

---

### 17. Desplegar el modelo (`.deploy()`)

- M√©todo: `.deploy(display_name="...")`
- Par√°metros opcionales:
  - Nombre visible
  - Descripci√≥n
  - Tipo y cantidad de instancias
  - Ancho de banda
  - Logging groups

üîπ El despliegue puede tardar unos minutos. Se muestra una barra de progreso.

---

### 18. Confirmar despliegue

- Verific√° que el modelo est√© en estado **Active**.
- Us√° `summary_status()` para confirmar que `predict()` est√° disponible.

---

### 19. Realizar predicciones

- Antes: usabas `.predict()` localmente sobre el objeto ADS.
- Ahora: us√°s `.predict()` sobre el modelo desplegado ‚Üí env√≠a datos al endpoint HTTPS.

üîπ La sintaxis es similar, pero ahora se invoca el endpoint remoto.

---

### 20. Limpieza de recursos

üî¥ ¬°Importante! Siempre liberar recursos al finalizar:

| Recurso | M√©todo |
|--------|--------|
| **Despliegue** | `.delete_deployment()` |
| **Modelo** | `.delete()` |
| **Artefactos locales** | `shutil.rmtree(artifact_dir)` o similar |

üîπ El modelo debe eliminarse **despu√©s** del despliegue.

---

### 21. Conclusi√≥n

En esta demo aprendiste a:

- Crear un modelo TensorFlow
- Preparar y verificar artefactos
- Guardar y desplegar el modelo en OCI
- Realizar inferencias desde un endpoint
- Limpiar recursos correctamente

---

---

# üß† 4.22 Lecci√≥n: Entrenamiento de LLM e integraci√≥n con LangChain
## üìò OCI Data Science + ADS + LangChain

### 1. Introducci√≥n

Bienvenido a esta lecci√≥n sobre entrenamiento de modelos de lenguaje grandes (LLM) e integraci√≥n con LangChain.  
OCI Data Science Jobs ofrece infraestructura totalmente gestionada para entrenar LLMs a escala.

---

### 2. Tipos de fine-tuning soportados

| Tipo | Descripci√≥n |
|------|-------------|
| **Full parameter fine-tuning** | Ajuste completo de todos los par√°metros del modelo |
| **Parameter-efficient fine-tuning** | Ajuste parcial (ej. LoRA, adapters) para ahorrar recursos |

---

### 3. Flujo de entrenamiento con ADS

| Paso | Acci√≥n |
|------|--------|
| 1Ô∏è‚É£ Obtener modelo preentrenado | Desde Meta o Hugging Face |
| 2Ô∏è‚É£ Definir job de entrenamiento | Usando ADS Python API |
| 3Ô∏è‚É£ Ejecutar job | `.run()` v√≠a API |
| 4Ô∏è‚É£ Streaming de logs | Ver salida en tiempo real |
| 5Ô∏è‚É£ Guardar resultados | Checkpoints ‚Üí OCI Object Storage |

üîπ ADS configura autom√°ticamente nodos y GPUs seg√∫n el `replica` y `shape` definidos.  
No es necesario especificarlos manualmente.

---

### 4. ¬øQu√© hace el job run?

- Configura entorno Conda
- Instala dependencias adicionales
- Clona c√≥digo desde GitHub (commit espec√≠fico)
- Ejecuta script de entrenamiento con argumentos
- Descarga modelo y dataset
- Guarda resultados en Object Storage

---

### 5. Integraci√≥n con LangChain

OCI Generative AI ofrece modelos para:

- ‚úçÔ∏è Generaci√≥n de texto
- üßæ Resumen autom√°tico
- üß† Embeddings

üîπ Estos modelos pueden usarse en **LangChain** junto con ADS.

---

### 6. Autenticaci√≥n

| M√©todo | Uso |
|--------|-----|
| `ads.set_auth()` | Configuraci√≥n por defecto |
| `auth="resource_principal"` | Alternativa expl√≠cita para usar Resource Principal |

---

---

# üîó 4.23 Lecci√≥n: Demo ‚Äì Despliegue de LangChain + RAG en OCI
## üìò Aplicaci√≥n de recuperaci√≥n aumentada con generaci√≥n (RAG)

### 1. Introducci√≥n

En esta demo se muestra c√≥mo **desplegar una aplicaci√≥n RAG basada en LangChain** dentro de OCI Data Science.

---

### 2. Flujo general del despliegue

| Paso | Acci√≥n |
|------|--------|
| 1Ô∏è‚É£ Importar clases necesarias | LangChain, ADS, Generative AI |
| 2Ô∏è‚É£ Autenticarse | Usando `resource principal` |
| 3Ô∏è‚É£ Crear embeddings | Con `GenerativeAIEmbeddings` |
| 4Ô∏è‚É£ Cargar documento | Usando `TextLoader` |
| 5Ô∏è‚É£ Dividir documento | En fragmentos para indexaci√≥n |
| 6Ô∏è‚É£ Crear vector store | Con embeddings + documentos |
| 7Ô∏è‚É£ Crear retriever | Desde el vector store |
| 8Ô∏è‚É£ Crear cadena RAG | Con `RetrievalQA` + LLM + retriever |
| 9Ô∏è‚É£ Crear directorio temporal | Para artefactos del modelo |
| üîü Crear modelo | Usando `ChainDeployment` |

---

### 3. Preparar y verificar el modelo

- Se llama a `.prepare()` para generar artefactos:
  - `score.py`
  - `runtime.yaml`
  - `input_schema.json`
  - `output_schema.json`
  - `model.pkl` o equivalente

- Se verifica el modelo con `.verify()` usando un prompt de prueba:
  - Ejemplo: `"¬øQu√© es el curso AI Foundations?"`

üîπ El modelo responde correctamente ‚Üí listo para guardar.

---

### 4. Guardar y desplegar el modelo

- Se guarda con `.save()` ‚Üí queda registrado en el **Model Catalog**
- Se despliega con `.deploy()` ‚Üí crea endpoint HTTPS

üìå Tiempo estimado de despliegue: **10‚Äì15 minutos**

---

### 5. Invocar el modelo desplegado

- Se usa `.predict()` para enviar preguntas al endpoint
- Ejemplo: `"¬øQui√©nes son los instructores del curso AI Foundations?"`

üîπ El modelo responde con informaci√≥n espec√≠fica extra√≠da del documento original:

> *"Los instructores son Nemant Cahanthari, Himansha Raj y Nick Commisso."*

---

### 6. Conclusi√≥n

- El modelo RAG fue desplegado exitosamente en OCI.
- Puede integrarse en una aplicaci√≥n LLM para responder preguntas basadas en documentos.
- La arquitectura combina:
  - LangChain
  - ADS
  - OCI Generative AI
  - Vector store + retriever

---

---

# ‚öôÔ∏è 4.24 Lecci√≥n: Demo ‚Äì OCI Data Science Operators
## üìò An√°lisis offline con operadores de bajo c√≥digo

### 1. ¬øQu√© son los operadores?

Los **Data Science Operators** son conjuntos de librer√≠as preempaquetadas dise√±adas para tareas espec√≠ficas como:

- üìà Pron√≥stico (Forecasting)
- üö® Detecci√≥n de anomal√≠as (Anomaly Detection)
- üîê Identificaci√≥n de datos personales (PII Detection)

üîπ Son de **bajo c√≥digo**, se ejecutan en notebooks de OCI y pueden invocarse f√°cilmente v√≠a **CLI**.

https://accelerated-data-science.readthedocs.io/en/v2.13.21/user_guide/operators/forecast_operator/quickstart.html


---

### 2. Tipos de operadores disponibles

| Operador | Uso |
|----------|-----|
| **Forecasting** | Predicci√≥n de valores futuros en series temporales |
| **Anomaly Detection** | Identificaci√≥n de valores at√≠picos |
| **PII Detection** | Detecci√≥n y redacci√≥n de informaci√≥n personal (emails, historial laboral, etc.)

---

### 3. Flujo de uso del operador (ejemplo: Forecasting)

| Paso | Acci√≥n |
|------|--------|
| 1Ô∏è‚É£ Instalar entorno Conda | Desde Environment Explorer o CLI |
| 2Ô∏è‚É£ Inicializar operador | `ads op init --output-dir my-forecast` |
| 3Ô∏è‚É£ Editar configuraci√≥n | Modificar `forecast.yml` con par√°metros deseados |
| 4Ô∏è‚É£ Activar entorno Conda | `conda activate <env>` |
| 5Ô∏è‚É£ Ejecutar operador | `ads op run --input forecast.yml` |
| 6Ô∏è‚É£ Revisar resultados | Archivos en `results/`: `forecast.csv`, `report.html`

---

### 4. Archivos generados

- `forecast.csv`: predicciones generadas
- `report.html`: visualizaci√≥n de datos hist√≥ricos + pron√≥stico
- Otros archivos YAML para ejecuci√≥n en distintos entornos

üîπ El reporte incluye:
  - Primeras y √∫ltimas 10 filas
  - Resumen estad√≠stico
  - Overlay de datos hist√≥ricos y predichos

---

### 5. Configuraci√≥n del operador

- El archivo `forecast.yml` define:
  - Dataset
  - Par√°metros del modelo
  - Salida esperada

üîπ Pod√©s copiar la configuraci√≥n desde la documentaci√≥n oficial de ADS.

---

### 6. Uso de otros operadores

#### üîç Anomaly Detection

- Instalar entorno Conda
- Activar entorno
- Inicializar operador
- Ejecutar operador

#### üîê PII Detection

- Instalar entorno Conda
- Activar entorno
- Inicializar operador
- Ejecutar operador

---

### 7. Conclusi√≥n

Los operadores de OCI Data Science permiten ejecutar an√°lisis offline de forma r√°pida y reproducible:

- ‚úÖ Bajo c√≥digo
- ‚úÖ Integraci√≥n con notebooks
- ‚úÖ Resultados exportables

---

---

# ‚ö° 4.25 Lecci√≥n: Demo ‚Äì OCI AI Quick Actions  
## üìò Despliegue r√°pido de LLMs preentrenados en OCI

### 1. ¬øQu√© son las AI Quick Actions?

Una funcionalidad reciente de OCI Data Science que permite:

- üöÄ Desplegar modelos de lenguaje grandes (LLMs) preentrenados
- üõ†Ô∏è Ajustarlos con datasets personalizados (fine-tuning)
- üìä Evaluarlos con datos de prueba
- üîó Integrarlos f√°cilmente en aplicaciones

---

### 2. Acceso desde notebooks

- Disponible directamente en sesiones de notebook de OCI
- Requiere configurar pol√≠ticas espec√≠ficas (ver documentaci√≥n oficial)

---

### 3. Interfaz de AI Quick Actions

Al hacer clic en el bot√≥n **AI Quick Actions**, se accede a tres pesta√±as:

| Pesta√±a | Funci√≥n |
|--------|---------|
| **Models** | Ver y seleccionar LLMs preentrenados |
| **Deployments** | Crear y administrar despliegues |
| **Evaluations** | Evaluar modelos con datasets espec√≠ficos |

---

### 4. Crear un despliegue

Pasos para desplegar un modelo:

1. Ir a la pesta√±a **Deployments**
2. Hacer clic en **Create Deployment**
3. Ingresar un nombre para el despliegue
4. Seleccionar un modelo preentrenado  
   - Ejemplo: `Mistral 7B Instruct v0.02`
5. Elegir forma de c√≥mputo  
   - Ejemplo: `VM.GPU.8NR.1`
6. Seleccionar grupo de logs (opcional)
7. Hacer clic en **Deploy**

üìå El modelo queda disponible como endpoint HTTP para invocaci√≥n v√≠a API.

---

### 5. Probar el modelo desplegado

- Una vez activo, se puede:
  - Ver el estado del modelo
  - Obtener el endpoint para integraci√≥n
  - Ajustar par√°metros del modelo
  - Probar prompts directamente desde la interfaz

üîπ Ejemplo de prompt: `"Tell us about Las Vegas"`  
üîπ El modelo responde con informaci√≥n generada en tiempo real.

---

### 6. Conclusi√≥n

AI Quick Actions permite:

- Desplegar LLMs en minutos
- Probarlos y ajustarlos sin escribir c√≥digo
- Integrarlos f√°cilmente en flujos de trabajo y aplicaciones



---
---
# *** 5. WELCOME TO DATA SCIENCE ***
---
---

# üß© 5.1 Lecci√≥n: MLOps Architecture  
## üìò Arquitectura de MLOps en Oracle Cloud Infrastructure

### 1. ¬øQu√© es MLOps?

**MLOps** (Machine Learning Operations) es el conjunto de pr√°cticas y tecnolog√≠as que permiten:

- Estandarizar, automatizar y escalar el ciclo de vida del ML
- Integrar modelos en producci√≥n junto a los servicios que los consumen
- Asegurar calidad, gobernanza y eficiencia en entornos reales

üîπ Se basa en principios de **DevOps**, adaptados al contexto de datos y modelos.

---

### 2. Comparaci√≥n entre DevOps y MLOps

| Aspecto | DevOps | MLOps |
|--------|--------|-------|
| Ciclo | Build ‚Üí Test ‚Üí Deploy ‚Üí Monitor | Igual, pero con **entrenamiento continuo** |
| Activos | C√≥digo fuente | Datos + modelos ML |
| Cambios | Poco frecuentes | Constantes (por cambio en datos) |
| Automatizaci√≥n | CI/CD | CI/CD + retraining autom√°tico |

üîπ En MLOps, los modelos deben **reentrenarse continuamente** para evitar degradaci√≥n por cambio de datos (data drift).

---

### 3. Niveles de madurez en MLOps

| Nivel | Descripci√≥n |
|-------|-------------|
| **Manual** | Entrenamiento y validaci√≥n manual (ej. Jupyter Notebooks) |
| **Automatizado** | Pipeline de ML automatizado: nuevos datos ‚Üí nuevo modelo |
| **CI/CD completo** | Pipeline de datos + modelo + despliegue automatizado y monitoreado

---

### 4. Flujo de arquitectura MLOps en OCI

```plaintext
üì• Ingesta de datos ‚Üí üìì Desarrollo en Notebooks ‚Üí üîÅ CI/CD DevOps Pipeline
‚Üí üß™ Validaci√≥n interna ‚Üí ‚úÖ Aprobaci√≥n ‚Üí üöÄ Despliegue en producci√≥n ‚Üí üë§ Aplicaci√≥n al usuario final
```

üîπ El pipeline DevOps ejecuta el entrenamiento y guarda el modelo en el **Model Catalog**  
üîπ El pipeline de despliegue lo publica como endpoint  
üîπ El monitoreo continuo verifica m√©tricas de rendimiento y puede disparar reentrenamiento

![alt text](image.png)

---

### 5. Componentes clave en OCI

| Componente | Rol en MLOps |
|------------|--------------|
| **Jupyter Notebooks** | Desarrollo y experimentaci√≥n |
| **OCI DevOps** | CI/CD pipelines para ML |
| **Model Catalog** | Registro y versionado de modelos |
| **Endpoints internos** | Validaci√≥n previa al despliegue |
| **Aplicaciones finales** | Consumen el modelo en producci√≥n |
| **Monitoring & Logging** | Verifican rendimiento y disparan retraining

---

### 6. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es MLOps y c√≥mo se diferencia de DevOps
- Por qu√© el reentrenamiento continuo es esencial
- C√≥mo evoluciona la automatizaci√≥n en MLOps
- C√≥mo se estructura una arquitectura MLOps en OCI
- Qu√© componentes participan en cada etapa

---

---

# ‚öôÔ∏è 5.2 Lecci√≥n: Data Science Jobs  
## üìò Automatizaci√≥n de tareas y procesamiento por lotes en OCI

### 1. ¬øQu√© es el servicio Jobs?

El servicio **Jobs** forma parte de OCI Data Science y es clave para implementar **MLOps**.  
Permite definir y ejecutar tareas repetibles sobre infraestructura gestionada, que se **provisiona solo cuando se ejecuta el job**, optimizando costos.

---

### 2. Usos t√≠picos

- üìä Preparaci√≥n de datos  
- üß† Entrenamiento de modelos  
- üì¶ Inferencia por lotes  
- üîÅ Automatizaci√≥n de etapas del ciclo ML

üîπ Puede usarse para automatizar una o varias etapas del flujo MLOps, seg√∫n el tama√±o del proyecto.

---

### 3. Beneficios del servicio

| Beneficio | Descripci√≥n |
|-----------|-------------|
| **Infraestructura gestionada** | No requiere instalar software ni servidores |
| **Integraci√≥n nativa OCI** | Acceso seguro a bases de datos, redes, seguridad |
| **Provisionamiento bajo demanda** | Solo se paga por el tiempo de ejecuci√≥n |

---

### 4. Conceptos clave

| Concepto | Descripci√≥n |
|----------|-------------|
| **Job** | Plantilla que define la tarea, infraestructura y artefacto |
| **Job Run** | Ejecuci√≥n individual del job, con par√°metros personalizados |

---

### 5. Componentes de un Job

- **Job Artifact**: instrucciones del job (inmutable)
- **Compute Shape**: tipo de m√°quina (editable entre ejecuciones)
- **Variables de entorno / argumentos CLI**: configurables por job o por ejecuci√≥n
- **Opciones de red, almacenamiento y logging**
- **Tiempo m√°ximo de ejecuci√≥n**: 30 d√≠as

![alt text](image-2.png)

---

### 6. Ciclo de vida de un Job

```plaintext
üì¶ Crear Job ‚Üí ‚ñ∂Ô∏è Ejecutar Job Run ‚Üí üìä Monitorear y registrar ‚Üí ‚úÖ Completar o cancelar ‚Üí üßπ Deprovisionar recursos
```

üîπ Se pueden ejecutar m√∫ltiples Job Runs secuenciales o simult√°neos con distintos par√°metros (ej. hiperpar√°metros)

![alt text](image-1.png)
![alt text](image-4.png)
---

### 7. Tipos de artefactos soportados

| Tipo | Uso |
|------|-----|
| **Python / Bash** | Proyectos simples (archivo √∫nico) |
| **ZIP / TAR** | Proyectos complejos con m√∫ltiples scripts |
| **YAML** | Configuraci√≥n de entorno y variables |
| **JOB_RUN_ENTRYPOINT** | Define el script principal en artefactos comprimidos

---

### 8. Acceso y gesti√≥n

- Jobs pueden acceder a todos los recursos OCI si las pol√≠ticas est√°n configuradas
- Soporte para redes privadas (VCN) y autenticaci√≥n v√≠a Vault
- Interfaces soportadas:
  - OCI Console
  - OCI CLI
  - SDKs: Python, Java, JS, Go, Ruby, Terraform
  - CI/CD: GitHub, Bitbucket, MLOps pipelines

  ![alt text](image-5.png)

---

### 9. Tipos de inferencia por lotes

| Tipo | Descripci√≥n | Ejemplo |
|------|-------------|---------|
| **Regular Batch** | Procesa grandes vol√∫menes peri√≥dicamente | An√°lisis diario de ventas |
| **Mini Batch** | Procesa datos frecuentes en peque√±as cantidades | Detecci√≥n de fraude bancario cada 5 min |
| **Distributed Batch** | Divide datos en chunks y ejecuta en paralelo | Procesamiento masivo de im√°genes satelitales

üîπ Mini batches son r√°pidos y livianos  
üîπ Distributed batches son pesados y paralelos  
üîπ Regular batches est√°n en el medio

![alt text](image-6.png)
---

### 10. Escalabilidad

- Pod√©s **escalar recursos** editando:
  - Compute Shape
  - Tama√±o de Block Storage
- Aplica tanto a Jobs como a Notebook Sessions

---

### 11. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es el servicio Jobs y c√≥mo habilita MLOps
- C√≥mo definir y ejecutar tareas automatizadas
- Qu√© tipos de artefactos y ejecuciones se soportan
- C√≥mo acceder desde terceros y escalar recursos
- Qu√© tipos de inferencia por lotes existen y cu√°ndo usarlos

---

---

# üß± 5.3 Lecci√≥n: Demo ‚Äì Create Artifacts  
## üìò C√≥mo crear artefactos para Jobs en OCI Data Science

### 1. ¬øQu√© es un Job Artifact?

Un **job artifact** es el archivo que contiene el c√≥digo que ser√° ejecutado por un Job. Puede ser:

- üêç Un archivo Python (.py)
- üñ•Ô∏è Un script Bash (.sh)
- üì¶ Un proyecto completo comprimido en `.zip` o `.tar`

üîπ No hay requisitos especiales sobre c√≥mo escribir el c√≥digo.  
üîπ En esta demo se muestra un ejemplo b√°sico con un archivo Python.

---

### 2. Ejemplo b√°sico: Python minimal

```python
print("Job started")
print("Job finished")
```

üîπ Luego se extiende para incluir:

- üïí Timestamp de inicio
- üìõ Lectura de variable de entorno `name`
- üí¨ Lectura de argumento de l√≠nea de comandos `--greeting` o `-g`

---

### 3. Lectura de variables y argumentos

```python
import os
import argparse
from datetime import datetime

print(f"Job started at {datetime.now()}")

name = os.getenv("name")
print(f"Name: {name}")

parser = argparse.ArgumentParser()
parser.add_argument("-g", "--greeting", required=True)
args = parser.parse_args()

print(f"{args.greeting}, {name}")
```

üîπ C√≥digo est√°ndar de Python, sin requerimientos espec√≠ficos de OCI

---

### 4. Uso del OCI SDK y Resource Principal

- Se agrega soporte para autenticaci√≥n con **Resource Principal**
- El c√≥digo detecta si se ejecuta localmente o como Job en OCI
- Se inicializa el SDK seg√∫n el entorno

üîπ Esto permite acceder a servicios OCI (ej. Object Storage) desde el Job

---

### 5. Recomendaciones

- ‚úÖ Probar el c√≥digo localmente antes de subirlo como artifact
- ‚úÖ Usar variables de entorno y argumentos para parametrizar ejecuciones
- ‚úÖ Incluir autenticaci√≥n con Resource Principal si se accede a otros servicios OCI
- ‚úÖ Comprimir el proyecto si incluye m√∫ltiples archivos o dependencias

---

### 6. Pr√≥ximo paso

En la siguiente parte de la demo se mostrar√° c√≥mo:

- Crear el Job en OCI Console
- Subir el artifact
- Ejecutar el Job con par√°metros personalizados

---

---

# ‚öôÔ∏è 5.4 Lecci√≥n: Demo ‚Äì Create and Manage Jobs  
## üìò C√≥mo crear y gestionar Jobs en OCI Data Science

### 1. Acceder al servicio

- Iniciar sesi√≥n en tu tenancy de Oracle Cloud
- Ir al men√∫ hamburguesa ‚Üí **Analytics and AI ‚Üí Machine Learning ‚Üí Data Science**
- Crear un proyecto si no ten√©s uno:
  - Clic en **Create Project**
  - Ingresar nombre y descripci√≥n
  - Clic en **Create**

---

### 2. Crear un Job

1. Dentro del proyecto, seleccionar **Jobs** en el panel izquierdo  
2. Clic en **Create Job**

üîπ En la pantalla de creaci√≥n:

- Cambiar el **compartimento** si es necesario
- Ingresar nombre y descripci√≥n (opcional)
- Subir el **job artifact** (ej. archivo Python)
  - L√≠mite: 100 MB v√≠a consola
  - Para archivos m√°s grandes, usar OCI SDK

---

### 3. Configurar par√°metros del Job

| Par√°metro | Descripci√≥n |
|-----------|-------------|
| **Environment Variables** | Ej. `name = Claudio` |
| **Command Line Arguments** | Ej. `-g Hey` |
| **Max Runtime** | Ej. `100` minutos |
| **Compute Shape** |  
  - **Fast Launch**: preconfigurados, arranque r√°pido  
  - **Custom**: incluye GPU e Intel fuera del pool prewarm |
| **Logging** |  
  - Activar logs autom√°ticos  
  - Seleccionar grupo de logs |
| **Block Storage** |  
  - Tama√±o seg√∫n necesidad del procesamiento |
| **Networking** |  
  - Default: acceso a internet y servicios OCI  
  - Custom: usar VCN y subnet propios |

---

### 4. Finalizar creaci√≥n

- Clic en **Create**
- El Job queda creado con:
  - Informaci√≥n general
  - Artifact subido
  - Configuraci√≥n de infraestructura y logging

üîπ El Job a√∫n no se ejecuta ‚Üí requiere iniciar un **Job Run**

---

### 5. Revisar y editar el Job

- Ver configuraciones: argumentos, tiempo m√°ximo, variables
- Clic en **Edit** para modificar:
  - Nombre, descripci√≥n
  - Compute shape, almacenamiento
- Clic en **Save** para guardar cambios

üîπ Tambi√©n pod√©s:

- Descargar el artifact
- Mover el Job a otro compartimento
- Agregar etiquetas
- Eliminar el Job

---

---

# ‚ñ∂Ô∏è 5.5 Lecci√≥n: Demo ‚Äì Start and Manage a Job Run  
## üìò C√≥mo iniciar, monitorear y gestionar ejecuciones de Jobs en OCI

### 1. Iniciar una Job Run

- Ir al Job creado en la consola de OCI
- Clic en **Start Job Run**

üîπ Se abre una pantalla para ajustar par√°metros:

| Par√°metro | Descripci√≥n |
|-----------|-------------|
| **Logging** | Activar/desactivar, elegir grupo de logs |
| **Variables de entorno** | Ej. `name = Claudio` |
| **Argumentos CLI** | Ej. `-g Hey` |
| **Tiempo m√°ximo** | Ej. `100` minutos |

Clic en **Start** para iniciar la ejecuci√≥n.

---

### 2. Estados del ciclo de vida

| Estado | Descripci√≥n |
|--------|-------------|
| **Accepted** | Job Run aceptada |
| **Provisioning** | Se prepara la infraestructura |
| **Running** | Se ejecuta el artifact |
| **Completed / Failed / Cancelled** | Finalizaci√≥n exitosa, con error o cancelada |

üîπ Solo se paga durante la ejecuci√≥n activa del Job

---

### 3. Ejecuciones paralelas

- Pod√©s iniciar m√∫ltiples Job Runs al mismo tiempo
- √ötil para probar distintos par√°metros (ej. hiperpar√°metros)
- Cada ejecuci√≥n puede tener variables o argumentos distintos

---

### 4. Diagn√≥stico de errores

- Si una Job Run falla:
  - Clic en la ejecuci√≥n fallida
  - Acceder al **log file**
  - Revisar el error y ajustar el c√≥digo o par√°metros

---

### 5. Gesti√≥n de Job Runs

| Acci√≥n | Descripci√≥n |
|--------|-------------|
| **Editar Job** | Cambiar nombre, descripci√≥n, shape, storage |
| **Clonar Job Run** | Reutiliza configuraci√≥n previa, permite modificar valores puntuales |
| **Eliminar Job** | Clic en **Delete**, confirmar eliminaci√≥n |
| **Cancelar Job Run** | Clic en **Cancel**, confirmar ‚Üí detiene ejecuci√≥n y facturaci√≥n

üîπ La opci√≥n de **clonar** est√° disponible solo en la consola web de OCI

---

### 6. Flujo de cancelaci√≥n

1. Iniciar una Job Run (puede ser clonada)
2. Esperar a que se habilite el bot√≥n **Cancel**
3. Clic en **Cancel**
4. Confirmar cancelaci√≥n

üîπ La cancelaci√≥n puede hacerse en cualquier estado (provisioning o ejecuci√≥n)  
üîπ La facturaci√≥n se detiene inmediatamente

---

### 7. Conclusi√≥n

En esta demo aprendiste:

- C√≥mo iniciar y configurar una Job Run
- C√≥mo monitorear su estado y revisar logs
- C√≥mo ejecutar m√∫ltiples Jobs en paralelo
- C√≥mo clonar, cancelar o eliminar Jobs
- C√≥mo evitar costos innecesarios con cancelaci√≥n temprana

---

---

# üìà 5.6 Lecci√≥n: Demo ‚Äì Scaling  
## üìò C√≥mo escalar Jobs y Notebooks en OCI Data Science

### 1. ¬øPor qu√© escalar?

Si detect√°s que el uso de CPU, memoria o almacenamiento es alto durante la ejecuci√≥n de un Job o Notebook, pod√©s **ajustar los recursos** para mejorar el rendimiento.

---

### 2. Escalar un Job

1. Seleccion√° el Job en la consola  
2. Clic en **Edit**

üîπ Pod√©s modificar:

| Par√°metro | Descripci√≥n |
|-----------|-------------|
| **Compute Shape** | Cambiar a una forma con m√°s OCPUs o memoria (ej. GPU para entrenamiento) |
| **Block Storage** | Aumentar tama√±o si el anterior no es suficiente |

3. Clic en **Save Changes**  
4. Iniciar un nuevo Job Run ‚Üí usar√° la nueva configuraci√≥n

---

### 3. Escalar un Notebook Session

1. Monitorear m√©tricas de CPU y memoria  
2. Si est√°n al m√°ximo, proceder a escalar

üîπ Pasos:

| Acci√≥n | Descripci√≥n |
|--------|-------------|
| **Deactivate Notebook** | Clic en **Deactivate** ‚Üí confirmar |
| **Importante** | Se detiene la facturaci√≥n, pero **no se borra el block storage** |
| **Activate Notebook** | Clic en **Activate** ‚Üí seleccionar nueva shape y tama√±o de almacenamiento |

---

### 4. Opciones de Compute Shape

| Tipo | Uso recomendado |
|------|-----------------|
| **Intel shape** | M√°s OCPUs y memoria |
| **GPU shape** | Entrenamiento intensivo |
| **Fast launch shape** | Arranque r√°pido (preconfigurado) |

üîπ Tambi√©n pod√©s aumentar el tama√±o del block storage durante la activaci√≥n

---

### 5. Conclusi√≥n

En esta demo aprendiste:

- C√≥mo escalar Jobs y Notebooks en OCI
- Qu√© par√°metros ajustar: shape y almacenamiento
- C√≥mo hacerlo sin perder datos
- C√≥mo optimizar recursos seg√∫n el tipo de tarea

---
Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de la lecci√≥n *Jobs Monitoring and Logging*, estructurada como ficha t√©cnica para tu manual de OCI Data Science.

---

# üìä 5.7 Lecci√≥n: Jobs Monitoring and Logging  
## üìò Monitoreo, logging y eventos en Jobs de OCI Data Science

### 1. ¬øPor qu√© monitorear y registrar?

El monitoreo y logging es la **√∫ltima etapa del ciclo de vida de un Job**, antes de que se desprovisione la infraestructura.  
Permite:

- Obtener m√©tricas de rendimiento
- Diagnosticar errores
- Registrar ejecuciones para auditor√≠a o referencia futura

---

### 2. Monitoreo: m√©tricas y alarmas

| Componente | Funci√≥n |
|------------|---------|
| **M√©tricas** | Seguimiento activo de CPU, GPU, memoria, red, disco |
| **Alarmas** | Notificaciones autom√°ticas cuando se superan umbrales definidos |
| **Notificaciones** | Env√≠o de alertas por Slack, SMS, email, etc. |

üîπ Ejemplo: alarma si CPU > 80% ‚Üí se dispara notificaci√≥n

![alt text](image-7.png)

---

### 3. M√©tricas disponibles

- Uso de CPU y GPU (seg√∫n shape)
- Uso de memoria
- Tr√°fico de red (bytes in/out)
- Uso de disco

üîπ Si se superan ciertos umbrales, pod√©s **escalar recursos** (shape, almacenamiento)

---

### 4. Logging: tipos y configuraci√≥n

| Tipo de log | Descripci√≥n |
|-------------|-------------|
| **Service Logs** | Logs est√°ndar (stdout y stderr) enviados al servicio de logging de OCI |
| **Custom Logs** | Logs definidos por el usuario, con ubicaci√≥n personalizada |

üîπ Requiere permisos adecuados del **resource principal** para escribir en los logs

---

### 5. Opciones de logging

- Activar logging es **opcional pero recomendado**
- Pod√©s:
  - Usar un log por Job Run
  - Compartir un log entre m√∫ltiples ejecuciones
- Activar **creaci√≥n autom√°tica de logs** al iniciar cada Job Run
- Los logs **no se eliminan** al borrar el Job o sus ejecuciones

---

### 6. Event Service: eventos y automatizaci√≥n

| Elemento | Funci√≥n |
|----------|--------|
| **Eventos** | Mensajes estructurados que indican cambios (create, read, update, delete) |
| **Reglas** | Filtran eventos relevantes |
| **Acciones** | Respuestas autom√°ticas: notificaciones, funciones, streaming |

üîπ Garantiza **al menos una entrega** por acci√≥n configurada

![alt text](image-8.png)

---

### 7. Conclusi√≥n

En esta lecci√≥n aprendiste:

- C√≥mo usar m√©tricas y alarmas para monitorear Jobs
- Qu√© tipos de logs existen y c√≥mo configurarlos
- C√≥mo usar el Event Service para automatizar respuestas a eventos
- Por qu√© el monitoreo y logging son claves para MLOps y trazabilidad

---

---

# üîÑ 5.8 Lecci√≥n: Data Science Pipeline  
## üìò Automatizaci√≥n de flujos ML con pipelines en OCI

### 1. ¬øQu√© es un pipeline?

Un **pipeline** es una nueva funcionalidad del servicio OCI Data Science que permite:

- Ejecutar flujos de trabajo de ML de extremo a extremo
- Compuestos por m√∫ltiples **steps** (etapas)
- Cada step puede usar distintos lenguajes o entornos (ej. Python, Java)

üîπ Ejemplos de steps: procesamiento de datos, entrenamiento, evaluaci√≥n, despliegue

---

### 2. Ejecuci√≥n secuencial o paralela

- Por defecto, los steps se ejecutan en **paralelo**
- Pod√©s definir **dependencias** para forzar ejecuci√≥n **secuencial**
- Esto permite construir flujos l√≥gicos como:

```plaintext
Step 1 ‚Üí Step 2a, 2b, 2c ‚Üí Step 3 ‚Üí Step N
```

---

### 3. Configuraci√≥n del pipeline

| Par√°metro | Nivel | Descripci√≥n |
|-----------|-------|-------------|
| **Compute Shape** | Pipeline | Tipo de m√°quina para ejecutar |
| **Block Volume** | Pipeline | Almacenamiento asociado |
| **Variables de entorno** | Pipeline | Ej. ubicaci√≥n de datos |
| **Logging** | Pipeline | Configuraci√≥n de logs |
| **Max Runtime** | Pipeline | Tiempo m√°ximo de ejecuci√≥n |

üîπ Los steps pueden **sobrescribir** la configuraci√≥n por defecto del pipeline

---

### 4. Tipos de steps

| Tipo | Descripci√≥n |
|------|-------------|
| **Script** | Artifact en Python, Bash o Java (archivo √∫nico o comprimido) |
| **Job** | Referencia a un Job precreado (via OCID) |

üîπ Los steps pueden acceder a recursos OCI (Object Storage, DB) si se configuran las **pol√≠ticas** y la **VCN** adecuadas

---

### 5. Ciclo de vida del pipeline

| Estado | Descripci√≥n |
|--------|-------------|
| **Creating** | Se est√° creando el recurso |
| **Active** | Listo para ejecutar |
| **Pipeline Run** | Instancia de ejecuci√≥n (puede haber varias) |
| **Deleted** | Eliminado cuando ya no se necesita

![alt text](image-9.png)
---

### 6. Ejemplo de demostraci√≥n

| Step | Acci√≥n |
|------|--------|
| **Step 1** | Leer archivo desde Object Storage ‚Üí limpiar columnas, codificar, escalar, dividir en train/test ‚Üí guardar en Object Storage |
| **Step 2** | Entrenar 3 modelos (Linear Regression, Random Forest, XGBoost) ‚Üí guardar en Model Catalog |
| **Step 3** | Recuperar modelos ‚Üí seleccionar el mejor ‚Üí desplegar modelo |

üîπ Se usan **variables de pipeline** para pasar informaci√≥n entre steps

---

### 7. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es un pipeline y c√≥mo se estructura
- C√≥mo configurar y ejecutar steps con distintos lenguajes
- C√≥mo definir dependencias y automatizar flujos ML
- C√≥mo usar recursos OCI dentro de un pipeline
- Ejemplo pr√°ctico de un pipeline completo

---

---

# üîÑ 5.9 Lecci√≥n: Demo ‚Äì Data Science Pipeline  
## üìò C√≥mo crear y ejecutar un pipeline de ML de extremo a extremo

### 1. Repositorio de c√≥digo

- Usamos el repositorio oficial: **OCI Data Science AI Samples** en GitHub
- Descargamos el ZIP ‚Üí carpeta local ‚Üí `pipelines/samples/employee-attrition`
- Contiene m√∫ltiples archivos `.zip` para cada step del pipeline

---

### 2. Crear el pipeline

1. Ir al proyecto de Data Science en OCI Console  
2. Clic en **Pipeline > Create Pipeline**

üîπ Configuraci√≥n general:

| Par√°metro | Valor |
|----------|-------|
| **Nombre** | `employee-attrition-pipeline` |
| **Descripci√≥n** | `demo` |
| **Variable de entorno** | `data_location = pipeline-temp-bucket` |
| **Compute Shape** | `VM.Standard2.2` |
| **Block Storage** | `50 GB` |
| **Log Group** | Precreado y seleccionado |

---

### 3. Crear los steps

| Step | Descripci√≥n | Artifact | Entry Point | Dependencias |
|------|-------------|----------|-------------|--------------|
| **Step 1** | Procesamiento de datos | `dataproc.zip` | `dataproc.py` | Ninguna |
| **Step 2a** | Entrenamiento LR | `lr.zip` | `lr.py` | Step 1 |
| **Step 2b** | Entrenamiento RF | `rf.zip` | `rf.py` | Step 1 |
| **Step 2c** | Entrenamiento XGB | `xgb.zip` | `xgb.py` | Step 1 |
| **Step 3** | Evaluaci√≥n y despliegue | `evaluate_deploy.zip` | `evaluate_deploy.py` | Steps 2a, 2b, 2c |

üîπ Todos los steps son de tipo **script**  
üîπ Se ejecutan en paralelo salvo Step 3, que espera los anteriores

---

### 4. Ejecutar el pipeline

1. Clic en **Start Pipeline Run**
2. Nombre del run: `Run-11`
3. Configurar entorno para cada step:
   - Tipo: `CONDA_ENV_SLUG`
   - Se repite para todos los steps

---

### 5. Monitorear ejecuci√≥n

- Estado inicial: `waiting` ‚Üí `accepted` ‚Üí `in progress` ‚Üí `succeeded`
- Logs disponibles por step
- AUC scores registrados:

| Modelo | AUC |
|--------|-----|
| Linear Regression | 0.85 ‚úÖ |
| Random Forest | 0.81 |
| XGBoost | 0.837 |

üîπ El modelo con mejor AUC (LR) fue **desplegado autom√°ticamente**

---

### 6. Verificar resultados

- Ir a **Project Details > Models**
- Ver modelo seleccionado y desplegado
- Confirmar que el pipeline ejecut√≥ todo el flujo de ML de forma automatizada

---

### 7. Conclusi√≥n

En esta demo aprendiste:

- C√≥mo crear un pipeline con m√∫ltiples steps
- C√≥mo configurar artefactos, entry points y dependencias
- C√≥mo ejecutar y monitorear el pipeline
- C√≥mo seleccionar y desplegar el mejor modelo autom√°ticamente

---
Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de la lecci√≥n *Model Deployment: Autoscaling*, estructurada como ficha t√©cnica para tu manual de OCI Data Science.

---

# üìà 5.10 Lecci√≥n: Model Deployment ‚Äì Autoscaling  
## üìò Escalado autom√°tico de despliegues de modelos en OCI

### 1. ¬øPor qu√© usar autoscaling?

El autoscaling permite ajustar autom√°ticamente la cantidad de instancias de un modelo desplegado seg√∫n la demanda, resolviendo el dilema entre:

- Disponibilidad constante y rendimiento √≥ptimo  
- Eficiencia de costos ante cargas variables e impredecibles

---

### 2. ¬øC√≥mo funciona?

- Defin√≠s un **rango de instancias** (m√≠nimo y m√°ximo)
- El servicio escala autom√°ticamente **hacia arriba o hacia abajo**
- Se basa en **m√©tricas de uso** (ej. CPU, memoria)
- Pod√©s definir **umbrales de activaci√≥n** y **per√≠odos de enfriamiento**

---

### 3. Beneficios clave

| Beneficio | Descripci√≥n |
|-----------|-------------|
| **Ajuste din√°mico** | Escala recursos seg√∫n demanda en tiempo real |
| **Eficiencia de costos** | Solo se usan y pagan los recursos necesarios |
| **Alta disponibilidad** | Con balanceador de carga, se redirige tr√°fico ante fallos |
| **Triggers personalizables** | Us√° expresiones NQL para definir condiciones |
| **Compatibilidad con Load Balancer** | Escala autom√°ticamente el ancho de banda |
| **Cooldown period** | Evita escalados excesivos en poco tiempo |

![alt text](image-10.png)

---

### 4. Tipos de autoscaling

| Tipo | Descripci√≥n |
|------|-------------|
| **Predefinido** | Basado en CPU o memoria, con umbrales fijos |
| **Personalizado (NQL)** | Us√°s cualquier m√©trica del modelo con expresiones NQL avanzadas |

üîπ Solo se puede tener **una pol√≠tica de autoscaling activa** por despliegue

---

### 5. M√©tricas disponibles

- CPU / Memoria
- ID de recurso
- C√≥digo y familia de estado
- ID de instancia
- Resultado
- Tipo de red

üîπ Las m√©tricas se emiten autom√°ticamente desde el recurso de despliegue  
üîπ No es necesario habilitar el servicio de monitoreo

---

### 6. Pol√≠tica requerida

Para que autoscaling funcione, agreg√° esta pol√≠tica a tu tenancy:

```plaintext
allow service autoscaling to read metrics in tenancy where target.metrics.namespace='oci_datascience_modeldeploy'
```

---

### 7. Consideraciones de configuraci√≥n

| Estado del despliegue | Qu√© se puede modificar |
|------------------------|------------------------|
| **Activo** | Solo campos de pol√≠tica de autoscaling (no simult√°neos con otros cambios) |
| **Inactivo** | Se pueden modificar todas las opciones a la vez |

üîπ Pod√©s crear despliegues con autoscaling desde:
- OCI Console
- OCI CLI
- Data Science API

---

### 8. Recomendaciones

- Us√° autoscaling para cargas variables o impredecibles
- Combin√° con Load Balancer para mayor disponibilidad
- Us√° m√©tricas personalizadas si necesit√°s control fino
- Defin√≠ cooldowns adecuados para evitar sobreescalado

---

### 9. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es y c√≥mo funciona el autoscaling en despliegues de modelos
- Qu√© m√©tricas y pol√≠ticas se requieren
- C√≥mo configurarlo con triggers predefinidos o personalizados
- C√≥mo mantener eficiencia, disponibilidad y control de costos

---

Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de la lecci√≥n final *Expert Tips: Pipelines*, estructurada como cierre de unidad para tu manual de OCI Data Science.

---

# üß† 5.11 Lecci√≥n final: Expert Tips ‚Äì Pipelines  
## üìò Recomendaciones para automatizar flujos de ML en OCI

### 1. Felicitaciones

Has llegado al final de esta unidad sobre **OCI Data Science Pipelines**.  
üéâ ¬°Felicitaciones por tu progreso y compromiso!

---

### 2. ¬øPor qu√© usar Pipelines?

- Permiten automatizar flujos completos de machine learning
- Incluyen m√∫ltiples etapas como:
  - Extracci√≥n de datos
  - Validaci√≥n
  - Preparaci√≥n
  - Entrenamiento
  - Evaluaci√≥n
  - Despliegue


  Pipelines, doc: https://docs.oracle.com/en-us/iaas/Content/data-science/using/pipelines-about.htm

üîπ Las etapas pueden ejecutarse en **secuencia** o en **paralelo**, seg√∫n tus necesidades

---

### 3. Recomendaci√≥n experta

> ‚ÄúPipelines es una funcionalidad muy poderosa para automatizar flujos de ML.  
> Recomiendo revisar la documentaci√≥n oficial y explorar su uso en tus proyectos.‚Äù  
> ‚Äî Hemant Gahankari, Oracle University

---

### 4. Conclusi√≥n de la unidad

En esta unidad aprendiste:

- Qu√© es un pipeline y c√≥mo se estructura
- C√≥mo crear, configurar y ejecutar pipelines en OCI
- C√≥mo integrar jobs, scripts, artefactos y dependencias
- C√≥mo monitorear, registrar y escalar tus ejecuciones
- C√≥mo seleccionar y desplegar el mejor modelo autom√°ticamente




---
---
# *** 6. Related OCI Services (Servicios de OCI Relacionados) ***
---
---


# üî• 6.1 Lecci√≥n: Spark Applications, Data Flow y Data Science
## üìò Procesamiento escalable y flujos Spark en OCI

### 1. Introducci√≥n a OCI Data Flow

**Data Flow** es un servicio serverless para ejecutar aplicaciones Apache Spark a gran escala.  
Permite a desarrolladores y cient√≠ficos de datos:

- Ejecutar cargas de trabajo de big data y ML
- Usar cualquier lenguaje Spark: PySpark, SQL, Java, Scala
- Realizar tareas como:
  - Agregaci√≥n y transformaci√≥n de datos
  - Ingenier√≠a de features
  - Limpieza y joins

üîπ Incluye **MLlib**, la librer√≠a de ML nativa de Spark  
üîπ Tambi√©n se pueden usar otras librer√≠as si se programa en Python

---

### 2. Caracter√≠sticas clave

| Componente | Descripci√≥n |
|------------|-------------|
| **Serverless** | No requiere cl√∫steres ni infraestructura |
| **Batch on demand** | Ejecuci√≥n por demanda v√≠a REST API |
| **UI rica** | Crear, editar y ejecutar jobs Spark desde consola |
| **Seguridad** | IAM integrado, datos cifrados, logs en Object Storage |
| **Compatibilidad** | Ideal para datos en Object Storage, admite conectores personalizados |

---

### 3. Componentes de Data Flow

| Elemento | Rol |
|---------|-----|
| **Library** | Repositorio central de aplicaciones Spark |
| **Application** | Plantilla reutilizable con c√≥digo, dependencias y configuraci√≥n |
| **Run** | Ejecuci√≥n individual de una aplicaci√≥n |
| **Logs** | Archivos generados por Spark, almacenados autom√°ticamente en Object Storage

---

### 4. Ventajas para ML y AI

- Motor escalable para ETL, procesamiento y entrenamiento
- Alternativa a Jobs para tareas de wrangling o entrenamiento
- Compatible con SQL y dataframes
- MLlib ofrece algoritmos listos para entrenar sobre Spark DataFrames

---

### 5. Arquitectura de ejecuci√≥n Spark

```plaintext
Driver ‚Üí Cluster Manager ‚Üí Worker Nodes ‚Üí Executors
```

- **SparkContext**: punto de entrada
- **Driver**: coordina ejecuci√≥n
- **Executors**: ejecutan tareas distribuidas
- Se elige:
  - Shape del driver
  - Shape y cantidad de executors

üîπ Ejemplo: 500 GB en 10 horas ‚Üí ~5 OCPUs

---

### 6. Integraci√≥n con ADS

- ADS SDK permite:
  - Crear y ejecutar aplicaciones Data Flow
  - Usar desde notebooks
  - Sincronizar scripts PySpark
  - Consultar logs y listar aplicaciones

---

### 7. Prerrequisitos para usar Data Flow con Data Science

| Requisito | Descripci√≥n |
|-----------|-------------|
| ‚úÖ Usuario con permisos |
| ‚úÖ Proyecto y notebook en Data Science |
| ‚úÖ Bucket para logs |
| ‚úÖ Aplicaci√≥n Spark en Object Storage |
| ‚úÖ Datos en Object Storage |
| ‚úÖ Pol√≠ticas de acceso configuradas |

---

### 8. Buenas pr√°cticas desde notebooks

- Usar **muestras de datos** para desarrollo
- Dividir c√≥digo en celdas
- Convertir Spark DataFrames a pandas para visualizaci√≥n
- Usar `matplotlib` para gr√°ficos
- Convertir notebook a script con:

```bash
jupyter nbconvert --to script my-notebook.ipynb
```

- Probar localmente con:

```bash
spark-submit my-script.py
```

- Eliminar referencias a librer√≠as externas (pandas, sklearn, etc.)
- Consultar documentaci√≥n para agregar librer√≠as al entorno de Data Flow

---

### 9. Operaciones comunes con ADS

- Cargar aplicaciones existentes
- Listar aplicaciones
- Consultar logs
- Sincronizar scripts
- Definir argumentos y par√°metros
- Agregar librer√≠as externas

---

### 10. Recapitulaci√≥n del m√≥dulo

En esta lecci√≥n cubrimos:

- Una **visi√≥n general de OCI Data Flow** como servicio serverless para ejecutar Spark
- C√≥mo **interact√∫a con OCI Data Science**, especialmente desde notebooks
- Buenas pr√°cticas para desarrollar aplicaciones **PySpark** dentro de sesiones de notebook

---

### 11. Recomendaciones finales

‚úÖ Us√° muestras de datos para desarrollo  
‚úÖ Iter√° tu c√≥digo en celdas y visualiz√° resultados  
‚úÖ Convert√≠ tu notebook en script con `nbconvert`  
‚úÖ Prob√° localmente con `spark-submit`  
‚úÖ Elimin√° dependencias externas no compatibles con Spark  
‚úÖ Consult√° la documentaci√≥n oficial para agregar librer√≠as a Data Flow  
‚úÖ Us√° el SDK de ADS para gestionar aplicaciones y ejecuciones

---

### 12. Cierre

> ‚ÄúData Flow es una herramienta poderosa para escalar procesamiento y entrenamiento en ML.  
> Su integraci√≥n con Data Science notebooks permite desarrollar, probar y ejecutar flujos Spark de forma eficiente.‚Äù  
> ‚Äî Hemant Gahankari, Oracle University

---

Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de la lecci√≥n *Oracle Open Data*, estructurada como ficha t√©cnica para tu manual de OCI Data Science.

---

# üåç 6.2 Lecci√≥n: Oracle Open Data  
## üìò Repositorio abierto de datos cient√≠ficos para investigaci√≥n y ciencia de datos

### 1. ¬øQu√© es Oracle Open Data?

**Oracle Open Data** es un servicio de Oracle for Research que:

- Proporciona acceso libre a grandes conjuntos de datos cient√≠ficos
- Est√° dise√±ado para quienes **crean, usan o manipulan datasets**
- No requiere login ni pago

üîπ Ideal para investigadores, cient√≠ficos de datos y desarrolladores de IA/ML

---

### 2. Tipos de datos disponibles

| Categor√≠a | Ejemplos |
|-----------|----------|
| **Geoespaciales** | Im√°genes satelitales: GOES, MODIS, Landsat |
| **Ciencias de la vida** | Compuestos qu√≠micos, secuencias de prote√≠nas, im√°genes CT, datos gen√≥micos |
| **IA y ML** | Im√°genes, corpus de libros en texto y audio |

---

### 3. Beneficios clave

- ‚úÖ Datos confiables y accesibles
- ‚úÖ Curados y listos para usar
- ‚úÖ Actualizaciones frecuentes
- ‚úÖ Ejemplos de c√≥digo y herramientas para reproducibilidad
- ‚úÖ Navegaci√≥n y descarga sencilla desde la plataforma

üîπ Fuentes reconocidas: NASA, DeepMind, Stanford, entre otras

---

### 4. Acceso al repositorio

- Sitio web: [opendata.oraclecloud.com](https://opendata.oraclecloud.com)
- Clic en **Explore Repository** para navegar los datasets

---

### 5. Conclusi√≥n

Oracle Open Data es un recurso valioso para:

- Acceder a datos abiertos de alta calidad
- Desarrollar proyectos de investigaci√≥n, ciencia de datos e inteligencia artificial
- Explorar dominios diversos con respaldo institucional

---

Perfecto, Claudio ‚úÖ. Aqu√≠ ten√©s la **traducci√≥n al espa√±ol** de la lecci√≥n final *OCI Data Labeling*, estructurada como ficha t√©cnica para cerrar tu manual de OCI Data Science.

---

# üè∑Ô∏è 6.3 Lecci√≥n: OCI Data Labeling  
## üìò Etiquetado de datos para entrenar modelos en OCI

### 1. ¬øQu√© es el data labeling?

El **etiquetado de datos** consiste en identificar propiedades en im√°genes o textos y asignarles etiquetas.  
Ejemplo: etiquetar 100 im√°genes de tigres permite entrenar un modelo para detectar tigres en im√°genes nuevas.

üîπ Es esencial para entrenar modelos supervisados en proyectos de IA/ML

---

### 2. ¬øQu√© es el servicio OCI Data Labeling?

- Servicio para **crear, gestionar y exportar datasets etiquetados**
- Compatible con otros servicios de OCI (Vision, Data Science, AI Services)
- Permite etiquetar im√°genes, texto y documentos
- Interfaz interactiva o v√≠a API

---

### 3. ¬øQui√©n lo usa?

| Perfil | Uso |
|--------|-----|
| **Data Scientists** | Arman datasets, etiquetan, exportan para entrenar modelos personalizados |
| **Developers / Engineers** | Etiquetan datos para ajustar modelos de AI Services (ej. reconocimiento de im√°genes) |

---

### 4. Aplicaciones por industria

| Industria | Ejemplo |
|----------|---------|
| **Retail / E-commerce** | Recomendaciones personalizadas |
| **Salud** | Detecci√≥n de anomal√≠as en im√°genes m√©dicas |
| **Medios / Entretenimiento** | Moderaci√≥n de contenido y an√°lisis de sentimiento |
| **Gobierno / Seguros / Manufactura** | Clasificaci√≥n, predicci√≥n, automatizaci√≥n

---

### 5. Rol en el ciclo de vida de IA/ML

```plaintext
üì• Etiquetado ‚Üí üß† Entrenamiento ‚Üí üìä Evaluaci√≥n ‚Üí üîÅ Reentrenamiento
```

- El etiquetado ocurre **al inicio**
- Etiquetado deficiente ‚Üí resultados distorsionados
- MLOps es iterativo: se reetiqueta si hay drift o baja precisi√≥n

üîπ Ejemplo: si una clase est√° subrepresentada, se agregan m√°s ejemplos etiquetados

---

### 6. Capacidades actuales

- Casos simples y r√°pidos
- Subida de datos v√≠a UI o API
- Etiquetado interactivo
- Exportaci√≥n para uso en otros servicios OCI

---

### 7. Conclusi√≥n

En esta lecci√≥n aprendiste:

- Qu√© es el etiquetado de datos y por qu√© es esencial
- C√≥mo funciona el servicio OCI Data Labeling
- Qui√©nes lo usan y en qu√© industrias
- C√≥mo impacta en el ciclo de vida de modelos ML
- C√≥mo usarlo para entrenar, ajustar y reentrenar modelos en OCI

---

















***********************************************************************************************************************************************


---

### üìò Glosario de T√©rminos Clave en OCI Data Science

| M√≥dulo / √Årea         | T√©rmino clave            | Descripci√≥n breve                                                  | Ejemplo aplicado a hotel real                                     |
|-----------------------|--------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|
| Entorno de desarrollo | ADS SDK                  | Librer√≠a de Python que simplifica tareas en el ciclo ML            | Entrenar modelo para predecir cancelaciones                       |
| Entorno de desarrollo | Notebook Session         | Ambiente interactivo en OCI para ejecutar c√≥digo y analizar datos  | Editar notebook para detecci√≥n de anomal√≠as en reservas            |
| IAM                   | Tenancy                  | Entorno ra√≠z que agrupa todos los recursos en OCI                  | Tenencia ‚ÄúHotelCorp‚Äù con compartimientos separados                |
| IAM                   | Compartment              | Contenedor l√≥gico para organizar recursos y pol√≠ticas              | Compartimiento ‚ÄúMarketing‚Äù con notebooks y objetos                |
| IAM                   | Group / Dynamic Group    | Grupo de usuarios o recursos con pol√≠ticas asociadas               | Grupo ‚ÄúAnalistas‚Äù con acceso a m√©tricas y logs                    |
| IAM                   | User / Principal         | Identidad que puede autenticarse y operar sobre recursos           | Usuario ‚ÄúAnaRecepcion‚Äù con acceso a modelos y buckets              |
| IAM                   | Policy / IAM Settings    | Reglas que autorizan acciones sobre recursos                       | Pol√≠tica que permite acceso al Object Storage                     |
| IAM                   | OCI CLI / Token          | Herramientas para operar OCI desde la terminal                     | Usar CLI para lanzar notebook desde cron semanal                  |
| Automatizaci√≥n        | Job / Pipeline / Workload| Ejecuciones automatizadas en infraestructura OCI                   | Job nocturno que actualiza predicci√≥n de ocupaci√≥n                |
| Automatizaci√≥n        | Scheduler / Cron         | Programador de tareas para ejecuci√≥n peri√≥dica                     | Ejecutar script todos los d√≠as a las 6 AM                         |
| Automatizaci√≥n        | Logging / Audit          | Registro de actividad y monitoreo del sistema                      | Ver qui√©n modific√≥ modelo de predicci√≥n ayer                      |
| Ciencia de datos      | ML Lifecycle             | Ciclo completo: ingesti√≥n, entrenamiento, despliegue, monitoreo    | Desde historial de reservas hasta API en producci√≥n               |
| Ciencia de datos      | AutoML / ADSTuner        | Entrenamiento autom√°tico y ajuste de hiperpar√°metros               | Entrenar 20 modelos y elegir el m√°s preciso                       |
| Ciencia de datos      | Model Catalog / Deployment| Repositorio y endpoints HTTP para modelos ML                       | Compartir modelo con el equipo de recepci√≥n                       |
| Ciencia de datos      | Feature Engineering      | Transformar variables para mejorar modelos                         | Crear ‚Äútemporada alta‚Äù desde campo fecha                          |
| Ciencia de datos      | Train-Test Split         | Divisi√≥n de datos para entrenamiento y evaluaci√≥n                  | Usar datos de 2021 para entrenar y 2022 para testear              |
| Ciencia de datos      | Metrics / Evaluation     | Indicadores para medir la calidad de un modelo                     | Ver precisi√≥n y F1 Score del modelo de ocupaci√≥n                  |
| Visualizaci√≥n         | Feature Types / Heatmap    | Clasificaci√≥n de variables y visualizaci√≥n de relaciones            | Ver correlaci√≥n entre ocupaci√≥n y d√≠a de la semana                  |
| Visualizaci√≥n         | Histogram / Distribution   | Gr√°fico que muestra frecuencia de valores                           | Distribuci√≥n de estad√≠as por cantidad de noches                    |
| Visualizaci√≥n         | Boxplot / Outliers         | Visualizaci√≥n de rango y valores extremos                           | Detectar precios fuera de lo com√∫n en reservas                     |
| Visualizaci√≥n         | Pairplot / Correlation     | Comparaci√≥n cruzada entre variables num√©ricas                       | Relaci√≥n entre tarifa, ocupaci√≥n y tipo de habitaci√≥n              |
| Almacenamiento        | Object Storage / Bucket    | Almacenamiento escalable en OCI para datasets y resultados          | Guardar CSV con reservas hist√≥ricas                                |
| Almacenamiento        | Dataset / CSV / JSON       | Formatos de datos para an√°lisis y entrenamiento de modelos          | Subir archivo ‚Äúcancelaciones_2023.csv‚Äù al bucket                   |
| Almacenamiento        | Data Flow / Data Catalog   | Servicios para procesar y documentar grandes vol√∫menes de datos     | Catalogar datasets sobre temporada alta y baja                     |
| Seguridad             | Vault / Secret Keeper      | Gesti√≥n segura de credenciales y claves                             | Conectar notebook con base Oracle sin exponer claves               |
| Seguridad             | Encryption / Access Policy | Protecci√≥n de datos y reglas de acceso                              | Definir pol√≠tica que proh√≠ba modificar modelos desde marketing     |
| Redes                 | VCN / Subnet / NAT / SG    | Red virtual y componentes para tr√°fico interno y externo            | Acceder a Object Storage sin exponer IP p√∫blica                    |
| Redes                 | Public / Private Endpoint  | Configuraci√≥n de acceso a servicios desde dentro o fuera de OCI     | API de predicci√≥n solo accesible desde subnet del hotel            |
| Redes                 | Internet Gateway / Route   | Permisos para que una red tenga salida a internet                   | Notebook con acceso a repositorios externos                        |
| Pr√°cticas MLOps       | Escalado / Load Balancer   | Optimizaci√≥n de recursos para alta demanda                          | Aumentar recursos si el uso del modelo crece durante temporada alta|
| Pr√°cticas MLOps       | Monitoring / Logging       | Seguimiento de m√©tricas y eventos en producci√≥n                     | Ver cu√°ntas veces se consult√≥ el modelo desde recepci√≥n            |
| Pr√°cticas MLOps       | Explainability / Feature Importance| Herramientas para interpretar el modelo                     | Mostrar que ‚Äútipo de cliente‚Äù impacta m√°s en cancelaciones         |
| Pr√°cticas MLOps       | Retraining / Drift         | Reentrenamiento y detecci√≥n de cambios en los datos                 | Actualizar modelo si cambian patrones de reserva                   |
| SDK / Herramientas    | Python SDK / OCI SDK       | Librer√≠as para interactuar con servicios OCI desde c√≥digo           | Crear bucket y notebook usando Python desde script                    |
| SDK / Herramientas    | ADS SDK / ADSInterpreter   | Herramientas espec√≠ficas para ciencia de datos en OCI               | Generar explicaci√≥n de modelo con gr√°ficos autom√°ticos                |
| SDK / Herramientas    | OCI CLI                    | Interfaz de l√≠nea de comandos para operar servicios OCI             | Lanzar notebook o subir archivos directamente desde consola           |
| Infraestructura       | Terraform / Resource Manager| Infraestructura como c√≥digo para automatizar configuraci√≥n          | Crear compartimientos y pol√≠ticas de acceso de forma repetible        |
| Infraestructura       | Stack / Plan / Apply       | Proceso de despliegue con Terraform: definir, previsualizar, ejecutar| Desplegar recursos para nuevo hotel sin errores manuales              |
| Organizaci√≥n           | Tags / Cost Tracking        | Etiquetado de recursos y seguimiento de costos                      | Ver cu√°nto cuesta entrenar modelos en entorno ‚ÄúTemporadaAlta‚Äù         |
| Buenas pr√°cticas      | Modularizaci√≥n / Reusabilidad| Separar funciones para claridad y mantenimiento                     | Validaciones de reserva en m√≥dulo ‚Äúutils‚Äù                             |
| Buenas pr√°cticas      | Confirmaci√≥n / Validaci√≥n  | Evitar errores cr√≠ticos con chequeos y confirmaciones expl√≠citas    | Confirmar borrado de modelo con ‚Äú¬øEst√°s seguro? [y/n]‚Äù                |
| Buenas pr√°cticas      | Documentaci√≥n / Naming     | Uso de nombres claros y descripciones en c√≥digo y estructura        | Bucket ‚Äúdatos_cancelaciones_hotelA_2023‚Äù                              |
| Bonus Ctrl+BA         | Ficha t√©cnica / Glosario Ctrl| Recurso con t√©rminos clave y ejemplos integrados                    | Usar en mentor√≠as dentro del servidor Ctrl+BA                         |
| Bonus Ctrl+BA         | Cuestionarios / Flashcards | Material para repasar y autoevaluarse en 3 niveles                  | Fichas para revisar IAM, ML y MLOps antes del examen                  |
| Bonus Ctrl+BA         | Presentaci√≥n / Teaching Pack| Recurso did√°ctico para exponer temas en clase o comunidad           | Explicar el ciclo ML con ejemplos hoteleros y slides visuales         |




---

En un proyecto de Machine Learning en OCI (o en cualquier entorno cloud moderno), los actores o perfiles cumplen roles complementarios que permiten llevar una soluci√≥n desde la idea hasta el despliegue y mantenimiento. Aqu√≠ te dejo una clasificaci√≥n clara y modular que pod√©s usar como base para documentar o planificar tus proyectos:

---

## üßë‚Äçüíº Actores en un Proyecto de Machine Learning

| Actor / Perfil | Rol principal | Funcionalidades clave |
|----------------|---------------|------------------------|
| **Usuario Visual / Analista** | Interacci√≥n con resultados y dashboards | - Usa la **OCI Console** para explorar notebooks y visualizar m√©tricas<br>- Interpreta salidas del modelo para decisiones de negocio<br>- No programa, pero necesita claridad en los resultados |
| **Cient√≠fico de Datos** | Desarrollo y entrenamiento de modelos | - Crea notebooks y scripts en Python<br>- Usa **SDKs** para lanzar Jobs, entrenar y evaluar modelos<br>- Experimenta con algoritmos y limpieza de datos<br>- Documenta y versiona experimentos |
| **Desarrollador / DevOps** | Integraci√≥n y automatizaci√≥n | - Usa **SDKs**, **REST API** y **CLI** para automatizar flujos<br>- Despliega modelos como endpoints<br>- Configura pipelines y triggers<br>- Gestiona recursos y seguridad |
| **Integrador / Arquitecto de Soluciones** | Conexi√≥n entre sistemas y servicios | - Dise√±a c√≥mo el modelo se conecta con otros sistemas (ERP, CRM, etc.)<br>- Usa **REST API** para integrar el modelo en apps externas<br>- Define arquitectura en OCI (compartimentos, redes, seguridad) |
| **Administrador de Infraestructura / Cloud Engineer** | Gesti√≥n de recursos y costos | - Configura entornos, compartimentos, pol√≠ticas IAM<br>- Monitorea uso de recursos y optimiza costos<br>- Asegura cumplimiento y escalabilidad |
| **Stakeholder / Product Owner** | Visi√≥n estrat√©gica y validaci√≥n | - Define objetivos del modelo<br>- Eval√∫a impacto en negocio<br>- Participa en validaci√≥n de resultados<br>- No t√©cnico, pero clave en decisiones |

---

## üß† Ejemplo de colaboraci√≥n

Imagin√° que est√°s desarrollando un modelo de predicci√≥n de demanda:

- El **Cient√≠fico de Datos** entrena el modelo con datos hist√≥ricos.
- El **Desarrollador** crea un pipeline que lanza el Job cada semana.
- El **Integrador** conecta el modelo con el sistema de inventario.
- El **Usuario Visual** revisa los resultados en un dashboard.
- El **Administrador** asegura que todo corra en un entorno seguro y eficiente.
- El **Stakeholder** valida si el modelo mejora la planificaci√≥n.

---

